title,company,location,city,date,link,description
Data Engineer,BOX8,"Bengaluru, Karnataka, India",Bengaluru,2025-05-30,https://in.linkedin.com/jobs/view/data-engineer-at-box8-4240914373?position=1&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=MU74IoIjcm3CQ%2BB6kXYDWw%3D%3D,"We are looking for a passionate and curious Data Engineer (Entry-Level) to join our DataTech team. This is an excellent opportunity for fresh graduates or early-career professionals to build a strong foundation in data engineering by working on real-world data problems, building robust pipelines, and collaborating across teams.

Responsibilities


Assist in developing scalable and optimized data pipelines for extraction, transformation, and loading (ETL).
Write clean and efficient Python scripts and SQL queries for data processing and analysis.
Work on integrating multiple data sources (databases, APIs, flat files, etc. )
Support team members in ensuring data quality, accuracy, and consistency.
Collaborate with analysts, data scientists, and engineers to deliver data solutions.
Contribute to automation initiatives and help build internal data tools.
Participate in code reviews, documentation, and team meetings to learn best practices in software and data engineering.
Assist in building computer vision or different AI models.


Requirements


B. E. /B. Tech in Computer Science, Information Technology, or related field (Tier I college background is a plus).
Strong foundation in: Python (Pandas, NumPy, basic scripting), SQL (writing basic to intermediate queries).
Exposure to: Git and Linux Shell Scripting, Data visualization tools or dashboards (e. g., Tableau, Power BI - optional).
Bonus if you've explored tools like Airflow, BigQuery, AWS S3/Redshift, or Firebase.
Built projects or done internships related to data engineering, analytics, or backend systems.
Strong logical thinking, curiosity to learn, and willingness to dive into data problems.


This job was posted by Payal Verma from Box8.
Show more "
Data Engineer II [T500-19642],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-08,https://in.linkedin.com/jobs/view/data-engineer-ii-t500-19642-at-mcdonald-s-4282147859?position=2&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=3aA8DZG%2FFl989AGH1TXwmA%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.?




Position Summary:

Looking to hire a Data Engineer who has a good understanding of Data Product Lifecycle, Standards and Practices. Will be responsible for building scalable and efficient data solutions to support the Finance, Franchising & Development function with a specific focus on the Finance Analytics product and initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Vital team member for initiatives to enable trusted financial data, supports decision-making, and partners with business and technology teams to align data capabilities with strategic finance objectives. Expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role within this domain.




Who we are looking for:

Primary Responsibilities:

Builds and maintains relevant and reliable data products that support Finance Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development and data engineering initiatives supporting Finance Analytics, ensuring timely and accurate delivery of financial data products.
Drive and implement best Data Engineering practices for pipeline development, data governance, data security and quality across financial datasets.
Implement security and privacy controls in data workflows, ensuring compliance with finance regulatory requirements.
Monitor, troubleshoot, and improve performance and reliability of existing finance data pipeline infrastructure.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving financial analytics needs.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Partner and collaborate with data engineers, particularly in finance-centric data models and processing frameworks.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed.




Skill:

Applies technical data engineering expertise to develop reliable pipelines and improve data quality in support of finance and analytics initiatives
Bachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing
3+ years of professional experience in data engineering or related fields
Proficiency in Python, Java, or Scala for data processing and automation
Hands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)
Good working knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Effective communication and stakeholder management skills to drive alignment and adoption of data engineering standards
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent collaboration skills to work effectively in cross-functional teams




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Data Engineer ( AM),KPMG India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-12,https://in.linkedin.com/jobs/view/data-engineer-am-at-kpmg-india-4283366096?position=3&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=6UUrWNjJCUnnM6a9OaWCsQ%3D%3D,"We are looking for 7 years of IT experience and 5+ in Data Engineering.

Locations open - Bangalore and Mumbai

Key Responsibilities:

Design, build, and maintain data pipelines using Azure Data Factory (ADF), Databricks, and PySpark
Optimize and transform large-scale datasets using Spark-based processing
Integrate and orchestrate workflows across Azure services using Logic Apps and ADF pipelines
Write efficient SQL queries to handle large datasets and support reporting/analytics needs
Collaborate with data architects, analysts, and business stakeholders to gather requirements and deliver solutions
Ensure data quality, consistency, and compliance with data governance policies
Document architecture, pipelines, and ETL/ELT processes for knowledge sharing and maintenance

Required Skills:

Strong hands-on experience in Azure Data Engineering
Proficiency in Azure Data Factory (ADF) and Azure Databricks
Solid command of PySpark for big data processing
Advanced knowledge of SQL
Experience working in agile development environments

Good to Have:

Proficiency in Python for data transformation or automation
Experience with Logic Apps for workflow integration

Show more "
Data Engineer II [T500-19595],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-07,https://in.linkedin.com/jobs/view/data-engineer-ii-t500-19595-at-mcdonald-s-4281487240?position=4&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=o%2FpRw%2FCu4mhtu%2FKRYOqCCg%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Position Summary:

Looking to hire a Data Engineer who has a good understanding of Data Product Lifecycle, Standards and Practices. Will be responsible for building scalable and efficient data solutions to support the Finance, Franchising & Development function with a specific focus on the Finance Analytics product and initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Vital team member for initiatives to enable trusted financial data, supports decision-making, and partners with business and technology teams to align data capabilities with strategic finance objectives. Expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role within this domain.




Who we are looking for:

Primary Responsibilities:

Builds and maintains relevant and reliable data products that support Finance Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development and data engineering initiatives supporting Finance Analytics, ensuring timely and accurate delivery of financial data products.
Drive and implement best Data Engineering practices for pipeline development, data governance, data security and quality across financial datasets.
Implement security and privacy controls in data workflows, ensuring compliance with finance regulatory requirements.
Monitor, troubleshoot, and improve performance and reliability of existing finance data pipeline infrastructure.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving financial analytics needs.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Partner and collaborate with data engineers, particularly in finance-centric data models and processing frameworks.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed.




Skill:

Applies technical data engineering expertise to develop reliable pipelines and improve data quality in support of finance and analytics initiatives
Bachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing
3+ years of professional experience in data engineering or related fields
Proficiency in Python, Java, or Scala for data processing and automation
Hands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)
Good working knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Effective communication and stakeholder management skills to drive alignment and adoption of data engineering standards
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent collaboration skills to work effectively in cross-functional teams




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Data Engineer,MakeMyTrip,"Gurgaon, Haryana, India",Gurgaon,2025-07-29,https://in.linkedin.com/jobs/view/data-engineer-at-makemytrip-4273701706?position=5&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=ktYLKsWDNGsmCqPiIuVDUw%3D%3D,"Purpose And Impact

Our teams are driven by the purpose providing exceptional travel experience for our customers. We have continuously stayed ahead of the curve by developing our technology and products to meet the ever-changing demands of the rapidly evolving travel ecosystem.

Currently We Are Solving The Below Challenging Problems


How do we leverage big data to provide a truly personalized experience to each of our users?
How do we leverage AI to innovate our products and deliver best in class end-to-end experience to all our users?
How to bring the next 100 million users to our platform?


If this excites you, join us, for a rewarding, fulfilling and enriching career.

What You’ll Be Doing


Accurately estimate and implement machine learning models.
Build pipelines for feature engineering by integrating data from different data sources.
You’ll meticulously develop and deploy production data pipelines (batch + real time)
Architect and design scalable data services that are consumed by millions of users.
Skillful implement performance engineering of big data systems.


What You’ll Bring To The Table


You’ll bring the compulsory and essential experience of working with distributed systems software development.
You’ll bring demonstrated experience of production experience in big data infrastructure and data modeling.
You’ll bring critical experience performance optimization for both data loading and data retrieval.
Know-how of Spark/Kafka.
Invaluable knowledge in AWS Deployment, Docker and Kubernetes.
Show more "
"Data Engineer, Python and SQL, Associate",BlackRock,"Gurgaon, Haryana, India",Gurgaon,2025-08-08,https://in.linkedin.com/jobs/view/data-engineer-python-and-sql-associate-at-blackrock-4258079627?position=6&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=4VhyNKrxOVeGTXRC3Q0Y8A%3D%3D,"About This Role

Aladdin Engineering is seeking a talented, hands-on Data Engineer to join its Regulatory Tech team. The Regulatory Tech team provides a comprehensive surveillance solution for Compliance that helps the firm protect itself against market manipulation, fraud and other financial related misconducts. Our product is widely used in the firm and is going through a series of feature buildouts so that it can be offered to external clients. We are facing a lot of potential and exciting times ahead.

As a team, we nurture and develop a culture that is:


Curious: We like to learn new things and have a healthy disrespect for the status quo
Brave: We are willing to get outside your comfort zone
Passionate: We feel personal ownership of your work, and strive to be better
Open: We value and respect other's opinions
Innovative: We conceptualize, design and implement new capabilities to ensure that Aladdin remains the best platform.


We are seeking an ambitious professional having strong technical experience in data engineering. You have a solid understanding of the software development lifecycle and enjoy working in a team of engineers. The ideal candidate shows aptitude to evaluate and incorporate new technologies. You thrive in a work environment that requires creative problem-solving skills, independent self-direction, open communication and attention to details. You are a self-starter, comfortable with ambiguity and working in a fast-paced, ever-changing environment. You are passionate about bringing value to clients.

As Member Of The Regulatory Tech Team, You Will


Work with engineers, project managers, technical leads, business owners and analysts throughout the whole SDLC
Design and implement new features in our core product’s data platform and suspicious activity identifying mechanism
Be brave enough to come up with ideas to improve resiliency, stability and performance of our platform
Participate in setting coding standards and guidelines, identify and document standard methodologies


Desired Skills And Experience


3+ years of hands-on experience with Python and SQL
Experience with Snowflake database
Experience with Airflow
Thorough knowledge of GIT, CI/CD and unit/end-to-end testing
Interest in data engineering
Solid written and verbal communication skills


Nice To Have


Experience with DBT, Great Expectations frameworks
Experience with Big Data technologies (Spark, Sqoop, HDFS, YARN)
Experience with Agile development


Our Benefits

To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.

Our hybrid work model

BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.

About BlackRock

At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being. Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.

This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.

For additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com/company/blackrock

BlackRock is proud to be an Equal Opportunity Employer. We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.
Show more "
Python Data Engineer,Infosys,"Gurgaon, Haryana, India",Gurgaon,2025-08-01,https://in.linkedin.com/jobs/view/python-data-engineer-at-infosys-4273720276?position=7&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=nSmjSzhQ4%2BBYLwrYvqevPA%3D%3D,"Primary skills:Technology->Machine Learning->Python


A day in the life of an Infoscion


As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction.
You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain.
You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews.
You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes.
You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!
Show more "
Data Engineer III [T500-18704],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-07-15,https://in.linkedin.com/jobs/view/data-engineer-iii-t500-18704-at-mcdonald-s-4253097595?position=8&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=IVOOjzqqjmYfC76p8oL4TQ%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Position Summary:

Looking to hire a Data Engineer at the G4 level who has a deep understanding of Data Product Lifecycle, Standards and Practices. Will be responsible for building scalable and efficient data solutions to support the Brand Marketing / Menu function with a specific focus on the Menu Data product and initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Leads initiatives to enable trusted Menu data, supports decision-making, and partners with business and technology teams to deliver scalable data solutions that drive insights into menu performance, customer preferences, and marketing effectiveness. Expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role within this domain.




Who we’re looking for:

Primary Responsibilities:

Builds and maintains relevant and reliable Menu data products that support menu and marketing Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development engineering and Lead data engineering initiatives supporting Product Mix Analytics, ensuring timely and accurate delivery of marketing and menu-related products.
Work closely with the Product owner and help to define business rules that determines the quality of Menu datasets.
Drive and implement best practices for pipeline development, data governance, data security and quality across marketing and menu-related datasets.
Ensure scalability, maintainability, and quality of data systems powering menu item tracking, promotion data, and marketing analytics.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving Product Mix analytics needs.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Mentor and coach junior data engineers, particularly in areas related to menu item tracking, promotion data, and marketing analytics.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed




Skill:

Leads teams to drive scalable data engineering practices and technical excellence within the Menu Data ecosystem.
Bachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing
5+ years of professional experience in data engineering or related fields
Proficiency in Python, Java, or Scala for data processing and automation
Hands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)
Expert knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Proven ability to mentor team members and lead technical initiatives across multiple workstreams
Effective communication and stakeholder management skills to drive alignment and adoption of data engineering standards
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent collaboration skills to work effectively in cross-functional teams.

Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Software Engineer (Backend 3-5yrs),PhonePe,"Bengaluru, Karnataka, India",Bengaluru,2025-07-31,https://in.linkedin.com/jobs/view/software-engineer-backend-3-5yrs-at-phonepe-4250613909?position=10&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=cWJpIiVoo%2FhJYUM9RSqtYA%3D%3D,"About PhonePe Limited:

Headquartered in India, its flagship product, the PhonePe digital payments app, was launched in Aug 2016. As of April 2025, PhonePe has over 60 Crore (600 Million) registered users and a digital payments acceptance network spread across over 4 Crore (40+ million) merchants. PhonePe also processes over 33 Crore (330+ Million) transactions daily with an Annualized Total Payment Value (TPV) of over INR 150 lakh crore.

PhonePe’s portfolio of businesses includes the distribution of financial products (Insurance, Lending, and Wealth) as well as new consumer tech businesses (Pincode - hyperlocal e-commerce and Indus AppStore Localized App Store for the Android ecosystem) in India, which are aligned with the company’s vision to offer every Indian an equal opportunity to accelerate their progress by unlocking the flow of money and access to services.

Culture:

At PhonePe, we go the extra mile to make sure you can bring your best self to work, Everyday!. And that starts with creating the right environment for you. We empower people and trust them to do the right thing. Here, you own your work from start to finish, right from day one. PhonePe-rs solve complex problems and execute quickly; often building frameworks from scratch. If you’re excited by the idea of building platforms that touch millions, ideating with some of the best minds in the country and executing on your dreams with purpose and speed, join us!

As a Software Engineer:


You will build Robust and Scalable web-based applications.
Build abstractions and contracts with separation of concerns for a larger scope.
Drive problem-solving skills for high-level business and technical problems.
Do high-level design with guidance; Functional modeling, break-down of a module.
Do incremental changes to architecture: impact analysis of the same.
Do performance tuning and improvements in large scale distributed systems
Work closely with Product Manager to derive capability view from features/solutions, Lead execution of medium-sized projects
Work with broader stakeholders to track the impact of projects/features and proactively iterate to improve them


As a Software Engineer, you must have:


Extensive and expert programming experience in at least one general programming language (e.g. Java, C, C++) & tech stack to write maintainable, scalable, unit-tested code.
Experience with multi-threading and concurrency programming.
Experience in building highly scalable business applications, which involve implementing large complex business flows and dealing with a huge amount of data.
Extensive experience in object-oriented design skills, knowledge of design patterns, and huge passion and ability to design intuitive module and class-level interfaces.
Excellent coding skills – should be able to convert the design into code fluently.
Knowledge of Test Driven Development.
Good understanding of databases (e.g. MySQL) and NoSQL (e.g. HBase, Elasticsearch, Aerospike, etc).
Experience with full life cycle development in any programming language.
Worked in a startups environment with high levels of ownership and commitment.
BTech, MTech, or Ph.D. in Computer Science or related technical discipline (or equivalent).
3-5 years of experience in the art of writing code and solving problems on a Large Scale.


PhonePe Full Time Employee Benefits (Not applicable for Intern or Contract Roles)


Insurance Benefits - Medical Insurance, Critical Illness Insurance, Accidental Insurance, Life Insurance
Wellness Program - Employee Assistance Program, Onsite Medical Center, Emergency Support System
Parental Support - Maternity Benefit, Paternity Benefit Program, Adoption Assistance Program, Day-care Support Program
Mobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy
Retirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment
Other Benefits - Higher Education Assistance, Car Lease, Salary Advance Policy


Our inclusive culture promotes individual expression, creativity, innovation, and achievement and in turn helps us better understand and serve our customers. We see ourselves as a place for intellectual curiosity, ideas and debates, where diverse perspectives lead to deeper understanding and better quality results. PhonePe is an equal opportunity employer and is committed to treating all its employees and job applicants equally; regardless of gender, sexual preference, religion, race, color or disability. If you have a disability or special need that requires assistance or reasonable accommodation, during the application and hiring process, including support for the interview or onboarding process, please fill out this form.

Read more about PhonePe on our blog.

Life at PhonePe

PhonePe in the news
Show more "
ICICI Securities - Data Engineer - Python/SQL/ETL,ICICIDirect,"Navi Mumbai, Maharashtra, India",Navi Mumbai,2025-05-21,https://in.linkedin.com/jobs/view/icici-securities-data-engineer-python-sql-etl-at-icicidirect-4233880080?position=11&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=4O5Uvz4U8LJjSkQVwwnczg%3D%3D,"Job Responsibilities


To work on Data Analytics to solve various business use cases.
Design and implement data pipelines to extract data from various sources (databases, flat files, APIs, streaming data, etc.
Develop efficient ETL processes using tools like Apache Spark, Apache Sqoop, Python/SQL, Pyspark,.
Good to have expertise/ knowledge in Apache Iceberg, Apace Ni-fi/ Apache Flink and Apache Kafka.
Basic Understanding of Data Pipeline design using PL/SQL jobs.
Provide seamless data Availability for data analysts, data scientists, and other stakeholders.
Develop various Business Requirements leveraging SQL and Python.
Stay updated with the latest industry trends and advancements in data analytics and AI, Data Lake, Delta Lake Experience :
Over all 6 -12 years of experience in Data Engineering & Data Analytics.
Hands-on experience in coding with Python and SQL.
Experience in building ETL, ELT Pipelines using Python.
Strong expertise in Hadoop Ecosystem (Hive, Impala, Cloudera), Spark, Sqoop, Delta Lake, Data warehouse Concepts, RDBMS System, No SQL Databases, Apache Tools like Ni-fi, Kafka etc.
Experience in Cloudera data platform is Qualification :
Bachelor's or Masters degree in Computer Science, IT or any Engineering field.


(ref:hirist.tech)
Show more "
Data Engineer,Oracle,"Bengaluru, Karnataka, India",Bengaluru,2025-07-18,https://in.linkedin.com/jobs/view/data-engineer-at-oracle-4268780150?position=12&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=VYmL8lZxCVyBhiYkgqGGvg%3D%3D,"About Oracle FSGIU - Finergy:

The Finergy division within Oracle FSGIU is dedicated to the Banking, Financial Services, and Insurance (BFSI) sector. We offer deep industry knowledge and expertise to address the complex financial needs of our clients. With proven methodologies that accelerate deployment and personalization tools that create loyal customers, Finergy has established itself as a leading provider of end-to-end banking solutions. Our single platform for a wide range of banking services enhances operational efficiency, and our expert consulting services ensure technology aligns with our clients' business goals

Responsibilities:

Snowflake Data Modeling & Architecture: Design and implement scalable Snowflake data models using best practices such as Snowflake Data Vault methodology.
Real-Time Data Replication & Ingestion: Utilize Oracle GoldenGate for Big Data to manage real-time data streaming and optimize Snowpipe for automated data ingestion.
Cloud Integration & Management: Work with AWS services (S3, EC2, Lambda) to integrate and manage Snowflake-based solutions.
Data Sharing & Security: Implement SnowShare for data sharing and enforce security measures such as role-based access control (RBAC), data masking, and encryption.
CI/CD Implementation: Develop and manage CI/CD pipelines for Snowflake deployment and data transformation processes.
Collaboration & Troubleshooting: Partner with cross-functional teams to address data-related challenges and optimize performance.
Documentation & Best Practices: Maintain detailed documentation for data architecture, ETL processes, and Snowflake configurations.
Performance Optimization: Continuously monitor and enhance the efficiency of Snowflake queries and data pipelines.

Mandatory Skills:

Should have 4 years of experience as Data Engineer
Strong expertise in Snowflake architecture, data modeling, and query optimization.
Proficiency in SQL for writing and optimizing complex queries.
Hands-on experience with Oracle GoldenGate for Big Data for real-time data replication.
Knowledge of Snowpipe for automated data ingestion.
Familiarity with AWS cloud services (S3, EC2, Lambda, IAM) and their integration with Snowflake.
Experience with CI/CD tools (e.g., Jenkins, GitLab) for automating workflows.
Working knowledge of Snowflake Data Vault methodology.

Good to Have Skills:

Exposure to Databricks for data processing and analytics.
Knowledge of Python or Scala for data engineering tasks.
Familiarity with Terraform or CloudFormation for infrastructure as code (IaC).
Experience in data governance and compliance best practices.
Understanding of ML and AI integration with data pipelines.

Show more "
Data Engineer,Infosys,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-01,https://in.linkedin.com/jobs/view/data-engineer-at-infosys-4239288194?position=13&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=d%2BPr6pACcEjpZNGvKcHI2A%3D%3D,"We are seeking a skilled and detail-oriented Data Warehouse Engineer to design, build, and maintain scalable data warehouse solutions. You will be responsible for developing efficient data pipelines, integrating diverse data sources, ensuring data accuracy, and enabling high-quality analytics to drive business decisions. Responsibilities: Design, develop, and maintain data warehouse architectures and systems. Build robust ETL (Extract, Transform, Load) processes for structured and unstructured data sources. Optimize data models, database performance, and storage solutions. Collaborate with data analysts, data scientists, and business stakeholders to understand data requirements. Implement data quality checks and ensure data governance best practices. Develop and maintain documentation related to data warehouse design, data flow, and processes. Monitor system performance and proactively identify areas for improvement. Support ad-hoc data requests and reporting needs. Stay up-to-date with emerging data technologies and industry best practices.
Show more "
Data Engineer,PwC Acceleration Centers,"Bengaluru, Karnataka, India",Bengaluru,2025-07-18,https://in.linkedin.com/jobs/view/data-engineer-at-pwc-acceleration-centers-4268745576?position=14&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=GuRE0VoSINOZIFxwZK2cVg%3D%3D,"Role: Azure Data Engineer - Senior Associate




Experience: 5.5 - 9.9 years




Key Skills: Azure




Educational Qualification: BE / B Tech / ME / M Tech / MBA




Work Location: Bangalore




Job Description

As a Senior Associate, you will work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:

Use feedback and reflection to develop self-awareness, personal strengths, and address development areas.
Flexible to work in stretch opportunities/assignments.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Ticket Quality and deliverables review, Status Reporting for the project.
Adherence to SLAs, experience in incident management, change management and problem management.
Seek and embrace opportunities which give exposure to different situations, environments, and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Demonstrate leadership capabilities by working, with clients directly and leading the engagement.
Work in a team environment that includes client interactions, workstream management, and cross-team collaboration.
Good team player, take up cross competency work and contribute to COE activities.
Escalation/Risk management.










Position Requirements:




Required Skills:

Azure Cloud Engineer:

Job description:




Candidate is expected to demonstrate extensive knowledge and/or a proven record of success in the following areas:

Should have minimum 6 years hand on experience building advanced Data warehousing solutions on leading cloud platforms.
Should have minimum 3-5 years of Operate/Managed Services/Production Support Experience
Should have extensive experience in developing scalable, repeatable, and secure data structures and pipelines to ingest, store, collect, standardize, and integrate data that for downstream consumption like Business Intelligence systems, Analytics modelling, Data scientists etc.
Designing and implementing data pipelines to extract, transform, and load (ETL) data from various sources into data storage systems, such as data warehouses or data lakes.
Should have experience in building efficient, ETL/ELT processes using industry leading tools like Informatica, Talend, SSIS, AWS, Azure, Spark, SQL, Python etc.
Should have Hands-on experience with Data analytics tools like Informatica, Collibra, Hadoop, Spark, Snowflake etc.
Design, implement, and maintain data pipelines for data ingestion, processing, and transformation in Azure.
Work together with data scientists and analysts to understand the needs for data and create effective data workflows.
Create and maintain data storage solutions including Azure SQL Database, Azure Data Lake, and Azure Blob Storage.
Utilizing Azure Data Factory or comparable technologies, create and maintain ETL (Extract, Transform, Load) operations.
Perform data transformation and processing tasks to prepare the data for analysis and reporting in Azure Databricks or Azure Synapse Analytics for large-scale data transformations using tools like Apache Spark.
Implementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.
Improve the scalability, efficiency, and cost-effectiveness of data pipelines.
Monitoring and troubleshooting data pipelines and resolving issues related to data processing, transformation, or storage.
Implementing and maintaining data security and privacy measures, including access controls and encryption, to protect sensitive data
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Should have experience in Building and maintaining Data Governance solutions (Data Quality, Metadata management, Lineage, Master Data Management and Data security) using industry leading tools
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Should have Hands-on experience with Data analytics tools like databricks
Should have Experience of ITIL processes like Incident management, Problem Management, Knowledge management, Release management, Data DevOps etc.
Should have Strong communication, problem solving, quantitative and analytical abilities.

Nice to have:

Azure certification







Managed Services- Data, Analytics & Insights Managed Service




At PwC we relentlessly focus on working with our clients to bring the power of technology and humans together and create simple, yet powerful solutions. We imagine a day when our clients can simply focus on their business knowing that they have a trusted partner for their IT needs. Every day we are motivated and passionate about making our clients’ better.




Within our Managed Services platform, PwC delivers integrated services and solutions that are grounded in deep industry experience and powered by the talent that you would expect from the PwC brand. The PwC Managed Services platform delivers scalable solutions that add greater value to our client’s enterprise through technology and human-enabled experiences. Our team of highly skilled and trained global professionals, combined with the use of the latest advancements in technology and process, allows us to provide effective and efficient outcomes. With PwC’s Managed Services our clients are able to focus on accelerating their priorities, including optimizing operations and accelerating outcomes. PwC brings a consultative first approach to operations, leveraging our deep industry insights combined with world class talent and assets to enable transformational journeys that drive sustained client outcomes. Our clients need flexible access to world class business and technology capabilities that keep pace with today’s dynamic business environment.




Within our global, Managed Services platform, we provide Data, Analytics & Insights where we focus more so on the evolution of our clients’ Data and Analytics ecosystem. Our focus is to empower our clients to navigate and capture the value of their Data & Analytics portfolio while cost-effectively operating and protecting their solutions. We do this so that our clients can focus on what matters most to your business: accelerating growth that is dynamic, efficient and cost-effective.




As a member of our Data, Analytics & Insights Managed Service team, we are looking for candidates who thrive working in a high-paced work environment capable of working on a mix of critical Data, Analytics & Insights offerings and engagement including help desk support, enhancement, and optimization work, as well as strategic roadmap and advisory level work. It will also be key to lend experience and effort in helping win and support customer engagements from not only a technical perspective, but also a relationship perspective.

Show more "
Data Engineer,PwC Acceleration Centers,"Bengaluru, Karnataka, India",Bengaluru,2025-07-18,https://in.linkedin.com/jobs/view/data-engineer-at-pwc-acceleration-centers-4268710865?position=16&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=yjxPbVYYILF26ex0HsKTYg%3D%3D,"Role: AWS Data Engineer- Senior Associate

Experience: : 5.5 -9.9 years

Key Skills: AWS

Educational Qualification: BE / B Tech / ME / M Tech / MBA

Work Location: Bangalore

Job Description

As a Senior Associate, you will work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:

Use feedback and reflection to develop self-awareness, personal strengths, and address development areas.
Flexible to work in stretch opportunities/assignments.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Ticket Quality and deliverables review, Status Reporting for the project.
Adherence to SLAs, experience in incident management, change management and problem management.
Seek and embrace opportunities which give exposure to different situations, environments, and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Demonstrate leadership capabilities by working, with clients directly and leading the engagement.
Work in a team environment that includes client interactions, workstream management, and cross-team collaboration.
Good team player, take up cross competency work and contribute to COE activities.
Escalation/Risk management.

Position Requirements:

Required Skills:

AWS Cloud Engineer:

Job description:

Candidate is expected to demonstrate extensive knowledge and/or a proven record of success in the following areas:

Should have minimum 5 years hand on experience building advanced Data warehousing solutions on leading cloud platforms.
Should have minimum 3-4 years of Operate/Managed Services/Production Support Experience
Should have extensive experience in developing scalable, repeatable, and secure data structures and pipelines to ingest, store, collect, standardize, and integrate data that for downstream consumption like Business Intelligence systems, Analytics modelling, Data scientists etc.
Designing and implementing data pipelines to extract, transform, and load (ETL) data from various sources into data storage systems, such as data warehouses or data lakes.
Should have experience in building efficient, ETL/ELT processes using industry leading tools like AWS, AWS GLUE, AWS Lambda, AWS DMS, PySpark, SQL, Python, DBT, Prefect, Snowflake, etc.
Design, implement, and maintain data pipelines for data ingestion, processing, and transformation in AWS.
Work together with data scientists and analysts to understand the needs for data and create effective data workflows.
Implementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.
Improve the scalability, efficiency, and cost-effectiveness of data pipelines.
Monitoring and troubleshooting data pipelines and resolving issues related to data processing, transformation, or storage.
Implementing and maintaining data security and privacy measures, including access controls and encryption, to protect sensitive data
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Should have experience in Building and maintaining Data Governance solutions (Data Quality, Metadata management, Lineage, Master Data Management and Data security) using industry leading tools
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Should have Hands-on experience with Data analytics tools like Informatica, Collibra, Hadoop, Spark, Snowflake etc.
Should have Experience of ITIL processes like Incident management, Problem Management, Knowledge management, Release management, Data DevOps etc.
Should have Strong communication, problem solving, quantitative and analytical abilities.

Nice to have:

AWS certification

Managed Services- Data, Analytics & Insights Managed Service

At PwC we relentlessly focus on working with our clients to bring the power of technology and humans together and create simple, yet powerful solutions. We imagine a day when our clients can simply focus on their business knowing that they have a trusted partner for their IT needs. Every day we are motivated and passionate about making our clients’ better.

Within our Managed Services platform, PwC delivers integrated services and solutions that are grounded in deep industry experience and powered by the talent that you would expect from the PwC brand. The PwC Managed Services platform delivers scalable solutions that add greater value to our client’s enterprise through technology and human-enabled experiences. Our team of highly skilled and trained global professionals, combined with the use of the latest advancements in technology and process, allows us to provide effective and efficient outcomes. With PwC’s Managed Services our clients are able to focus on accelerating their priorities, including optimizing operations and accelerating outcomes. PwC brings a consultative first approach to operations, leveraging our deep industry insights combined with world class talent and assets to enable transformational journeys that drive sustained client outcomes. Our clients need flexible access to world class business and technology capabilities that keep pace with today’s dynamic business environment.

Within our global, Managed Services platform, we provide Data, Analytics & Insights where we focus more so on the evolution of our clients’ Data and Analytics ecosystem. Our focus is to empower our clients to navigate and capture the value of their Data & Analytics portfolio while cost-effectively operating and protecting their solutions. We do this so that our clients can focus on what matters most to your business: accelerating growth that is dynamic, efficient and cost-effective.

As a member of our Data, Analytics & Insights Managed Service team, we are looking for candidates who thrive working in a high-paced work environment capable of working on a mix of critical Data, Analytics & Insights offerings and engagement including help desk support, enhancement, and optimization work, as well as strategic roadmap and advisory level work. It will also be key to lend experience and effort in helping win and support customer engagements from not only a technical perspective, but also a relationship perspective.

Show more "
Data Engineer,PwC Acceleration Centers,"Bengaluru, Karnataka, India",Bengaluru,2025-08-06,https://in.linkedin.com/jobs/view/data-engineer-at-pwc-acceleration-centers-4280800105?position=17&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=tYx2jYZuV%2Fjslx3AhkIYRw%3D%3D,"Palantir Data Engineer – Senior Associate (5–9 Years)

Our Analytics & Insights Managed Services team brings a unique combination of industry expertise, technology, data management and managed-services experience to create sustained outcomes for our clients and improve business performance. We empower companies to transform their approach to analytics and insights while building your skills in exciting new directions. Have a voice at our table to help design, build and operate the next generation of software and services leveraging the power of Palantir.

Job Requirements and Preferences

Basic Qualifications

Minimum Degree Required:

Bachelor's degree in computer science, Data Engineering, Data Science, Information Systems, or a related technical field

Minimum Years of Experience:

5–9 years of hands-on data engineering experience, including 2+ years working with Palantir Foundry or Gotham

Preferred Qualifications

Degree Preferred:

Master's degree in data science, Analytics, Computer Science, Information Systems, or related discipline

Preferred Fields of Study:

Data Processing/Analytics/Science, Management Information Systems, Software Engineering

Preferred Knowledge & Skills

As a Senior Associate, you architect, develop, and optimize end-to-end data solutions on Palantir platforms, while mentoring junior teammates. You demonstrate deep technical acumen across:

Palantir Platform & Data Modeling

– Design and maintain Foundry ontologies, datasets, and code workbooks

– Build reusable transforms and data models that underpin business workflows

Cloud-Scale Data Engineering

– Develop and optimize ETL/ELT pipelines in Python (PySpark) and SQL

– Integrate diverse sources (batch, streaming, JDBC/ODBC, REST/Kafka/Kinesis) into Foundry

Performance & Scalability

– Tune high-volume, latency-sensitive data feeds for both batch and event-driven patterns

– Employ caching, partitioning, and parallelization best practices

DevOps & Automation

– Implement CI/CD pipelines with Git, Docker, Kubernetes, and infrastructure-as-code

– Automate testing, deployment, and versioning of Foundry code

Data Governance & Quality

– Leverage Foundry’s built-in lineage, access controls, and monitoring capabilities

– Collaborate with data stewards to define quality metrics and enforce policies

Cloud & Infrastructure

– Hands-on experience with AWS, Azure or GCP services (e.g., S3, Glue, Dataflow) supporting Palantir deployments

– Understand network security, IAM, and multi-cloud/hybrid architectures

Collaboration & Mentorship

– Partner with data scientists, analysts, and architects to translate requirements into robust solutions

– Coach junior engineers, share best practices, and drive continuous improvement

Communication & Delivery

– Present technical designs and performance analyses to senior stakeholders

– Contribute accelerators, playbooks, and internal tools to accelerate client delivery

Show more "
Data Engineer III [T500-19645],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-08,https://in.linkedin.com/jobs/view/data-engineer-iii-t500-19645-at-mcdonald-s-4282149752?position=18&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=I7nPcNgr3%2BjTZjPcr%2BLrkw%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Position Summary:

Looking to hire a Data Engineer at the G4 level who has a deep understanding of Data Product Lifecycle, Standards and Practices. Will be responsible for building scalable and efficient data solutions to support the Brand Marketing / Menu function with a specific focus on the Menu Data product and initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Leads initiatives to enable trusted Menu data, supports decision-making, and partners with business and technology teams to deliver scalable data solutions that drive insights into menu performance, customer preferences, and marketing effectiveness. Expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role within this domain.




Who we are looking for:

Primary Responsibilities:

Builds and maintains relevant and reliable Menu data products that support menu and marketing Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development engineering and Lead data engineering initiatives supporting Product Mix Analytics, ensuring timely and accurate delivery of marketing and menu-related products.
Work closely with the Product owner and help to define business rules that determines the quality of Menu datasets.
Drive and implement best practices for pipeline development, data governance, data security and quality across marketing and menu-related datasets.
Ensure scalability, maintainability, and quality of data systems powering menu item tracking, promotion data, and marketing analytics.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving Product Mix analytics needs.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Mentor and coach junior data engineers, particularly in areas related to menu item tracking, promotion data, and marketing analytics.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed




Skill:

Leads teams to drive scalable data engineering practices and technical excellence within the Menu Data ecosystem.
Bachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing
5+ years of professional experience in data engineering or related fields
Proficiency in Python, Java, or Scala for data processing and automation
Hands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)
Expert knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Proven ability to mentor team members and lead technical initiatives across multiple workstreams
Effective communication and stakeholder management skills to drive alignment and adoption of data engineering standards
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent collaboration skills to work effectively in cross-functional teams.




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Data Engineer III [T500-19596],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-07,https://in.linkedin.com/jobs/view/data-engineer-iii-t500-19596-at-mcdonald-s-4281485539?position=19&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=B%2BJzYkDRQ7xlkRSsuZcfNg%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Additional Information:

McDonald’s is committed to providing qualified individuals with disabilities with reasonable accommodations to perform the essential functions of their jobs. McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

McDonald’s Capability Center India Private Limited (“McDonald’s in India”) is a proud equal opportunity employer and is committed to hiring a diverse workforce and sustaining an inclusive culture. At McDonald’s in India, employment decisions are based on merit, job requirements, and business needs, and all qualified candidates are considered for employment. McDonald’s in India does not discriminate based on race, religion, colour, age, gender, marital status, nationality, ethnic origin, sexual orientation, political affiliation, veteran status, disability status, medical history, parental status, genetic information, or any other basis protected under state or local laws.

Nothing in this job posting or description should be construed as an offer or guarantee of employment.




Position Summary:

Looking to hire a Data Engineer at the G4 level who has a deep understanding of Data Product Lifecycle, Standards and Practices. Will be responsible for building scalable and efficient data solutions to support the Brand Marketing / Menu function with a specific focus on the Menu Data product and initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Leads initiatives to enable trusted Menu data, supports decision-making, and partners with business and technology teams to deliver scalable data solutions that drive insights into menu performance, customer preferences, and marketing effectiveness. Expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role within this domain.




Who we are looking for:

Primary Responsibilities:

Builds and maintains relevant and reliable Menu data products that support menu and marketing Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development engineering and Lead data engineering initiatives supporting Product Mix Analytics, ensuring timely and accurate delivery of marketing and menu-related products.
Work closely with the Product owner and help to define business rules that determines the quality of Menu datasets.
Drive and implement best practices for pipeline development, data governance, data security and quality across marketing and menu-related datasets.
Ensure scalability, maintainability, and quality of data systems powering menu item tracking, promotion data, and marketing analytics.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving Product Mix analytics needs.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Mentor and coach junior data engineers, particularly in areas related to menu item tracking, promotion data, and marketing analytics.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed




Skill:

Leads teams to drive scalable data engineering practices and technical excellence within the Menu Data ecosystem.
Bachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing
5+ years of professional experience in data engineering or related fields
Proficiency in Python, Java, or Scala for data processing and automation
Hands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)
Expert knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Proven ability to mentor team members and lead technical initiatives across multiple workstreams
Effective communication and stakeholder management skills to drive alignment and adoption of data engineering standards
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent collaboration skills to work effectively in cross-functional teams.




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Data Engineer,Xiaomi India,"Bengaluru, Karnataka, India",Bengaluru,2025-07-18,https://in.linkedin.com/jobs/view/data-engineer-at-xiaomi-india-4268752348?position=20&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=pqJF6n2goJfVimRWYOLXeQ%3D%3D,"Job Description:

As a Data Engineer, you will be responsible for designing, implementing, and maintaining our data infrastructure to support our rapidly growing business needs.
The ideal candidate will have expertise in Apache Iceberg, Apache Hive, Apache Hadoop, SparkSQL, YARN, HDFS, MySQL, Data Modeling, Data Warehousing, Spark Architecture, and SQL Query Optimization.
Experience with Apache Flink, PySpark, Automated Data Quality testing & Data Migration is considered a plus.
Also, it's mandatory to know any one cloud stack (AWS or Azure) for Data Engineering to Create Data Jobs and Workflows and Scheduler it later for Automation




Job Responsibilities & Requirements:

Bachelor's degree in computer science, Information Technology, or a related field. Master's degree preferred.
4-5 years of experience working as a Data Engineer
Mandatory experience in PySpark Development for Big data processing
Strong proficiency in Apache Iceberg, Apache Hive, Apache Hadoop, SparkSQL, YARN, HDFS, Data Modeling, and Data Warehousing.
Core PySpark Development and Optimizing SQL queries and performance tuning to ensure optimal data retrieval and processing.
Experience with Apache Flink, and Automated Data Quality testing is a plus.
It's mandatory to know any one cloud stack (AWS or Azure) for Data Engineering to Create Data Jobs and Workflows and Scheduler later for Automation




Join Xiaomi India Technology and be part of a team that is shaping the future of technology innovation. Apply now and embark on an exciting journey with us!

Show more "
Data Engineer,Lenovo,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-07-23,https://in.linkedin.com/jobs/view/data-engineer-at-lenovo-4259502618?position=21&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=FLMqXAhq6hcYDtmIvoOkuw%3D%3D,"We are Lenovo. We do what we say. We own what we do. We WOW our customers.

Lenovo is a US$69 billion revenue global technology powerhouse, ranked #196 in the Fortune Global 500, and serving millions of customers every day in 180 markets. Focused on a bold vision to deliver Smarter Technology for All, Lenovo has built on its success as the world’s largest PC company with a full-stack portfolio of AI-enabled, AI-ready, and AI-optimized devices (PCs, workstations, smartphones, tablets), infrastructure (server, storage, edge, high performance computing and software defined infrastructure), software, solutions, and services. Lenovo’s continued investment in world-changing innovation is building a more equitable, trustworthy, and smarter future for everyone, everywhere. Lenovo is listed on the Hong Kong stock exchange under Lenovo Group Limited (HKSE: 992) (ADR: LNVGY).

This transformation together with Lenovo’s world-changing innovation is building a more inclusive, trustworthy, and smarter future for everyone, everywhere. To find out more visit www.lenovo.com, and read about the latest news via our StoryHub.

Essential Duties And Responsibilities


Develop, deploy, and support real-time, automated, scalable data streams from a variety of sources into the data lake or data warehouse.
Develop and implement data auditing strategies and processes to ensure data quality; identify and resolve problems associated with large scale data processing workflows; implement technical solutions to maintain data pipeline processes and troubleshoot failures
Collaborate with technology teams and partners to specify data requirements and provide access to data
Tune application and query performance using profiling tools and SQL or other relevant query language
Understand business, operations, and analytics requirements for data
Build data expertise and own data quality for assigned areas of ownership
Work with data infrastructure to triage issues and drive to resolution


Required Qualifications


Bachelor’s Degree in Data Science, Data Analytics, Information Management, Computer Science, Information Technology, related field, or equivalent professional experience
Overall experience should be more than 5+ years
3+ years of experience working with SQL and Talend.
3+ years of experience in implementing modern data architecture-based data warehouses
2+ years of experience working with data warehouses such as Snowflake BigQuery, or Redshift and understand data architecture design
Excellent software engineering and scripting knowledge
Strong communication skills (both in presentation and comprehension) along with the aptitude for thought leadership in data management and analytics
Expertise with data systems working with massive data sets from various data sources


Preferred Qualifications


Advanced knowledge of SQL, including the ability to write stored procedures, triggers, analytic/windowing functions, and tuning
Advanced knowledge of Snowflake, including the ability to write and orchestrate streams and tasks
Background in Big Data, non-relational databases, Machine Learning and Data Mining
Experience with cloud-based technologies like S3.
Experience with modern data platforms like Solr or ElasticSearch
Expertise in Data Quality and Data Governance


We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class.
Show more "
"Associate, Data Engineer",Bain & Company,"Gurugram, Haryana, India",Gurugram,2024-12-09,https://in.linkedin.com/jobs/view/associate-data-engineer-at-bain-company-3950872092?position=22&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=MT4ula%2B9BcRqEij0jOK6TA%3D%3D,"Who We Are

Bain & Company is a global management consulting that helps the world’s most ambitious change makers define the future. Across 65 offices in 40 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition and redefine industries. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry.

Who You’ll work with

BCN Labs is a Center of Excellence (CoE) functioning akin to a small R&D boutique startup within the Bain ecosystem, delivering end-to-end data driven client deployable solutions across a wide variety of sectors and industries. We work directly with other CoEs and Practices within Bain as part of the Expert Client Delivery system and interface with teams across the globe. We are first and foremost business thought partners working on intelligent ways of using analytical techniques and algorithms across the spectrum of disciplines that can enable building world-class solutions. Our goal is to build a disruptive high-impact business-enabled end-to-end analytical solutions delivery system across all verticals of Bain.

What You Will Do

We are seeking a strong candidate with experience in building applications around advanced analytics models, including front-end and back-end, and hosting said applications to fill an exciting Associate (AS) role within BCN Labs. The AS is expected to have a strong expertise in designing and building business-intuitive front-end interfaces and in setting up a robust back-end for our Machine Learning models and analytical solutions. The team has quite a few data scientists and the AS would have to interface with them on a day-to-day basis to enable the analytical solutions to be encapsulated within innovative, intuitive and seamless apps for end-clients and non-technical business leaders.

An AS is expected to have the ability to:

Collaborate with data scientists (who typically work with Python) to design and help build automated, deployable solutions using data orchestration tools (like AirFlow, etc.)
Develop and maintain front-end interfaces for data science applications, enhancing user experience and interaction with complex data sets.
Assist in the design and implementation of database solutions and data pipelines, supporting analytics and machine learning projects.
Lead the integration of Python-based models with databases via RESTful APIs, facilitating real-time data processing and analytics.
Employ Docker for application containerization and Git for version control, ensuring code quality and efficient team collaboration.
Successfully deploy multiple applications on AWS, optimizing cloud resources for cost-efficiency and scalability.
Contribute to the development of internal tools and platforms using technologies like Django and/or Streamlit to improve productivity and project delivery times.
Engage in continuous learning to stay ahead of emerging technologies and methodologies in data engineering and software development.

The AS is expected to have a knack for seeking out challenging problems and coming up with their own ideas which they will be encouraged to brainstorm with their peers and managers. They should be willing to learn new techniques and be open to solving problems with an interdisciplinary approach. They must have excellent coding skills and should demonstrate a willingness to be able to write modular, functional codes.

About You

A Masters or any other advanced degrees in a field linked to analytics such as Computer Science, Information Technology (IT), Operations Research, Engineering, etc.
If you are a Bachelors in any of the fields mentioned above, then we would seek a stellar academic record with proof of ability in not just implementing applications but also working through the end-to-end delivery cycle of analytical solutions including hosting
Excellent skills in HTML, CSS, JavaScript, SQL, Ajax, working with APIs – RESTful or otherwise, a coding language such as C or JAVA and an intermediate exposure to Python.
Having skills and exposure to Django and/or Streamlit would be given preference, although it is not a mandatory requirement.
(Good-to-have, but not necessary) Exposure to either AWS or Azure with some experience of deploying Python based solutions on these cloud platforms, Airflow, Snowflake, PySpark, Git, Docker, etc.
You will fit into our team-oriented structure with a college/hostel-style way of working, having the comfort of reaching out to anyone for support that can enable our clients better
At least 1 or 2 years of demonstrated abilities in data engineering and software development if you are a Masters degree holder; and, at least 3 years of a stellar career track record if you are a Bachelors degree holder
Demonstrated abilities to manage and deliver data-driven projects

 

What makes us a great place to work

We are proud to be consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked the #1 consulting firm on Glassdoor’s Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 12 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally. We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for diversity and inclusion, women, LGBTQ and parents..

 

 

Show more "
Data Engineer,Atlassian,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-engineer-at-atlassian-4269396866?position=23&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=ThILlCOJVM%2FoH8SbIb7IwQ%3D%3D,"Overview

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities

Atlassian is looking for a Data Engineer to join our Data Engineering team, responsible for building our data lake, maintaining big data pipelines / services and facilitating the movement of billions of messages each day. We work directly with the business stakeholders, platform and engineering teams to enable growth and retention strategies at Atlassian. We are looking for an open-minded, structured thinker who is passionate about building services/pipelines that scale.

On a typical day you will help our stakeholder teams ingest data faster into our data lake, you’ll find ways to make our data pipelines more efficient, or even come up ideas to help instigate self-serve data engineering within the company. You will be involved in strategizing measurement, collecting data, and generating insights.

Qualifications

Benefits & Perks

Atlassian offers a wide range of perks and benefits designed to support you, your family and to help you engage with your local community. Our offerings include health and wellbeing resources, paid volunteer days, and so much more. To learn more, visit go.atlassian.com/perksandbenefits .

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .
Show more "
Data Engineer,Persistent Systems,"Pune, Maharashtra, India",Pune,2025-07-22,https://in.linkedin.com/jobs/view/data-engineer-at-persistent-systems-4268543953?position=24&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=XPm%2BWccSoOAYJDiKABnMAw%3D%3D,"About Position:




We are seeking a skilled data professional with hands-on experience in ETL tools (e.g., DataStage) and a strong background in implementing large-scale Data Warehouse projects.




Role: Data Engineer
Location: All PSL Locations
Experience: 5+ Years
Job Type: Full Time Employment




What You'll Do:




Design, develop, and maintain advanced data pipelines and ETL processes using niche technologies.
Collaborate with cross-functional teams to understand complex data requirements and deliver tailored solutions.
Ensure data quality and integrity by implementing robust data validation and monitoring processes.
Optimize data systems for performance, scalability, and reliability.
Develop comprehensive documentation for data engineering processes and systems




Expertise You'll Bring:




Proficiency in programming languages, especially Python, for data manipulation and automation.
Expertise in SQL and a solid understanding of database management systems.
Familiarity with cloud platforms such as AWS, Azure, or GCP, and experience with data pipeline orchestration tools like Apache Airflow.
A proven track record of leading and mentoring high-performing teams, with excellent communication and interpersonal skills.
Strong analytical and problem-solving abilities, with a focus on delivering actionable insights from complex data sets.




Benefits:




Competitive salary and benefits package
Culture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications
Opportunity to work with cutting-edge technologies
Employee engagement initiatives such as project parties, flexible work hours, and Long Service awards
Annual health check-ups
Insurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parents




Inclusive Environment:




Persistent Ltd. is dedicated to fostering diversity and inclusion in the workplace. We invite applications from all qualified individuals, including those with disabilities, and regardless of gender or gender preference. We welcome diverse candidates from all backgrounds.




We offer hybrid work options and flexible working hours to accommodate various needs and preferences.
Our office is equipped with accessible facilities, including adjustable workstations, ergonomic chairs, and assistive technologies to support employees with physical disabilities.
If you are a person with disabilities and have specific requirements, please inform us during the application process or at any time during your employment. We are committed to creating an inclusive environment where all employees can thrive.




Our company fosters a values-driven and people-centric work environment that enables our employees to:




Accelerate growth, both professionally and personally
Impact the world in powerful, positive ways, using the latest technologies
Enjoy collaborative innovation, with diversity and work-life wellbeing at the core
Unlock global opportunities to work and learn with the industry’s best




Let’s unleash your full potential at Persistent




“Persistent is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind.”

Show more "
Data Engineer III [T500-19644],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-08,https://in.linkedin.com/jobs/view/data-engineer-iii-t500-19644-at-mcdonald-s-4282153228?position=25&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=DIuxT4tIr5782j4AjzG3lw%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Position Summary:

Looking to hire a Data Engineer at the G4 level who has a deep understanding of Data Product Lifecycle, Standards and Practices. Will be responsible for building scalable and efficient data solutions to support the Brand Marketing / Menu function with a specific focus on the Menu Data product and initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Leads initiatives to enable trusted Menu data, supports decision-making, and partners with business and technology teams to deliver scalable data solutions that drive insights into menu performance, customer preferences, and marketing effectiveness. Expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role within this domain.




Who we are looking for:

Primary Responsibilities:

Builds and maintains relevant and reliable Menu data products that support menu and marketing Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development engineering and Lead data engineering initiatives supporting Product Mix Analytics, ensuring timely and accurate delivery of marketing and menu-related products.
Work closely with the Product owner and help to define business rules that determines the quality of Menu datasets.
Drive and implement best practices for pipeline development, data governance, data security and quality across marketing and menu-related datasets.
Ensure scalability, maintainability, and quality of data systems powering menu item tracking, promotion data, and marketing analytics.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving Product Mix analytics needs.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Mentor and coach junior data engineers, particularly in areas related to menu item tracking, promotion data, and marketing analytics.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed




Skill:

Leads teams to drive scalable data engineering practices and technical excellence within the Menu Data ecosystem.
Bachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing
5+ years of professional experience in data engineering or related fields
Proficiency in Python, Java, or Scala for data processing and automation
Hands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)
Expert knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Proven ability to mentor team members and lead technical initiatives across multiple workstreams
Effective communication and stakeholder management skills to drive alignment and adoption of data engineering standards
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent collaboration skills to work effectively in cross-functional teams.




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Senior Data Engineer,Godrej & Boyce Mfg. Co. Ltd.,Mumbai Metropolitan Region,Mumbai Metropolitan Region,2025-08-06,https://in.linkedin.com/jobs/view/senior-data-engineer-at-godrej-boyce-mfg-co-ltd-4280754542?position=27&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=i6U42KbiisO7%2FCBmERKGig%3D%3D,"Digital




G&B is a diversified conglomerate with robust processes which is the foundation of seamless functioning. With the rapid growth of digital technologies, the Digital function aims to strengthen the digital ecosystem by collaborating with all stakeholders to achieve cost reduction, efficiency, productivity gains & superior customer experience.







Seeking Senior Data Engineer for our Data CoE team to help us implement advanced analytics solution on both on-premises and AWS environments in our Enterprise Data Lake.

The incumbent must have a sound understanding of databases, relational structures, dimensional data modelling, structured query language (SQL) skills, data warehouse and reporting techniques.




This position is responsible for the successful delivery of advanced analytics, ML/ AI solution for various use cases.




KRA

Identifying & driving Digital Transformation initiatives across G&B
Creation and implementing cloud-based architecture.
Creation and implementing of advanced analytics use cases.
Collaboration with internal and external teams
Create Presentation / Proposal on Value proposition




Job Description:




Identifying & driving Digital Transformation initiatives across G&B

Work with business teams to understand the business needs and how emerging technologies can be leveraged.
Ideation, conceptualization & analysis of Digital opportunities across the value chain including manufacturing, supply chain, workplace & customer experience.
Work closely with vendors for planning, executing & supporting Digital projects.
Working closely with end users and understand the use case in question.
Design and implement the use case.
Creation and implementing cloud-based architecture.
Hands on experience in Python programming and deploying ML models.




Creation and implementing of advanced analytics use cases.

Working closely with end users and understand the use case in question.
Design and implement the use case.




Collaboration with internal and external teams

Ability to collaborate on a team with infrastructure, BI report development and business analyst resources and clearly communicate solutions to both technical and non-technical team members. Design and implement the use case.
Coordinate with vendors and bridge the gap amongst teams.




Create Presentation / Proposal on Value proposition.

Create high quality presentations and value proposition to create stakeholder buy-in
Engage with internal stakeholders to evangelize the benefits of Digital technologies and drive cultural change.




Requisite Experience & Qualification:




Bachelor’ s in engineering

(Computer application/Information & Technology/ Electronics and Telecomm)




4 – 7 yrs of relevant experience

AWS Certified Database Specialty or

AWS Certified Data Analytics







Special Skills Required

Databricks:
AWS: S3, DMS, Redshift, EC2, VPC, Lambda, Delta Lake, CloudWatch etc.
Bigdata: Databricks, Spark, Glue and Athena
Expertise in Lake Formation, Python programming, Spark, Shell scripting
Minimum Bachelor’s degree with 5+ years of experience in designing, building, and maintaining Databricks and AWS data components
3+ years of experience in data component configuration, related roles and access setup
Expertise in Python programming
Knowledge in all aspects of DevOps (source control, continuous integration, deployments, etc.)
Strong hands-on coding skills in Python, processing large-scale data set and developing machine learning models. Experience programming in Python, R, and SQL.
Expertise in deploying use cases and AI/ML models in standalone and cloud based systems and services.
Knowledge in all aspects of DevOps (source control, continuous integration, deployments, etc.)
Comfortable working with DevOps: Jenkins, Bitbucket, CI/CD
Hands on ETL development experience, preferably using or SSIS.
SQL Server experience required
Strong analytical skills to solve and model complex business requirements.
Sound understanding of BI Best Practices/Methodologies, relational structures, dimensional data modelling, structured query language (SQL) skills, data warehouse and reporting techniques.
Comfortable with creating data models and visualization using Power BI







Preferred Skills Required

Good understanding of machine learning techniques and algorithms, including clustering, anomaly detection, optimization, neural network etc.
Comfortable in deploying AI/ML models (ML Ops) in standalone and cloud based systems and services.
Experience working in the SCRUM Environment.
Experience in Administration (Windows/Unix/Network/Database/Hadoop) is a plus.
Experience in SQL Server, SSIS, SSAS, SSRS
Ability to collaborate on a team with infrastructure, BI report development and business analyst resources, and clearly communicate solutions to both technical and non-technical team members.

Show more "
Data Engineer,bp,"Pune, Maharashtra, India",Pune,2025-07-04,https://in.linkedin.com/jobs/view/data-engineer-at-bp-4229448752?position=28&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=GdvoPN7%2FovRzbM4RFL9uGA%3D%3D,"Senior Data Engineer will be Responsible for delivering business analysis and consulting activities for the defined specialism using sophisticated technical capabilities, building and maintaining effective working relationships with a range of customers, ensuring relevant standards are defined and maintained, and implementing process and system improvements to deliver business value. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation!!!
Senior Data Engineer will work as part of an Agile software delivery team; typically delivering within an Agile Scrum framework. Duties will include attending daily scrums, sprint reviews, retrospectives, backlog prioritisation and improvements!
Will coach, mentor and support the data engineering squad on the full range of data engineering and solutions development activities covering requirements gathering and analysis, solutions design, coding and development, testing, implementation and operational support.
Will work closely with the Product Owner to understand requirements / user stories and have the ability to plan and estimate the time taken to deliver the user stories.
Proactively collaborate with the Product Owner, Data Architects, Data Scientists, Business Analysts, and Visualisation developers to meet the acceptance criteria
Will be very highly skilled and experienced in use of tools and techniques such as AWS Data Lake technologies, Redshift, Glue, Spark SQL, Athena




Years of Experience: 8- 12

Essential domain expertise:
Experience in Big Data Technologies – AWS, Redshift, Glue, Py-spark
Experience of MPP (Massive Parallel Processing) databases helpful – e.g. Teradata, Netezza
Challenges involved in Big Data – large table sizes (e.g. depth/width), even distribution of data
Experience of programming- SQL, Python
Data Modelling experience/awareness – Third Normal Form, Dimensional Modelling
Data Pipelining skills – Data blending, etc
Visualisation experience – Tableau, PBI, etc
Data Management experience – e.g. Data Quality, Security, etc
Experience of working in a cloud environment - AWS
Development/Delivery methodologies – Agile, SDLC.
Experience working in a geographically disparate team

Show more "
Data Engineer,Procter & Gamble,"Hyderabad, Telangana, India",Hyderabad,2025-08-07,https://in.linkedin.com/jobs/view/data-engineer-at-procter-gamble-4281678161?position=29&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=jF83GtFxWdzYTCnIktnO4A%3D%3D,"Job Location

HYDERABAD OFFICE INDIA

Job Description

Key Responsibilities:


Productionize pipelines for large, complex data sets which meet technical and business requirements.
Partner with data asset managers, architects, and development leads to ensure a sound technical solution.
Follow, and contribute to, coding standards and best practices to ensure pipelines and components are efficient, robust, cost effective and reusable.
Identify, design, and implement internal process improvements.
Optimize Spark jobs for performance and cost. Tune configurations, minimize shuffles, and leverage advanced techniques like broadcast joins, caching, and partitioning.
Ensure data quality, reliability, and performance by implementing best practices for data validation, monitoring, and optimization.
Monitor and troubleshoot data pipelines and workflows to ensure seamless operation.
Stay updated on the latest Databricks features, tools, and industry trends to continuously improve data engineering practices.
Strong understanding of distributed computing concepts and big data processing.
Excellent problem-solving skills and the ability to work collaboratively in a team environment.


Job Qualifications


Strong skills with Python, SQL, Delta Lake, Databricks, Spark/Pyspark, Github and Azure.
You will be expected to Attain and/or maintain technical certifications related to the role (Databricks, Azure)
Ability to use and implement CI/CD and associated tools such as Github Actions, SonarQube, Snyk
Familiarity or experience in one or more modern application development framework methods and tools (e.g. Disciplined Agile, Scrum).
Familiarity or experience with a range of data engineering best practices for development including query optimization, version control, code reviews, and documentation
The ability to build relationships and work in diverse, multidisciplinary teams
Excellent communication skills with business intuition and ability to understand business systems, versatility, and willingness to learn new technologies on the job


About Us

We produce globally recognized brands and we grow the best business leaders in the industry. With a portfolio of trusted brands as diverse as ours, it is paramount our leaders are able to lead with courage the vast array of brands, categories and functions. We serve consumers around the world with one of the strongest portfolios of trusted, quality, leadership brands, including Always®, Ariel®, Gillette®, Head & Shoulders®, Herbal Essences®, Oral-B®, Pampers®, Pantene®, Tampax® and more. Our community includes operations in approximately 70 countries worldwide. Visit http://www.pg.com to know more.

We are an equal opportunity employer and value diversity at our company. We do not discriminate against individuals on the basis of race, color, gender, age, national origin, religion, sexual orientation, gender identity or expression, marital status, citizenship, disability, HIV/AIDS status, or any other legally protected factor.

""At P&G, the hiring journey is personalized every step of the way, thereby ensuring equal opportunities for all, with a strong foundation of Ethics & Corporate Responsibility guiding everything we do.

All the available job opportunities are posted either on our website - pgcareers.com, or on our official social media pages, for the convenience of prospective candidates, and do not require them to pay any kind of fees towards their application.”

Job Schedule

Full time

Job Number

R000135017

Job Segmentation

Experienced Professionals
Show more "
Software Developer/ Engineer -1,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-07-02,https://in.linkedin.com/jobs/view/software-developer-engineer-1-at-nxtwave-4258614545?position=30&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=nLYRzfT4B8gEq2MzcXhAVQ%3D%3D,"Job Title: Software Developer/ Engineer -1

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
Data Engineer,PwC Acceleration Centers,"Hyderabad, Telangana, India",Hyderabad,2025-08-06,https://in.linkedin.com/jobs/view/data-engineer-at-pwc-acceleration-centers-4280801035?position=31&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=QVdIJO4MUdMzcAHI0mIfeQ%3D%3D,"Palantir Data Engineer – Senior Associate (5–9 Years)

Our Analytics & Insights Managed Services team brings a unique combination of industry expertise, technology, data management and managed-services experience to create sustained outcomes for our clients and improve business performance. We empower companies to transform their approach to analytics and insights while building your skills in exciting new directions. Have a voice at our table to help design, build and operate the next generation of software and services leveraging the power of Palantir.

Job Requirements and Preferences

Basic Qualifications

Minimum Degree Required:

Bachelor's degree in computer science, Data Engineering, Data Science, Information Systems, or a related technical field

Minimum Years of Experience:

5–9 years of hands-on data engineering experience, including 2+ years working with Palantir Foundry or Gotham

Preferred Qualifications

Degree Preferred:

Master's degree in data science, Analytics, Computer Science, Information Systems, or related discipline

Preferred Fields of Study:

Data Processing/Analytics/Science, Management Information Systems, Software Engineering

Preferred Knowledge & Skills

As a Senior Associate, you architect, develop, and optimize end-to-end data solutions on Palantir platforms, while mentoring junior teammates. You demonstrate deep technical acumen across:

Palantir Platform & Data Modeling

– Design and maintain Foundry ontologies, datasets, and code workbooks

– Build reusable transforms and data models that underpin business workflows

Cloud-Scale Data Engineering

– Develop and optimize ETL/ELT pipelines in Python (PySpark) and SQL

– Integrate diverse sources (batch, streaming, JDBC/ODBC, REST/Kafka/Kinesis) into Foundry

Performance & Scalability

– Tune high-volume, latency-sensitive data feeds for both batch and event-driven patterns

– Employ caching, partitioning, and parallelization best practices

DevOps & Automation

– Implement CI/CD pipelines with Git, Docker, Kubernetes, and infrastructure-as-code

– Automate testing, deployment, and versioning of Foundry code

Data Governance & Quality

– Leverage Foundry’s built-in lineage, access controls, and monitoring capabilities

– Collaborate with data stewards to define quality metrics and enforce policies

Cloud & Infrastructure

– Hands-on experience with AWS, Azure or GCP services (e.g., S3, Glue, Dataflow) supporting Palantir deployments

– Understand network security, IAM, and multi-cloud/hybrid architectures

Collaboration & Mentorship

– Partner with data scientists, analysts, and architects to translate requirements into robust solutions

– Coach junior engineers, share best practices, and drive continuous improvement

Communication & Delivery

– Present technical designs and performance analyses to senior stakeholders

– Contribute accelerators, playbooks, and internal tools to accelerate client delivery

Show more "
Software Engineer,Intuit,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-at-intuit-4282496088?position=33&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=xPBbGH%2F0LpUt5Z8TVRoc4A%3D%3D,"Overview

Intuit is a mission-driven, global financial platform company that gives everyone the opportunity to prosper. With products like TurboTax, QuickBooks , we’re using technology to build solutions to challenging financial problems for millions of people around the world.

Our mission is to significantly enhance software quality across Intuit, improving the end-customer experience and accelerating our feature delivery velocity. We are building the frameworks, infrastructure, and guidance necessary to improve our current quality posture. This team focuses on four key pillars: Test Authoring, Test Management, Test Execution, and Test Reporting, with an emphasis on improving quality through end-to-end (E2E) and integration testing.

We are seeking a Software Engineer 2 to join our team, playing a pivotal role in building and evolving the core infrastructure and tooling that will drive our quality improvement initiatives. You will contribute to creating a ""paved road"" for comprehensive, user-flow centric testing, enabling developers to ship rapidly with confidence.

Responsibilities

Design and Implement Quality Infrastructure: Partner effectively with all team members to build solutions that support various testing frameworks (e.g., Playwright, Cypress, Selenium, Karate) and integrate them into a unified system.
Enhance Test Management and Reporting: Build capabilities for a comprehensive test registry that automatically captures integration and E2E tests, linking them to assets, features, and capabilities. Implement standardized reporting mechanisms to provide real-time visibility into test coverage, health, and flakiness.
Improve Test Authoring and Maintenance: Contribute to the development of tools and practices that simplify the creation and updating of test cases, potentially leveraging AI-assisted test maintenance to adapt to UI and logic changes.
Optimize Test Execution: Design and implement intelligent automated test selection, parallelized test execution, and real-time feedback loops to improve release velocity.
Technical Leadership: Provide technical guidance and mentorship to other engineers, contributing to the overall technical direction of the quality initiative.
Drive Standardization and Best Practices: Champion consistent coding practices for tests, advocating for and implementing a ""paved road"" for integration and E2E testing across various organizations (CG, Fintech, Mailchimp, GBSG).
Troubleshoot and Resolve Issues: Investigate and resolve complex issues related to test failures, flakiness, and environment conflicts.




Qualifications

2+ years of experience working in an enterprise hosting complex systems
BS/MS in computer science or equivalent work experience
Proficiency in at least one Programming language e.g. Go, Java etc.
Strong communication and collaboration skills, with the ability to influence and drive change across multiple teams and organizations.
Proficiency in designing, implementing, and maintaining automated test frameworks and tools.
Experience with continuous integration/continuous delivery (CI/CD) pipelines and quality gates.
Demonstrated ability to identify and solve complex technical problems related to test flakiness, performance, and reliability.
Experience with cloud platforms (e.g., AWS) and related testing services at scale is a plus.

Show more "
Data Engineer,LTIMindtree,"Pune, Maharashtra, India",Pune,2025-07-29,https://in.linkedin.com/jobs/view/data-engineer-at-ltimindtree-4273580862?position=34&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=PIW1jX2NgIRPAX8DnWzxkw%3D%3D,"Greeting from LTIMINDTREE!!

Experiences: 5 yrs-8yrs

Location: PAN India

If so, I’d be happy to coordinate. please share your updated resume to woonna.sowmya@ltimindtree.com

Show more "
Software Engineer,Microsoft,"Bengaluru, Karnataka, India",Bengaluru,2025-07-29,https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4277621673?position=35&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=VZEJk5XNt61mdsnMqmb6bw%3D%3D,"The Dynamics 365 Business Central team within Microsoft is dedicated to revolutionizing business operations with a suite of comprehensive business management applications. As we navigate this era of digital transformation, we focus on delivering seamless experiences and empowering organizations with cutting-edge solutions.

As Software Engineer within the Dynamics 365 Business Central team, you are actively involved in developing and maintain a highly scalable world class service tailored products to support diverse business functions that incorporate latest generative AI innovation across various business processes.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

Responsibilities


Design, code, test and deploy robust, scalable, and high-performance full-stack features for our web-based business management platform using C#, .NET, Azure and modern web frameworks
Integrate generative AI and LLMs to build intelligent, next generation user experiences. This includes designing, implementing and refining prompts to ensure optimal performance relevance.
Collaborate closely with program managers, UX designers and other engineers to translate complex business requirements into well-architected technical solutions.
Actively participate in the team’s agile processes, contributing to planning, design sessions and sprint retrospectives.
Enhance system quality by conducting code reviews, writing unit tests, and developing automation to ensure features are reliable and maintainable.
Contribute to the health of our live service by monitoring performance, investigating and resolving production issues, and participating in an on-call rotation.


Qualifications

Required qualifications:


Bachelor's Degree in Computer Science, Engineering, or a related field, or equivalent industry experience.
1-3 yrs professional experience in full-stack software development, with a proven track record of shipping commercial software.
Experience building and deploying scalable web applications using modern front-end frameworks like React, Angular etc.
Hands on experience coding in an object-oriented language such as C#, TypeScript or similar.
Strong problem-solving skills and the ability to work collaboratively in an agile team environment.
Excelent written and verbal communication skils with the ability to clearly articulate complex technical topics and discuss requirements with stakeholders.


Preferred Qualifications


Demonstrated experience developing solutions on a cloud platform like Microsoft Azure, AWS or GAE
Proficient with relational databases, SQL and data modeling
Previous experience working with complex, data-intensive business applications
Familiarity with LLM models, prompt engineering, and Agentic workflows.
Familiar with CI/CD, automated testing, and modern DevOps practices.


Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
Data Engineer,Atlassian,Greater Kolkata Area,Greater Kolkata Area,2025-08-05,https://in.linkedin.com/jobs/view/data-engineer-at-atlassian-4266891295?position=36&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=QZ%2BJ1u1dqI0SqC0b%2Fm8NdQ%3D%3D,"Overview

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities

Atlassian is looking for a Data Engineer to join our Data Engineering team, responsible for building our data lake, maintaining big data pipelines / services and facilitating the movement of billions of messages each day. We work directly with the business stakeholders, platform and engineering teams to enable growth and retention strategies at Atlassian. We are looking for an open-minded, structured thinker who is passionate about building services/pipelines that scale.

On a typical day you will help our stakeholder teams ingest data faster into our data lake, you’ll find ways to make our data pipelines more efficient, or even come up ideas to help instigate self-serve data engineering within the company. You will be involved in strategizing measurement, collecting data, and generating insights.

Qualifications

Benefits & Perks

Atlassian offers a wide range of perks and benefits designed to support you, your family and to help you engage with your local community. Our offerings include health and wellbeing resources, paid volunteer days, and so much more. To learn more, visit go.atlassian.com/perksandbenefits .

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .
Show more "
Senior Data Engineer II,MakeMyTrip,"Bengaluru, Karnataka, India",Bengaluru,2025-07-22,https://in.linkedin.com/jobs/view/senior-data-engineer-ii-at-makemytrip-4271175349?position=37&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=W0OpKmp3sxfcqOlStLXToQ%3D%3D,"Position: Senior Data Engineer II

Experience: Must have 4+ years of experience

About Role:

We are looking for experienced Data engineers with excellent problem-solving skills to develop machine-learning powered Data Products design to enhance customer experiences.

About us:

Nurtured from the seed of a single great idea - to empower the traveler - MakeMyTrip went on to pioneer India’s online travel industry Founded in the year 2000 by Deep Kalra, MakeMyTrip has since transformed how India travels. One of our most memorable moments has been to ring the bell at NASDAQ in 2010.

Post-merger with the Ibibo group in 2017, we created a stronger identity and traction for our portfolio of brands, increasing the pace of product and technology innovations. Ranked amongst the LinkedIn Top 25 companies 2018.

GO-MMT is the corporate entity of three giants in the Online Travel Industry—Goibibo, MakeMyTrip and RedBus. The GO-MMT family celebrates the compounded strengths of their brands. The group company is easily the most sought after corporate in the online travel industry.

About the team:

MakeMyTrip as India’s leading online travel company and provides petabytes of raw data which is helpful for business growth, analytical and machine learning needs.

Data Platform Team is a horizontal function at MakeMyTrip to support various LOBs (Flights, Hotels, Holidays, Ground) and works heavily on streaming datasets which powers personalized experiences for every customer from recommendations to in-location engagement.

There are two key responsibilities of Data Engineering team:

One to develop the platform for data capture, storage, processing, serving and querying.
Second is to develop data products starting from;

o personalization & recommendation platform

o customer segmentation & intelligence

o data insights engine for persuasions and

o the customer engagement platform to help marketers craft contextual and personalized campaigns over multi-channel communications to users

We developed Feature Store, an internal unified data analytics platform that helps us to build reliable data pipelines, simplify featurization and accelerate model training. This enabled us to enjoy actionable insights into what customers want, at scale, and to drive richer, personalized online experiences.

Technology experience:

Extensive experience working with large data sets with hands-on technology skills to design and build robust data architecture
Extensive experience in data modeling and database design
At least 4+ years of hands-on experience in Spark/BigData Tech stack
Stream processing engines – Spark Structured Streaming/Flink
Analytical processing on Big Data using Spark
At least 4+ years of experience in Java/Scala
Hands-on administration, configuration management, monitoring, performance tuning of Spark workloads, Distributed platforms, and JVM based systems
At least 2+ years of cloud deployment experience – AWS | Azure | Google Cloud Platform
At least 2+ product deployments of big data technologies – Business Data Lake, NoSQL databases etc
Awareness and decision making ability to choose among various big data, no sql, and analytics tools and technologies
Should have experience in architecting and implementing domain centric big data solutions
Ability to frame architectural decisions and provide technology leadership & direction
Excellent problem solving, hands-on engineering, and communication skills

Show more "
Junior Data Engineer work location : PAN India,Capgemini Engineering,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/junior-data-engineer-work-location-pan-india-at-capgemini-engineering-4277397066?position=38&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=lh8TypTwEbxb9JvsOuV%2BOg%3D%3D,"Job Title: Data Engineer




Company Overview: Capgemini Engineering is a forward-thinking organization dedicated to leveraging data-driven insights to propel our business strategies. We are currently seeking a motivated Junior Data Engineer with proficiency in Python and a keen interest in working with Cognite Data Fusion to join our dynamic team.




Position Overview: As a Junior Data Engineer, you will be instrumental in designing, developing, and maintaining scalable data pipelines and infrastructure. Your primary focus will be on integrating and optimizing data workflows using Cognite Data Fusion and Python, thereby facilitating seamless data accessibility and analysis across the organization.




Key Responsibilities:

Data Pipeline Development: Design, implement, and optimize end-to-end data pipelines for ingesting, processing, and transforming large volumes of structured and unstructured data.
Data Integration: Utilize Cognite Data Fusion to automate and scale the contextualization of various data sources, ensuring efficient data integration and accessibility.
Programming: Develop robust ETL processes and data workflows using Python, ensuring code quality, scalability, and maintainability.​
Collaboration: Work closely with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand data requirements and deliver effective solutions.​
Data Quality Assurance: Implement data validation and quality checks to ensure accuracy, consistency, and reliability of data.​
Documentation: Maintain comprehensive documentation of data processes, workflows, and system architectures.​




Bachelor’s degree in Computer Science, Information Technology, Engineering, or a related field.​
Proficiency in Python programming language.​
Familiarity with data integration platforms
Understanding of data modelling, database design, and data warehousing concepts.​
Experience with SQL and working with relational databases.​
Basic knowledge of cloud platforms such as AWS or Azure is a plus.​
Strong problem-solving skills and attention to detail.​
Excellent communication and collaboration abilities.​




Preferred Qualifications:




Experience with data pipeline and workflow management tools.​
Knowledge of big data technologies and frameworks.
Familiarity with data visualization tools and techniques (Grafana is a plus).

Show more "
Data Engineer,LTIMindtree,"Bengaluru, Karnataka, India",Bengaluru,2025-07-29,https://in.linkedin.com/jobs/view/data-engineer-at-ltimindtree-4273576354?position=39&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=dpWKD%2B%2BHZ1d7JVadzEMpjw%3D%3D,"Greeting from LTIMINDTREE!!

Experiences: 5 yrs-8yrs

Location: PAN India

If so, I’d be happy to coordinate. please share your updated resume to woonna.sowmya@ltimindtree.com

Show more "
Data Engineer 2,Intuit,"Bengaluru, Karnataka, India",Bengaluru,2025-07-29,https://in.linkedin.com/jobs/view/data-engineer-2-at-intuit-4273704796?position=40&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=B0I4WqBwtGaW2y3%2FuoKcLw%3D%3D,"Overview

Come join the ""Unified Ingestion Platform (UIP)"" under A2D org as a ""Data Engineer 2"". UIP is a designated paved platform at Intuit for data ingestion/movement from one hosting location to another. As a Data Engineer, you will be working on cutting edge technologies to create a world class data movement platform. This is the place to be if it is your passion to build highly reliable and scalable ingestion capabilities on cloud and push the boundaries of automation!

What you'll bring


BE/B.Tech/MS in Computer Science (or equivalent)
2 to 5 years of experience in a Data Engineering role with good knowledge of Software engineering.
Strong CS fundamentals including data structures, algorithms and distributed systems.
Demonstrate robust problem solving, decision-making, and analytical skills.
Expert level experience in designing high throughput data solutions / services.
Hands-on experience on AWS (EC2, EMR, S3, Athena, EMR, Kinesis, Lambda etc). Knowledge of GCP(DataProc, GCS, BigQuery etc) is a plus.
Strong programming knowledge in one of the languages - Java, Scala or Python.
Expert level experience in developing data pipelines/solutions using processing engines like Hive, Spark,Spark Streaming, Flink etc
Good knowledge on Lake House architecture for data persistence. DeltaLake, Iceberg or Hudi knowledge isa plus
Adequate experience with RESTful web services and micro service architectures


How you will lead


Design and build capabilities to support Batch and Realtime ingestion at scale using open source technologies which are fault tolerant.
Design solutions that involve complex, multi-system and multi cloud integration, possibly across BUs or domains
End to end engineering – design, development, testing, deployment and operations
Ability to work in a dynamic environment, adapt to business requirements using Agile methodologies and DevOps culture
Conducts code reviews to ensure code quality, consistency and best practices adherence.
Conducts quick Proof of Concept (POCs) for feasibility studies and take it to the prod
Lead by example, demonstrating best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting, and incident response
Show more "
Data Engineer-Databricks,Oracle,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/data-engineer-databricks-at-oracle-4278235356?position=41&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=b%2BvBVqR8cXlc0a3R%2BGQuQw%3D%3D,"Location- Mumbai, Pune, Bangalore and Chennai




Senior Data Engineer Databricks (Azure/AWS)




Role Overview:




We are looking for a hands-on Senior Data Engineer experienced in migrating and building large-scale data pipelines on Databricks using Azure or AWS platforms. The role will focus on implementing batch and streaming pipelines, applying the bronze-silver-gold data lakehouse model, and ensuring scalable and reliable data solutions.




Required Skills and Experience:




6+ years of hands-on data engineering experience, with 2+ years specifically working on Databricks in Azure or AWS.
Proficiency in building and optimizing Spark pipelines (batch and streaming).
Strong experience implementing bronze/silver/gold data models.
Working knowledge of cloud storage systems (ADLS, S3) and compute services.
Experience migrating data from RDBMS (Oracle, SQL Server) or Hadoop ecosystems.
Familiarity with Airflow, Azure Data Factory, or AWS Glue for orchestration.
Good scripting skills (Python, Scala, SQL) and version control (Git).

Preferred Qualifications:

Databricks Certified Data Engineer Associate or Professional.
Experience with Delta Live Tables (DLT) and Databricks SQL.
Understanding of cloud security best practices (IAM roles, encryption, ACLs).




Key Responsibilities:




Design, develop, and operationalize scalable data pipelines on Databricks following medallion architecture principles.
Migrate and transform large data volumes from traditional on-prem systems (Oracle, Hadoop, Exadata) into cloud data platforms.
Develop efficient Spark (PySpark/Scala) jobs for ingestion, transformation, aggregation, and publishing of data.
Implement data quality checks, error handling, retries, and data validation frameworks.
Build automation scripts and CI/CD pipelines for Databricks workflows and deployment.
Tune Spark jobs and optimize cost and performance in cloud environments.
Collaborate with data architects, product owners, and analytics teams




Attributes for Success:




Strong analytical and problem-solving skills.
Attention to scalability, resilience, and cost efficiency.
Collaborative attitude and passion for clean, maintainable code.

Show more "
Software Engineer,Microsoft,"Noida, Uttar Pradesh, India",Noida,2025-07-25,https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4275645969?position=42&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=p%2B2J9YkfIv9imOoPsxkznw%3D%3D,"On Team Xbox, we aspire to empower the world’s 3 billion gamers to play the games they want, with the people they want, anywhere they want. Gaming, the largest and fastest growing category in media & entertainment, represents an important growth opportunity for Microsoft. We are leading with innovation, as highlighted by bringing Xbox to new devices with Cloud Gaming, bringing the Game Pass subscription to PC, and our recent acquisition of Activision Blizzard King creating exciting new possibilities for players.

The Xbox Experiences and Platforms team is home to the engineering work that makes this vision possible, building the developer tools and services that enable game creators to craft incredible experiences, the commerce systems that connect publishers with their audience and help gamers engage with their next favorite games, the platforms on which those games play at their best, and the experiences that turn every screen into an Xbox.

Responsibilities

Our Developer team is looking for a Software Engineer I to join us in our journey to reimagine how game creators bring content to life—working together to transform the way developers onboard, publish, and receive support across our platforms. Our mission is to simplify and accelerate the creator journey by building intuitive tools, resilient services, and responsive support systems that empower creators—from indie studios to AAA publishers—to move faster, with greater confidence and less friction.

Responsibilities include: 


Working on products and services leveraging the latest technologies from Microsoft.
Partner with experts across geographic and organizational boundaries to make impactful changes. 
Adhere to modern engineering principles and practices, code reviews, and project management.
Take on challenges of working with well-established, large-scale systems. 
Participate in governance activities, manage technical tasks, and ensure quality assurance through automated testing and integration validation.
Build functional and technical documentation, write unit and integration tests, and update Continuous Integration and Continuous Deliver (CI/CD) pipelines.


Qualifications

Required Qualifications:


Master's/Bachelor's Degree in Computer Science or related technical field AND 1-3 year(s) technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python OR equivalent experience.


Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
"Data Engineer, Product Analytics",Meta,"Bengaluru, Karnataka, India",Bengaluru,2025-08-12,https://in.linkedin.com/jobs/view/data-engineer-product-analytics-at-meta-4243744751?position=43&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=05jKed9QUHG53Re1GLZ8Xw%3D%3D,"As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
Define and manage Service Level Agreements for all data sets in allocated areas of ownership
Solve challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
Improve logging
Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
Influence product and cross-functional teams to identify data opportunities to drive impact


Minimum Qualifications:


Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)


Preferred Qualifications:


Master's or Ph.D degree in a STEM field


About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.
Show more "
Data Engineer,Persistent Systems,"Noida, Uttar Pradesh, India",Noida,2025-08-08,https://in.linkedin.com/jobs/view/data-engineer-at-persistent-systems-4279875833?position=44&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=JI0SYVUEPxDvLp49GoBqIg%3D%3D,"About Position:




We are looking for an experienced Data Engineer to join our growing data team. The ideal candidate will have a strong background in building and optimizing data pipelines, data architecture, and data sets. You will work closely with data scientists, analysts, and software engineers to support data initiatives and ensure optimal data delivery architecture is consistent throughout ongoing projects.




Role: Data Engineer
Location: Noida
Experience: 5+ years
Job Type: Full Time Employment




What You'll Do:




Design and develop ETL/ELT pipelines using Azure Data Factory, Databricks, and other Azure services.
Build and maintain data lakes, data warehouses, and real-time data streaming solutions.
Write efficient and reusable Python scripts for data transformation, automation, and orchestration.
Optimize and manage SQL queries and database performance across Azure SQL, Synapse, and other platforms.
Collaborate with data scientists, analysts, and business stakeholders to deliver actionable insights.
Implement CI/CD pipelines for data workflows and ensure robust data governance and security.
Monitor and troubleshoot data pipelines and ensure high availability and reliability.




Expertise You'll Bring:




5+ years of experience in Microsoft Azure Cloud, Azure Data Factory, Data Bricks, Spark, Scala/Python, ADO.
5+ years of experience working with Relational database (SQL, Oracle)
5+ years of experience working with Provider and Payer data
5+ years of combined experience in data engineering, ingestion, normalization, transformation, aggregation, structuring, and storage
5+ years of combined experience working with industry standard relational, dimensional or non-relational data storage systems
5+ years of experience in designing ETL/ELT solutions using tools like Informatica, DataStage, SSIS , PL/SQL, T-SQL, etc.
5+ years of experience in managing data assets using SQL, Python, Scala, VB.NET or other similar querying/coding language
3+ years of experience working with healthcare data or data to support healthcare organizations
Working knowledge of various tools such as ALM, Rally etc.
Experience in US healthcare




Inclusive Environment:




Persistent Ltd. is dedicated to fostering diversity and inclusion in the workplace. We invite applications from all qualified individuals, including those with disabilities, and regardless of gender or gender preference. We welcome diverse candidates from all backgrounds.




We offer hybrid work options and flexible working hours to accommodate various needs and preferences.
Our office is equipped with accessible facilities, including adjustable workstations, ergonomic chairs, and assistive technologies to support employees with physical disabilities.
If you are a person with disabilities and have specific requirements, please inform us during the application process or at any time during your employment. We are committed to creating an inclusive environment where all employees can thrive.

Our company fosters a values-driven and people-centric work environment that enables our employees to:




Accelerate growth, both professionally and personally
Impact the world in powerful, positive ways, using the latest technologies
Enjoy collaborative innovation, with diversity and work-life wellbeing at the core
Unlock global opportunities to work and learn with the industry’s best




Let’s unleash your full potential at Persistent




“Persistent is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind.”

Show more "
"Software Engineer, Data Engineer II",DoorDash,"Pune, Maharashtra, India",Pune,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-data-engineer-ii-at-doordash-4123642935?position=45&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=Pxz3s6CQjP90eWBnujliBw%3D%3D,"About the Team

Data is at the foundation of DoorDash success. The Data Engineering team builds database solutions for various use cases including reporting, product analytics, marketing optimization and financial reporting. Team serves as the foundation for decision-making at DoorDash.

About the Role

DoorDash is looking for a Software Engineer, Data to be a technical powerhouse to help us scale our data reliability, data infrastructure, automation and tools to meet growing business needs.

You're excited about this opportunity because you will…


Own critical data systems that support multiple products/teams
Develop, implement and enforce best practices for data infrastructure and automation
Design, develop and implement large scale, high volume, high performance data models and pipelines for Data Lake and Data Warehouse
Improve the reliability and scalability of our Ingestion, data processing, ETLs, Reporting tools and data ecosystem services
Manage a portfolio of data products that deliver high-quality, trustworthy data
Help onboard and support other engineers as they join the team


We're excited about you because…


3+ years of professional experience
3+ years experience working in data platform and data engineering or a similar role
Proficiency in programming languages such as Python/Kotlin/Scala
3+ years of experience in ETL orchestration and workflow management tools like Airflow
Expert in database fundamentals, SQL, data reliability practices and distributed computing
3+ years of experience with the Distributed data/similar ecosystem (Spark, Presto) and streaming technologies such as Kafka/Flink/Spark Streaming
Excellent communication skills and experience working with technical and non-technical teams and knowledge of reporting tools
Comfortable working in fast paced environment, self starter and self organizing
Ability to think strategically, analyze and interpret market and consumer information
You must be located near one of our engineering hubs indicated above


Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

If you need any accommodations, please inform your recruiting contact upon initial connection.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

If you need any accommodations, please inform your recruiting contact upon initial connection.

We use Covey as part of our hiring and/or promotional process for jobs in certain locations.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: https://getcovey.com/nyc-local-law-144

To request a reasonable accommodation under applicable law or alternate selection process, please inform your recruiting contact upon initial connection.
Show more "
"Software Engineer, Data Tools",DoorDash,"Pune, Maharashtra, India",Pune,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-data-tools-at-doordash-4084261319?position=46&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=YYjQkmfdwqPm4JfpvxEi3w%3D%3D,"About the Team

Come help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash's three-sided marketplace of consumers, merchants, and dashers.

About the Role

The Data Tools mission is to build robust data platforms and establish policies that guarantee the analytics data is of high quality, easily accessible/cataloged, and compliant with financial and privacy regulations, fostering trust and confidence in our data-driven decision-making process.

We are building the Data Tools team in India and you will have an opportunity to be part of a founding team with a greater opportunity for impact where you can help grow the team and shape the roadmap for the data platform at DoorDash. You will report directly to the Data Tools Engineering Manager.



You're excited about this opportunity because you will…


Work on building a data discovery platform, privacy frameworks, unified access control frameworks, and data quality platform to enable data builders at DoorDash to deliver high-quality and trustable data sets and metrics
Help accelerate the adoption of the data discovery platform by building integrations across online, analytics platforms and promoting self-serve
Come up with solutions for scaling data systems for various business needs
Collaborate in a dynamic startup environment


We're excited about you because…


B.E./B.Tech., M.E./M.Tech, or Ph.D. in Computer Science or equivalent
2+ years of experience with CS fundamental concepts and experience with at least one of the programming languages of Scala, Java, and Python
Prior technical experience in Big Data infrastructure & governance - you've built meaningful pieces of data infrastructure. Bonus if those were open-sourced technologies like DataHub, Spark, Airflow, Kafka, Flink
Experience improving efficiency, scalability, and stability of data platforms


We use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on June 20, 2024.

Please see the independent bias audit report covering our use of Covey here.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

If you need any accommodations, please inform your recruiting contact upon initial connection.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

If you need any accommodations, please inform your recruiting contact upon initial connection.

We use Covey as part of our hiring and/or promotional process for jobs in certain locations.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: https://getcovey.com/nyc-local-law-144

To request a reasonable accommodation under applicable law or alternate selection process, please inform your recruiting contact upon initial connection.
Show more "
Data Engineer,Deccan AI,"Bengaluru, Karnataka, India",Bengaluru,2025-07-24,https://in.linkedin.com/jobs/view/data-engineer-at-deccan-ai-4275356479?position=47&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=nadBsVD8R8E9xVnqJmbj%2Fw%3D%3D,"About Soul AI Pods

Deccan AI is a pioneering company founded by IIT Bombay and IIM Ahmedabad alumni, with a strong founding team from top tier institutes like IITs, NITs, and BITS.







We’re hiring for our client servicing arm Soul AI. Soul AI has a talent network, known as Soul AI Pods, under which highly skilled & vetted tech talent gets the opportunity to work with top-tier global tech companies. Our client list includes tech giants like Google & Snowflake.

Read more about here

Responsibilities

Design, build, and maintain ETL/ELT pipelines using tools like Airflow, DBT, or Spark
Develop and optimize data lakes, data warehouses, and streaming pipelines
Ensure data quality, reliability, and lineage across sources and pipelines
Integrate structured and unstructured data from internal and third-party APIs
Collaborate with ML teams to deliver production-ready feature pipelines, labeling data, and dataset versioning
Implement data governance, security, and access control policies




Required Skills




Strong SQL skills including analytical queries, CTEs, window functions, and query optimization
Proficient in Python for data manipulation and scripting using libraries like Pandas and NumPy
Experience with ETL orchestration tools such as Airflow, Prefect, or Luigi
Hands-on with batch and streaming data processing using Spark, Kafka, or Flink
Familiarity with data lakes and warehouses (S3, BigQuery, Redshift, Snowflake) and schema design
Bonus: experience with DBT, data validation, MLOps integration, or compliance-aware data workflows




Application & Other Details

To apply, fill the Soul AI Pods Interest Form
You will be invited for selection process → R1: Test, R2: AI Interview, R3: 1:1 Interview
We are hiring for full-time or long Contract (40 hrs/week) hybrid roles
We are hiring across different seniority levels

You will work on a key client project (Top-tier tech consulting firm)

Show more "
Software Engineer,Flipkart,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-at-flipkart-4282735345?position=48&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=DjHgvU1tmG8EWo7d8eP3tg%3D%3D,"About Flipkart

Flipkart is India’s largest e-commerce marketplace with a registered customer base of over 100 million. In the 10 years since it started, Flipkart has come to offer over 80 million products across 80+ categories including Smartphones, Books, Media, Consumer Electronics, Furniture, Fashion and Lifestyle. Launched in October 2007, Flipkart is known for its path-breaking services like Cash on Delivery, No cost EMI and a 10-day replacement policy. Flipkart was the pioneer in offering services like In-a-Day Guarantee (65 cities) and Same-Day-Guarantee (13 cities) at scale. With over 1,00,000 registered sellers, Flipkart has redefined the way brands and MSME’s do business online.




The Role

The Software Development Engineer's core responsibilities include working on highly-maintainable and unit tested software components/system that address real world problems. You will be working in a fast paced and agile work environment delivering quality solutions that have immediate business impact.




You (Must Have)

• Minimum 0.6 year of experience and Less than 2 years of experience

• Strong problem solving skills

• Good understanding of data structures & algorithms and their space & time complexities

• Strong hands-on and practical working experience with at least one programming language:

• C/Java/C++

• Excellent coding skills – should be able to convert design into code fluently

• Strong technical aptitude and a good knowledge of CS fundamentals

• Hands-on experience working with Databases and Linux platform is a plus

• B Tech in Computer Science or equivalent from a reputed college




Your Array (Nice to Haves):

You will assume complete ownership of the projects you deliver while collaborating with technical and non-technical stakeholders on all elements of the development process. You are expected to demonstrate good learnability and adopt technologies that help build large scale, performant, reliable and sustainable systems.

Show more "
Data Engineer (Azure),PwC Acceleration Centers,"Bengaluru, Karnataka, India",Bengaluru,2025-07-18,https://in.linkedin.com/jobs/view/data-engineer-azure-at-pwc-acceleration-centers-4268748896?position=49&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=FqjCDDjpFD1%2F9qYgsbX5CA%3D%3D,"Role: Senior Associate

Tower: Data, Analytics & Specialist Managed Service

Experience: 6 - 10 years

Key Skills: Azure

Educational Qualification: BE / B Tech / ME / M Tech / MBA

Work Location: Bangalore

Job Description

As a Senior Associate, you will work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:

Use feedback and reflection to develop self-awareness, personal strengths, and address development areas.
Flexible to work in stretch opportunities/assignments.
Demonstrate critical thinking and the ability to bring order to unstructured problems.
Ticket Quality and deliverables review, Status Reporting for the project.
Adherence to SLAs, experience in incident management, change management and problem management.
Seek and embrace opportunities which give exposure to different situations, environments, and perspectives.
Use straightforward communication, in a structured way, when influencing and connecting with others.
Able to read situations and modify behavior to build quality relationships.
Uphold the firm's code of ethics and business conduct.
Demonstrate leadership capabilities by working, with clients directly and leading the engagement.
Work in a team environment that includes client interactions, workstream management, and cross-team collaboration.
Good team player, take up cross competency work and contribute to COE activities.
Escalation/Risk management.

Position Requirements:

Required Skills:

Azure Cloud Engineer:

Job description:

Candidate is expected to demonstrate extensive knowledge and/or a proven record of success in the following areas:

Should have minimum 6 years hand on experience building advanced Data warehousing solutions on leading cloud platforms.
Should have minimum 3-5 years of Operate/Managed Services/Production Support Experience
Should have extensive experience in developing scalable, repeatable, and secure data structures and pipelines to ingest, store, collect, standardize, and integrate data that for downstream consumption like Business Intelligence systems, Analytics modelling, Data scientists etc.
Designing and implementing data pipelines to extract, transform, and load (ETL) data from various sources into data storage systems, such as data warehouses or data lakes.
Should have experience in building efficient, ETL/ELT processes using industry leading tools like Informatica, Talend, SSIS, AWS, Azure, Spark, SQL, Python etc.
Should have Hands-on experience with Data analytics tools like Informatica, Collibra, Hadoop, Spark, Snowflake etc.
Design, implement, and maintain data pipelines for data ingestion, processing, and transformation in Azure.
Work together with data scientists and analysts to understand the needs for data and create effective data workflows.
Create and maintain data storage solutions including Azure SQL Database, Azure Data Lake, and Azure Blob Storage.
Utilizing Azure Data Factory or comparable technologies, create and maintain ETL (Extract, Transform, Load) operations.
Perform data transformation and processing tasks to prepare the data for analysis and reporting in Azure Databricks or Azure Synapse Analytics for large-scale data transformations using tools like Apache Spark.
Implementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.
Improve the scalability, efficiency, and cost-effectiveness of data pipelines.
Monitoring and troubleshooting data pipelines and resolving issues related to data processing, transformation, or storage.
Implementing and maintaining data security and privacy measures, including access controls and encryption, to protect sensitive data
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Should have experience in Building and maintaining Data Governance solutions (Data Quality, Metadata management, Lineage, Master Data Management and Data security) using industry leading tools
Scaling and optimizing schema and performance tuning SQL and ETL pipelines in data lake and data warehouse environments.
Should have Hands-on experience with Data analytics tools like databricks
Should have Experience of ITIL processes like Incident management, Problem Management, Knowledge management, Release management, Data DevOps etc.
Should have Strong communication, problem solving, quantitative and analytical abilities.

Nice to have:

Azure certification

Managed Services- Data, Analytics & Insights Managed Service

At PwC we relentlessly focus on working with our clients to bring the power of technology and humans together and create simple, yet powerful solutions. We imagine a day when our clients can simply focus on their business knowing that they have a trusted partner for their IT needs. Every day we are motivated and passionate about making our clients’ better.

Within our Managed Services platform, PwC delivers integrated services and solutions that are grounded in deep industry experience and powered by the talent that you would expect from the PwC brand. The PwC Managed Services platform delivers scalable solutions that add greater value to our client’s enterprise through technology and human-enabled experiences. Our team of highly skilled and trained global professionals, combined with the use of the latest advancements in technology and process, allows us to provide effective and efficient outcomes. With PwC’s Managed Services our clients are able to focus on accelerating their priorities, including optimizing operations and accelerating outcomes. PwC brings a consultative first approach to operations, leveraging our deep industry insights combined with world class talent and assets to enable transformational journeys that drive sustained client outcomes. Our clients need flexible access to world class business and technology capabilities that keep pace with today’s dynamic business environment.

Within our global, Managed Services platform, we provide Data, Analytics & Insights where we focus more so on the evolution of our clients’ Data and Analytics ecosystem. Our focus is to empower our clients to navigate and capture the value of their Data & Analytics portfolio while cost-effectively operating and protecting their solutions. We do this so that our clients can focus on what matters most to your business: accelerating growth that is dynamic, efficient and cost-effective.

As a member of our Data, Analytics & Insights Managed Service team, we are looking for candidates who thrive working in a high-paced work environment capable of working on a mix of critical Data, Analytics & Insights offerings and engagement including help desk support, enhancement, and optimization work, as well as strategic roadmap and advisory level work. It will also be key to lend experience and effort in helping win and support customer engagements from not only a technical perspective, but also a relationship perspective.

Show more "
Software Developer/ Engineer -1,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-07-02,https://in.linkedin.com/jobs/view/software-developer-engineer-1-at-nxtwave-4258614972?position=50&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=XKc3HcIPrbNUXyLXovfBbg%3D%3D,"Job Title: Software Developer/ Engineer -1

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
Data Engineer - II,Airtel Payments Bank,"Gurugram, Haryana, India",Gurugram,2025-07-23,https://in.linkedin.com/jobs/view/data-engineer-ii-at-airtel-payments-bank-4273425402?position=51&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=IyKdNf9QD5QSK7dhWMBUYw%3D%3D,"About Us:

Airtel Payments Bank, India's first payments bank is a completely digital and paperless bank. The bank aims to take basic banking services to the doorstep of every Indian by leveraging Airtel's vast retail network in a quick and efficient manner.

At Airtel Payments Bank, we’re transforming the way banking operates in the country. Our core business is banking and we’ve set out to serve each unbanked and underserved Indian. Our products and technology aim to take basic banking services to the doorstep of every Indian. We are a fun-loving, energetic and fast growing company that breathes innovation. We encourage our people to push boundaries and evolve from skilled professionals of today to risk-taking entrepreneurs of tomorrow. We hire people from every realm and offer them opportunities that encourage individual and professional growth. We are always looking for people who are thinkers & doers; people with passion, curiosity & conviction; people who are eager to break away from conventional roles and do 'jobs never done before’.




About the Team:

We are a team of engineers and problem-solvers building scalable, modern data infrastructure. Our mission is to power intelligent decision-making through clean, reliable, and real-time data pipelines using technologies like Kafka, PySpark, Hadoop, Airflow, and AWS. If you love working with data at scale, building cloud-native solutions, and improving pipeline reliability, you'll thrive here.




Key Responsibilities:

•Design, build, and maintain scalable ETL/ELT pipelines using Python, PySpark, and SQL.

•Develop real-time data ingestion and streaming solutions using Apache Kafka and AWS Kinesis.

•Leverage the Hadoop ecosystem and AWS EMR for distributed data processing.

•Automate and orchestrate workflows using Apache Airflow (deployed via MWAA on AWS).

•Build and expose data services and APIs using Flask, deployed via Nginx.

•Implement centralized logging and monitoring with Filebeat and the ELK/Opensearch stack.

•Work extensively with AWS services including S3, API Gateway, OpenSearch, Kinesis, and EMR.

•Collaborate with data scientists, analysts, and platform engineers to ensure high-quality, accessible data.




Must-Have Skills:

•4–7 years of experience in data engineering.

•Proficiency in Python and SQL (Experience with Oracle or similar RDBMS).

•Good experience with Apache Kafka (producer/consumer architecture, stream processing concepts).

•Hands-on with PySpark, Hadoop & Hive for big data processing.

•Workflow orchestration using Apache Airflow (and optionally MWAA).

•Building APIs with Flask and serving via Nginx.

•Logging and observability using ELK Stack and Filebeat.

•Good familiarity with AWS ecosystem: EMR, Kinesis, S3, OpenSearch, API Gateway, MWAA.




Good-to-Have (But not mandatory)

•Experience with AWS Glue, Athena, and Redshift for serverless data processing and warehousing.

•Familiarity with AWS Flink or other stream processing frameworks.

•Exposure to AWS DMS (Data Migration Service) for database migrations and replication tasks.

•Knowledge of AWS QuickSight for dashboarding and BI reporting.

•Understanding of data lake architectures and event-driven processing on AWS




Why Join Us?

Airtel Payments Bank is transforming from a digital-first bank to one of the largest Fintech company. There could not be a better time to join us and be a part of this incredible journey than now. We at Airtel payments bank don’t believe in all work and no play philosophy. For us, innovation is a way of life and we are a happy bunch of people who have built together an ecosystem that drives financial inclusion in the country by serving 300 million financially unbanked, underbanked, and underserved population of India. Some defining characteristics of life at Airtel Payments Bank are Responsibility, Agility, Collaboration and Entrepreneurial development : these also reflect in our core values that we fondly call RACE..

Show more "
AWS Data Engineer,Infosys,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-01,https://in.linkedin.com/jobs/view/aws-data-engineer-at-infosys-4273719441?position=53&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=92KzDv1rVXwmqNaIweMAWg%3D%3D,"Primary skills: Technology->Cloud Platform->AWS Data Analytics->AWS Glue DataBrew


A day in the life of an Infoscion


As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction.
You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain.
You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews.
You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes.
You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!
Show more "
Software Engineer-Frontend Developer,Microsoft,"Noida, Uttar Pradesh, India",Noida,2025-07-25,https://in.linkedin.com/jobs/view/software-engineer-frontend-developer-at-microsoft-4275650000?position=54&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=CRzhulYUz9eAwJDDPYFJgg%3D%3D,"On Team Xbox, we aspire to empower the world’s 3 billion gamers to play the games they want, with the people they want, anywhere they want. Gaming, the largest and fastest growing category in media & entertainment, represents an important growth opportunity for Microsoft. We are leading with innovation, as highlighted by bringing Xbox to new devices with Cloud Gaming, bringing the Game Pass subscription to PC, and our recent acquisition of Activision Blizzard King creating exciting new possibilities for players.

The Xbox Experiences and Platforms team is home to the engineering work that makes this vision possible, building the developer tools and services that enable game creators to craft incredible experiences, the commerce systems that connect publishers with their audience and help gamers engage with their next favorite games, the platforms on which those games play at their best, and the experiences that turn every screen into an Xbox.

Responsibilities

Our Developer team is looking for a Software Engineer to join us in our journey to reimagine how game creators bring content to life—working together to transform the way developers onboard, publish, and receive support across our platforms. Our mission is to simplify and accelerate the creator journey by building intuitive tools, and responsive support systems that empower creators—from indie studios to AAA publishers—to move faster, with greater confidence and less friction.    

Responsibilities include: 


Learn about various tools and technologies and effectively use them to deliver a wide variety of customer experiences.
Implement, validate, and release high quality product features.
Adhere to modern engineering principles and practices. 
Collaborate with other engineers and program managers to make impactful changes. 
Actively contribute to a flexible, diverse, and inclusive culture that brings out the best in the team.


Qualifications

Required: 


BS or MS in Computer Science or equivalent.
2 years of experience in software development skills building end-user applications
Understanding of data structures, algorithms, threading, synchronization.
Experience building React, Angular and Typescript applications  
Good design and coding skills in JavaScript
A strong interest in bringing end user experiences to a gaming audience and an understanding of their needs 


Preferred:  


Experience shipping web applications using React JS and Typescript  
Experience shipping cross-platform applications using React JS and Typescript  
Understanding of modern web app development against cloud service dependencies  
Technical knowledge and understanding of challenges related to the gaming space, including but not limited to responsive UX design across device form factors, navigational input including gamepad, touch, and mouse/keyboard.  


Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
Software Engineer,Microsoft,"Hyderabad, Telangana, India",Hyderabad,2025-07-25,https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4275640780?position=55&pageNum=0&refId=0MCi57ktfUkVWGLP%2Fedybg%3D%3D&trackingId=xq6R9jk3BXVLZUR4MEqMVw%3D%3D,"The Experience plus Devices (E+D) Growth team is seeking engineers to help accelerate the adoption of Copilot and Microsoft 365. Our team is uniquely positioned at the strategic epicenter of E+D for revolutionizing the productivity business by delivering embedded experiences across the Microsoft 365 suite (Teams, Outlook, Word, PowerPoint, Excel, etc.) that drive the growth of our company’s cutting-edge generative AI solutions across the commercial and consumer spectrum. Our team tackles technical challenges across a diverse tech stack, with the solutions we deliver having a direct impact on the bottom line of the business. This role requires strategic and creative thinking, as well as a passion for building technical solutions that address customer needs.  

  

We are a modern engineering organization that embodies industry best practices in Product-Led Growth (PLG). We are data-informed, hypothesis-driven, and rigorous in measuring outcomes to ensure undeniable customer and business impact. We collaborate closely with industry-leading PMs, designers, data scientists, user researchers, and marketers to build deep customer insights that inform the design of experiences used by hundreds of millions of people every day. We partner with teams across the company to deliver world-class services, and we create experiences that connect with customers across Microsoft products. We play a direct role in driving business growth and framing our business value to end users and our vibrant community of fans.  We are looking for a Software Engineer to join us.

Responsibilities


Works with appropriate stakeholders to determine user requirements for a feature.
Supports identification of dependencies, and the development of design documents for a product feature with oversight.
With guidance, learns to create and implement code for a product, service, or feature reusing code as applicable.
Assists and learns about breaking down work items into tasks and provides estimation.
Acts as a Designated Responsible Individual (DRI) in monitoring system/product feature/service for degradation, downtime, or interruptions for simple problems, and recommends actions to restore system/product/service by following the playbook.


Qualifications


Bachelor's Degree in Computer Science, or related technical discipline AND 1+ years technical engineering experience with coding and shiping high quality features.
1+ year experience with Swift, Objective-C++ and knowledge of end-to-end software development life cycle for iOS/MacOS.
Experience with native iOS architecture, frameworks (e.g., Swift UI, UIKit) and toolchain


OR


1+ years’ experience with Kotlin, Java and knowledge of end-to-end software development life cycle for Android.
Experience with native Android architecture, frameworks and toolchain .


Preferred Qualifications


Bachelor's Degree in Computer Science
OR related technical field AND 1+ year(s) technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, Python
OR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
Understanding of GitHub Copilot will be an added advantage
Native Android/iOS/Windows/macOS experiences using modern C++, Java, Kotlin, Objective-C, Swift and platform-specific frameworks.
OR equivalent experience.


Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
Software Developer,Larsen & Toubro,Mumbai Metropolitan Region,Mumbai Metropolitan Region,2025-08-04,https://in.linkedin.com/jobs/view/software-developer-at-larsen-toubro-4200597602?position=1&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=7%2BarRJ5UtccbZSnwrJKQXA%3D%3D,"This vacancy is for a software developer in UAV development division. Candidate is expected to have following skills,

Skills: C,C++, QT, QML, GUI, Geographic Information System(GIS), FPGA

Responsibilities


Design, build, and maintain efficient, reusable, and reliable C,C++ code.
UAV software stack development.
Identify bottlenecks and bugs, and devise solutions to problems.
Help to maintain product quality, organization integrity and team coordination.


Description/Requirements


Strong proficiency in C++, with fair knowledge of the OOPs & STL.
Proficient knowledge on communication protocols like CAN, TCP/UDP, UART, I2C etc.
Experience in QGIS and MAV Link is a plus.
Experience in developing GUI with tool chains such as Qt, QML etc.
Hands-on experience in designing and developing scalable computer vision solutions with OpenCV, CUDA, OpenCL, NPP etc.
Good understanding of memory management, thread Management, Concurrency & Parallelism programming.
Familiarity with embedded systems design, low-level hardware interactions.
Experience with Xilinx FPGA tool flow (Vivado) for synthesis, implementation, and bitstream generation.
Familiarity with Yocto, RTOS.
Good to have knowledge on Unit/integration testing.
Know-how of coding standards like MISRA, C++.
Familiarity with code versioning & project management tools.
Show more "
SDE-1,Amazon,"Bengaluru, Karnataka, India",Bengaluru,2025-08-12,https://in.linkedin.com/jobs/view/sde-1-at-amazon-4271077952?position=2&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=Wj902w3u%2BHA69VCNMNlOLw%3D%3D,"DESCRIPTION

Cross Border Tech is looking for an experienced Software Development Engineer to work on our Cross Border technology stacks, which enables to launch new Cross Border arc with local language, local currency, local payments and build new features and enhancements. The Cross Border strategy, and roadmap is one of the most important initiatives across Amazon. You will design, architect and innovative technology solutions that will reduce time to market, standardize execution and scale for expansion globally. You will build, operate and play a key role in the evolution of our platform to solve the world's most complex technical challenges in Information extraction, Large-scale computing, Distributed systems, Web applications, Data mining, Scalability, Security, and Algorithms to name a few. You’ll strive for simplicity, and demonstrate significant creativity and high judgment. You will play a key role in stabilizing the day to day operations and improving the platform’s build and testing process, and ensure adherence to organizational software and security compliance.

The job is simple: make everything available to everyone all the time at the best possible price. The requirements are almost as simple - we’re looking for leaders and trailblazers who aren’t afraid of tackling massive scale, layered complexity and ambiguous requirements to empower our customers to shop the World. No two features are ever the same and our customers are hungry for every single one!

What To Expect Day-to-day:


Solve complex problems through data, rapidly.
Design and develop state of the art software systems that address these complex and ambiguous problems.
Own the inputs and the business outcome through cultivating a culture of relentless auditing and metric monitoring, automatically where possible.


This is a contractual position which is ideal for candidates who are looking to deal with scaling challenges at Amazon and ready to build mission critical system software applications and tools. It is also an opportunity for freelance candidates to become domain experts and have an enormous opportunity to make a large impact on the design, architecture and development of consumer products. Depending on individual performance this experience can lead to permanent positions as Software Development Engineers at Amazon.

Key job responsibilities

What To Expect Day-to-day:


Solve complex problems through data, rapidly.
Design and develop state of the art software systems that address these complex and ambiguous problems.
Own the inputs and the business outcome through cultivating a culture of relentless auditing and metric monitoring, automatically where possible.


BASIC QUALIFICATIONS


1+ years of non-internship professional software development experience
Experience programming with at least one software programming language


PREFERRED QUALIFICATIONS


Bachelor's degree in computer science or equivalent


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Karnataka

Job ID: A2965548
Show more "
Software Engineer,Intuit,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-at-intuit-4282496088?position=3&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=JjXuPTZJfOSY4Csh6YgEMg%3D%3D,"Overview

Intuit is a mission-driven, global financial platform company that gives everyone the opportunity to prosper. With products like TurboTax, QuickBooks , we’re using technology to build solutions to challenging financial problems for millions of people around the world.

Our mission is to significantly enhance software quality across Intuit, improving the end-customer experience and accelerating our feature delivery velocity. We are building the frameworks, infrastructure, and guidance necessary to improve our current quality posture. This team focuses on four key pillars: Test Authoring, Test Management, Test Execution, and Test Reporting, with an emphasis on improving quality through end-to-end (E2E) and integration testing.

We are seeking a Software Engineer 2 to join our team, playing a pivotal role in building and evolving the core infrastructure and tooling that will drive our quality improvement initiatives. You will contribute to creating a ""paved road"" for comprehensive, user-flow centric testing, enabling developers to ship rapidly with confidence.

Responsibilities

Design and Implement Quality Infrastructure: Partner effectively with all team members to build solutions that support various testing frameworks (e.g., Playwright, Cypress, Selenium, Karate) and integrate them into a unified system.
Enhance Test Management and Reporting: Build capabilities for a comprehensive test registry that automatically captures integration and E2E tests, linking them to assets, features, and capabilities. Implement standardized reporting mechanisms to provide real-time visibility into test coverage, health, and flakiness.
Improve Test Authoring and Maintenance: Contribute to the development of tools and practices that simplify the creation and updating of test cases, potentially leveraging AI-assisted test maintenance to adapt to UI and logic changes.
Optimize Test Execution: Design and implement intelligent automated test selection, parallelized test execution, and real-time feedback loops to improve release velocity.
Technical Leadership: Provide technical guidance and mentorship to other engineers, contributing to the overall technical direction of the quality initiative.
Drive Standardization and Best Practices: Champion consistent coding practices for tests, advocating for and implementing a ""paved road"" for integration and E2E testing across various organizations (CG, Fintech, Mailchimp, GBSG).
Troubleshoot and Resolve Issues: Investigate and resolve complex issues related to test failures, flakiness, and environment conflicts.




Qualifications

2+ years of experience working in an enterprise hosting complex systems
BS/MS in computer science or equivalent work experience
Proficiency in at least one Programming language e.g. Go, Java etc.
Strong communication and collaboration skills, with the ability to influence and drive change across multiple teams and organizations.
Proficiency in designing, implementing, and maintaining automated test frameworks and tools.
Experience with continuous integration/continuous delivery (CI/CD) pipelines and quality gates.
Demonstrated ability to identify and solve complex technical problems related to test flakiness, performance, and reliability.
Experience with cloud platforms (e.g., AWS) and related testing services at scale is a plus.

Show more "
Software Engineer,Flipkart,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-at-flipkart-4282735345?position=4&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=v7eUrRG8nlQoKf53wUGwow%3D%3D,"About Flipkart

Flipkart is India’s largest e-commerce marketplace with a registered customer base of over 100 million. In the 10 years since it started, Flipkart has come to offer over 80 million products across 80+ categories including Smartphones, Books, Media, Consumer Electronics, Furniture, Fashion and Lifestyle. Launched in October 2007, Flipkart is known for its path-breaking services like Cash on Delivery, No cost EMI and a 10-day replacement policy. Flipkart was the pioneer in offering services like In-a-Day Guarantee (65 cities) and Same-Day-Guarantee (13 cities) at scale. With over 1,00,000 registered sellers, Flipkart has redefined the way brands and MSME’s do business online.




The Role

The Software Development Engineer's core responsibilities include working on highly-maintainable and unit tested software components/system that address real world problems. You will be working in a fast paced and agile work environment delivering quality solutions that have immediate business impact.




You (Must Have)

• Minimum 0.6 year of experience and Less than 2 years of experience

• Strong problem solving skills

• Good understanding of data structures & algorithms and their space & time complexities

• Strong hands-on and practical working experience with at least one programming language:

• C/Java/C++

• Excellent coding skills – should be able to convert design into code fluently

• Strong technical aptitude and a good knowledge of CS fundamentals

• Hands-on experience working with Databases and Linux platform is a plus

• B Tech in Computer Science or equivalent from a reputed college




Your Array (Nice to Haves):

You will assume complete ownership of the projects you deliver while collaborating with technical and non-technical stakeholders on all elements of the development process. You are expected to demonstrate good learnability and adopt technologies that help build large scale, performant, reliable and sustainable systems.

Show more "
Software Engineer (WEB),Microsoft,"Hyderabad, Telangana, India",Hyderabad,2025-08-08,https://in.linkedin.com/jobs/view/software-engineer-web-at-microsoft-4282143410?position=5&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=2p6a72979DPULYHiKi8a7w%3D%3D,"Are you passionate about shaping the future applications of AI and empowering millions of users to unlock their full potential? The OneNote team is at the forefront of an exciting transformation with Copilot Notebooks: intelligent, dynamic notebooks infused with powerful AI that act as a true ""second brain."" Imagine effortlessly capturing ideas, intuitively understanding complex information, and seamlessly taking informed action. This is the heart of our mission.

 We plan to build transformational experiences in Copilot notebook and are looking to hire a Software Engineer II in the OneNote Web team. The problems we solve will include building a multitude of grounding capabilities, creation of richer artefacts, multi-modal capture support, and above all building agent support on top of Copilot notebooks. The problems will also encompass deep architectural improvements to optimize performance and increase reliability. We plan to build these experiences at scale across all Web and mobile platforms and will continue to use the best-in-class infrastructure that boosts developer productivity & engineering velocity.

 We are looking for creative problem solvers and diverse thinkers, people who care about culture as well as customers and features.  We believe that how we do things is at least as important as what we do.  Big vision, a common purpose, passion for quality, curiosity as well as grit, and investment in fun and collaboration are what lead to great results.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

Responsibilities


Design and implementation of high-quality features/experiences in an iterative and rapid manner.
Demonstrate passion for quality with customer empathy.
Demonstrate ownership and technical expertise of product areas.
Be self-motivated to identify and fix gaps in our product/engineering stack.


Qualifications

Required Qualifications:


Bachelor's Degree in Computer Science or related technical field AND 2+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR equivalent experience.
Full stack experience in Web technologies.
Proficiency in one of the following languages - TypeScript, JS, C#, or Java.
Strong problem solving, debugging, and troubleshooting skills.
Working in agile teams with strong customer focus.
Good communication and cross group collaboration skills.
Experience in Cloud and distributed systems is a big plus.

Other Requirements

Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:


Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.


Preferred Qualifications


Bachelor's Degree in Computer Science
OR related technical field AND 4+ year(s) technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR equivalent experience.

Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
SDE 1,Licious,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/sde-1-at-licious-4281490468?position=6&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=FT3Vg1qQAqXnJ1vPqT3xmw%3D%3D,"Licious was launched in September 2015 by Abhay Hanjura and Vivek Gupta who sensed a huge business opportunity in offering prime quality meat products that was otherwise dominated by the unhygienic and unreliable wet market followed by frozen meat options which is an unpopular workaround for Indian consumers. Licious follows an end-to-end business based on the hub and spoke model that starts from procuring the fresh produce to processing, storage and delivery.

Through this entire supply chain, the freshness and nutritional content of the meat is strictly maintained till the delivery at the doorstep of the consumer. Licious was started with the aim of satisfying customers with world class meat, fish, seafood and meat based products. Powered by technology, Licious delivers within 120 minutes of ordering through either the web site or the Licious app.




Required technical skills:




● Bachelor's Degree in Computer Science or similar discipline/B.E from reputed

colleges.

● 1-3 years of development experience in fast phased startups as developer

● Should be proficient in Java or related frameworks.

● Good knowledge on frontend technologies (HTML, JS, CSS and ReactJs) - good to

have

● Good problem-solving skills and self-motivated.

● Thrives in agile environments but also understands the balance in coding discipline

required for large scale, high quality, end consumer apps.

● Comfort and experience working with API development.

● Experience in both jumping into an existing architecture and starting projects from

scratch.

● Proven ability to take initiative and dive into new areas of technology.

● Passion for learning, analysing technology trade-offs and shipping products.

● Full stack experience is a plus

● Comfortable with SQL, NOSQL databases

● Knowledge on AWS deployments is a plus

● Good logical thinking with fundamentally strong




Roles:




● Actively participate and contribute to all aspects of the software development lifecycle

including: brainstorm, architecture, design and technical tradeoffs and prioritization,

implementation, quality assurance, and delivery for features slated for both our existing

platform and new services.

● Continuously deliver rapid and consistent software and services that delight and engage

our customers in tight collaboration with Product Managers and other members of the

team.

● Improve our development processes and code quality, keeping us up-to-date with the

latest industry trends.

● Taking initiative and ownership to complete given project

Show more "
Software Engineer,PhonePe,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/software-engineer-at-phonepe-4245875707?position=7&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=yBvfMJ37%2FJToxoGfbiwAJA%3D%3D,"About PhonePe Limited:

Headquartered in India, its flagship product, the PhonePe digital payments app, was launched in Aug 2016. As of April 2025, PhonePe has over 60 Crore (600 Million) registered users and a digital payments acceptance network spread across over 4 Crore (40+ million) merchants. PhonePe also processes over 33 Crore (330+ Million) transactions daily with an Annualized Total Payment Value (TPV) of over INR 150 lakh crore.

PhonePe’s portfolio of businesses includes the distribution of financial products (Insurance, Lending, and Wealth) as well as new consumer tech businesses (Pincode - hyperlocal e-commerce and Indus AppStore Localized App Store for the Android ecosystem) in India, which are aligned with the company’s vision to offer every Indian an equal opportunity to accelerate their progress by unlocking the flow of money and access to services.

Culture:

At PhonePe, we go the extra mile to make sure you can bring your best self to work, Everyday!. And that starts with creating the right environment for you. We empower people and trust them to do the right thing. Here, you own your work from start to finish, right from day one. PhonePe-rs solve complex problems and execute quickly; often building frameworks from scratch. If you’re excited by the idea of building platforms that touch millions, ideating with some of the best minds in the country and executing on your dreams with purpose and speed, join us!

Challenges

Building for Scale, Rapid Iterative Development, and Customer-centric Product Thinking at each step defines every day for a developer at PhonePe. Though we engineer for a 50million+ strong user base, we code with every individual user in mind. While we are quick to adopt the latest in Engineering, we care utmost for security, stability, and automation. Apply if you want to experience the best combination of passionate application development and product-driven thinking

As a Software Engineer:


You will build Robust and scalable web-based applications You will need to think of platforms & reuse
Build abstractions and contracts with separation of concerns for a larger scope
Drive problem-solving skills for high-level business and technical problems.
Do high-level design with guidance; Functional modeling, break-down of a module
Do incremental changes to architecture: impact analysis of the same
Do performance tuning and improvements in large scale distributed systems
Mentor young minds and foster team spirit, break down execution into phases to bring predictability to overall execution
Work closely with Product Manager to derive capability view from features/solutions, Lead execution of medium-sized projects
Work with broader stakeholders to track the impact of projects/features and proactively iterate to improve them As a senior software engineer you must have
Extensive and expert programming experience in at least one general programming language (e.g. Java, C, C++) & tech stack to write maintainable, scalable, unit-tested code.
Experience with multi-threading and concurrency programming
Extensive experience in object-oriented design skills, knowledge of design patterns, and huge passion and ability to design intuitive module and class-level interfaces
Excellent coding skills – should be able to convert the design into code fluently
Knowledge of Test Driven Development
Good understanding of databases (e.g. MySQL) and NoSQL (e.g. HBase, Elasticsearch, Aerospike, etc)
Strong desire to solving complex and interesting real-world problems
Experience with full life cycle development in any programming language on a Linux platform
Go-getter attitude that reflects in energy and intent behind assigned tasks
Worked in a startups environment with high levels of ownership and commitment
BTech, MTech, or Ph.D. in Computer Science or related technical discipline (or equivalent).
Experience in building highly scalable business applications, which involve implementing large complex business flows and dealing with a huge amount of data.
9+ years of experience in the art of writing code and solving problems on a Large Scale.
An open communicator who shares thoughts and opinions frequently listens intently and takes constructive feedback.


As a Software Engineer, good to have


The ability to drive the design and architecture of multiple subsystems
Ability to break-down larger/fuzzier problems into smaller ones in the scope of the product
Understanding of the industry’s coding standards and an ability to create appropriate technical documentation.


PhonePe Full Time Employee Benefits (Not applicable for Intern or Contract Roles)


Insurance Benefits - Medical Insurance, Critical Illness Insurance, Accidental Insurance, Life Insurance
Wellness Program - Employee Assistance Program, Onsite Medical Center, Emergency Support System
Parental Support - Maternity Benefit, Paternity Benefit Program, Adoption Assistance Program, Day-care Support Program
Mobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy
Retirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment
Other Benefits - Higher Education Assistance, Car Lease, Salary Advance Policy


Our inclusive culture promotes individual expression, creativity, innovation, and achievement and in turn helps us better understand and serve our customers. We see ourselves as a place for intellectual curiosity, ideas and debates, where diverse perspectives lead to deeper understanding and better quality results. PhonePe is an equal opportunity employer and is committed to treating all its employees and job applicants equally; regardless of gender, sexual preference, religion, race, color or disability. If you have a disability or special need that requires assistance or reasonable accommodation, during the application and hiring process, including support for the interview or onboarding process, please fill out this form.

Read more about PhonePe on our blog.

Life at PhonePe

PhonePe in the news
Show more "
Software Engineering,Microsoft,"Hyderabad, Telangana, India",Hyderabad,2025-08-08,https://in.linkedin.com/jobs/view/software-engineering-at-microsoft-4282302472?position=8&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=E6xyVQyGWEQyZV1ZdoYvDA%3D%3D,"Are you a customer-obsessed, AI-curious problem-solver who thrives in an inclusive, collaborative global team? The Azure CXP team’s mission is to transform Microsoft Cloud customers into fans. Through our deep engineering engagements with customers and teams across Microsoft, we analyze and amplify customer needs and drive the vision to improve Cloud quality, security, and reliability. Our culture of growth mindset and empowerment are central to who we are and how we work. 

We are customer-obsessed problem-solvers. We orchestrate deep engagements in areas like incident management, support, and enablement. We analyze and amplify those customer voices, both within our own team, and across the Cloud + AI team, bringing the customer connection to the Quality vision for Azure. We innovate ways to scale what we learn across our customer base.  Diversity and inclusion are central to who we are, how we work, and what we enable our customers to achieve. We know that empowering our customers starts with empowering our team to show up authentically, work in ways that are best for them, and achieve their career goals. Azure Reliability team is a multidisciplinary engineering organization part of CXP dedicated to making, “Azure the safest and most reliable Cloud”. 

We are the Azure Reliability team; a multidisciplinary engineering organization committed to making Azure the world’s safest and most reliable cloud. For Azure’s most critical services and products, we apply a Site Reliability Engineering (SRE) approach. Our software engineers work closely with product teams to enhance availability, reliability, observability, and operability across our planet-scale systems. 

We prioritize long-term platform improvements through engineering over repetitive manual tasks. Increasingly, we leverage AI to amplify our ability to scale reliability across Azure. Our teams contribute to product architecture, share knowledge and code, and focus on building reusable solutions that benefit multiple teams and services.  

As the SRE discipline evolves, we continuously learn from industry peers and contribute to its advancement by innovating within our group and sharing our insights publicly. Our team brings diverse professional backgrounds, both traditional and non-traditional, and we’re committed to growing diversity. We believe that an inclusive environment where everyone feels safe to contribute leads to better teams, better products, and a better workplace. We’re not looking for people who know it all; we’re looking for those eager to learn it all. If you thrive on collaboration, embrace challenges, and see mistakes as opportunities to grow, we’d love to meet you. 

Every day, our customers stake their business and reputation on our cloud. You can help #AzCXP provide our customers with the world-class cloud services they need to succeed. 

Company Culture Statement 

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. 

Responsibilities

Billions of users across the world rely on our products, and to meet this demand we design and implement world-class distributed systems.   

As a Software Engineer in one of our Azure SRE teams, you will be responsible for improving the reliability of key Azure products.  

The Azure SRE key focus areas are: 


Defining system reliability goals through Service Level Objectives (SLOs). Enhancing production posture with targeted improvements in observability and operability (telemetry, alerting, incident/change management, safe deployment practices). 
Building reusable automation and processes that help multiple teams meet their reliability goals. Influencing product architecture and roadmaps to ensure customer-experienced reliability is a core design principle. 
Contributing directly to product code to achieve reliability outcomes. Leveraging AI to proactively detect anomalies, predict incidents, and automate operational workflows - scaling reliability efforts across complex systems. 


We are looking for engineers passionate about the above areas who are also interested in:  


Designing and developing large-scale distributed software services and solutions. Delivering “best-in-class” engineering by ensuring services are modular, secure, reliable, testable, diagnosable, observable, and reusable. 
Collaborating with internal and external partners to support team goals. Balancing pragmatism with vision - driving continuous improvements in process and codebase. Building automation to prevent or remediate service issues before they impact users. 
Driving innovation in large-scale operations by applying cutting-edge AI tools and techniques to reduce operational toil and scale reliability engineering across complex systems. 
Gaining a working understanding of Microsoft businesses and contributing to cohesive, end-to-end user experiences. 


Qualifications

Required Qualifications:


Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python 
OR equivalent experience


Preferred Qualifications 


Familiarity with modern distributed software design patterns and cloud systems architecture, including microservices, containers, load balancing, queuing, caching. 
Proven track record in building, shipping, and operating reliable solutions. 
Proficiency in programming languages like C#/Java/Python. 
Experience with data technologies (SQL/NoSQL/etc.). 
Experience with Azure is a plus. 
Experience in AI adoption with tools like GitHub Copilot, Azure OpenAI and custom copilots to streamline development and reduce toil. 


Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
Software Engineer,Flipkart,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-at-flipkart-4283073170?position=9&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=cUqkcORmgAyVnUu3uiMmRw%3D%3D,"About the job




About Flipkart

Flipkart is India’s largest e-commerce marketplace with a registered customer base of over 100 million. In the 10 years since it started, Flipkart has come to offer over 80 million products across 80+ categories including Smartphones, Books, Media, Consumer Electronics, Furniture, Fashion and Lifestyle. Launched in October 2007, Flipkart is known for its path-breaking services like Cash on Delivery, No cost EMI and a 10-day replacement policy. Flipkart was the pioneer in offering services like In-a-Day Guarantee (65 cities) and Same-Day-Guarantee (13 cities) at scale. With over 1,00,000 registered sellers, Flipkart has redefined the way brands and MSME’s do business online




The Role

The Software Development Engineer's core responsibilities include working on highly-maintainable and unit tested software components/system that address real world problems. You will be working in a fast paced and agile work environment delivering quality solutions that have immediate business impact.




You (Must Have)

• Minimum 0.6 year of experience and Less than 2 years of experience

• Strong problem solving skills

• Good understanding of data structures & algorithms and their space & time complexities

• Strong hands-on and practical working experience with at least one programming language:

• C/Java/C++

• Excellent coding skills – should be able to convert design into code fluently

• Strong technical aptitude and a good knowledge of CS fundamentals

• Hands-on experience working with Databases and Linux platform is a plus

• B Tech in Computer Science or equivalent from a reputed college




Your Array (Nice to Haves):

You will assume complete ownership of the projects you deliver while collaborating with technical and non-technical stakeholders on all elements of the development process. You are expected to demonstrate good learnability and adopt technologies that help build large scale, performant, reliable and sustainable systems.

Show more "
Fullstack - Software Engineer (Backend focus): Entry Level Talent,Cisco,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/fullstack-software-engineer-backend-focus-entry-level-talent-at-cisco-4281533833?position=10&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=vK%2FI1KowwBRuVxVMaFCdmw%3D%3D,"At Cisco, we’re revolutionizing how data and infrastructure connect and protect organizations in the AI era – and beyond. We’ve been innovating fearlessly for 40 years to create solutions that power how humans and technology work together across the physical and digital worlds. These solutions provide customers with unparalleled security, visibility, and insights across the entire digital footprint. Simply put – we power the future.

Fuelled by the depth and breadth of our technology, we experiment and create meaningful solutions. Add to that our worldwide network of doers and experts, and you’ll see that the opportunities to grow and build are limitless. We work as a team, collaborating with empathy to make really big things happen on a global scale. Because our solutions are everywhere, our impact is everywhere.

We are Cisco, and our power starts with you.

About this role:

As a team member, you'll will work on cutting-edge backend systems built on a modern, cloud-native, distributed architecture. This includes developing real-time streaming solutions as part of the Cisco Spaces platform, a global SaaS product that serves some of the world’s most recognized brands.

You will also contribute to frontend development using React, gaining hands-on experience in building user-facing applications that deliver meaningful impact across the globe. This role offers full-stack exposure, allowing team members to build solutions that are both technically advanced and customer-facing.

In addition, you will have the opportunity to learn and contribute to emerging technologies, including artificial intelligence and machine learning

What We're Looking For:

Technical Proficiency: Strong foundation in Core Java and server-side technologies (J2EE, Spring Boot).
Frontend Knowledge: Good understanding of frontend technologies-especially React and JavaScript.
Database Expertise: Skilled in designing efficient database architectures and optimizing query performance in relational databases like Postgres or SQL.
Software as a Service: Experience (2yrs +) working to developing SaaS product components.
Cloud Technology & Containerization: Ability to build, deploy, and manage microservices on AWS using tools like Docker and Kubernetes.

Bonus Skills

Familiarity with tools like Maven, Gradle, Jenkins, and Git.
Experience with Kotlin, Vertx, WebSockets, Kafka, GraphQL, EKS, or CDN.

Who you are:

Recent graduate or early career engineer, ready to learn and grow
Collaborative team player with strong problem-solving skills.
You're ready to kick-start your tech career and build the future of SaaS
Can demonstrate 2+ years of experience

Note: We welcome candidates from all backgrounds. If you meet most of the requirements, we encourage you to apply!

Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified

applicants will receive consideration for employment without regard to race, color,

religion, gender, sexual orientation, national origin, genetic information, age, disability,

veteran status, or any other legally protected basis. Cisco will consider for employment,

on a case by case basis, qualified applicants with arrest and conviction records.

Show more "
Software Engineer 2,Flipkart,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-2-at-flipkart-4283016164?position=11&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=7ik55zc6RkKKQLtlVvisDw%3D%3D,"About the role

At Flipkart, SDE-2 are engineers who create features based on product requirements. You’re expected to design and code in multiple tech components related to your functional area. You’re required to learn the best practices and design principles and patterns to make the code-base maintainable and extensible. You must also develop a deep understanding of non-functional requirements, such as reliability and availability, scale, horizontal scalability, etc. over time and make tech stack decisions accordingly. We are looking for engineers who are well rounded - quality conscious, product thinkers, business cognizant and smart – not mere coders. Engineers get to significantly amplify their impact with the scale that Flipkart operates at.




What you’ll do:

● Design components by translating product requirements, break down project into tasks and

provide accurate estimates

● Independently come up with different solutions, extensible Low level design. Write modular,

extensible, readable and performant code

● Choose the right Data Structures, tools and tech stacks and be able to do High Level

Designing with guidance.

● Build, develop, mentor and coach junior team members

● Collaborate with teams by contributing to the shared vision and working closely with

cross-functional stakeholders.




What you’ll need:

● B.Tech or M.Tech or equivalent with at least 3-year of experience

● Build abstractions and contracts with separation of concerns for a larger scope.

● Extensive programming experience in any one programming language like Java, Ruby, Clojure,

Scala,C or C++, SQL etc

● Strong object-oriented programming skills.

● Experience with multi-threading and concurrency programming

● Ability to work with complex business flows and dealing with huge amounts of data.

● Prior work experience in an agile environment or continuous integration and continuous delivery

(CI or CD)

● Experience of building robust and scalable web-application is good to have.

Show more "
React JS Developer,Infosys,"Chandigarh, Chandigarh, India",Chandigarh,2025-08-09,https://in.linkedin.com/jobs/view/react-js-developer-at-infosys-4282074378?position=12&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=EEqsRderzomTzsvbbvDRsA%3D%3D,"Technology->Reactive Programming->react JS

A day in the life of an Infoscion


As part of the Infosys consulting team, your primary role would be to lead the engagement effort of providing high-quality and value-adding consulting solutions to customers at different stages- from problem definition to diagnosis to solution design, development and deployment.
You will review the proposals prepared by consultants, provide guidance, and analyze the solutions defined for the client business problems to identify any potential risks and issues.
You will identify change Management requirements and propose a structured approach to client for managing the change using multiple communication mechanisms.
You will also coach and create a vision for the team, provide subject matter training for your focus areas, motivate and inspire team members through effective and timely feedback and recognition for high performance.
You would be a key contributor in unit-level and organizational initiatives with an objective of providing high-quality, value-adding consulting solutions to customers adhering to the guidelines and processes of the organization. If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!
Good knowledge on software configuration management systems
Strong business acumen, strategy and cross-industry thought leadership
Awareness of latest technologies and Industry trends
Logical thinking and problem solving skills along with an ability to collaborate
Two or three industry domain knowledge
Understanding of the financial processes for various types of projects and the various pricing models available
Client Interfacing skills
Knowledge of SDLC and agile methodologies
Project and Team management
Show more "
Software Developer,Oracle,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/software-developer-at-oracle-4209903428?position=13&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=s2FQzEdAPB35Oy4F4Lx6wQ%3D%3D,"Job Description

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.We are looking for talented and motivated engineers of all experience levels to join our fast-growing team and take our product to the next level, as we scale up and develop our business.

As a member of our development team, you will be responsible for designing and building components for OCI Object Storage systems. Object Storage is a highly scalable and performant public facing service for storing unlimited amount of unstructured data. Components include Web Servers, Storage Servers, Cloud Gateways, and Bulk Import Appliances. You will own development of new components and features, from initial concepts through design, implementation, test, and operation. Your intelligence and expertise will result in a sense of accomplishment as you create new features as well as oversee their use by customers in a production environment. This is your chance to be part of an exciting new technology that is hot in the market, has many opportunities to work on new features, and is already in demand by customers.

Career Level - IC3

Responsibilities

Responsibilities:


Work with senior architects and Product Management to define requirements
Work with the team to document designs
Implement code, review code written by your peers
Write test automation
Share responsibility with other team members to deploy new code to production.
Work with the team to operate services that host massive amounts of data



Minimum Qualifications:


Proven experience with a major Object Oriented Programming language such as Java or C++
Understanding of data structures and design patterns
Aptitude for problem solving
Experience with RESTful Web Services or Storage Systems is a plus
Experience with massively scalable systems is a plus



About Us

As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s challenges. We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity.

We know that true innovation starts when everyone is empowered to contribute. That’s why we’re committed to growing an inclusive workforce that promotes opportunities for all.

Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs.

We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States.

Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.
Show more "
Software development engineer 1,Amazon,"Gurugram, Haryana, India",Gurugram,2025-08-04,https://in.linkedin.com/jobs/view/software-development-engineer-1-at-amazon-4279597801?position=14&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=eKBR7KuSjwW1jNFydRqVUw%3D%3D,"Description

We started 7 years back with a mission to “transform the way India buys and sells, thereby transforming lives”. Not only have we created strong impact in India taking Amazon to a leadership position, but on this journey we have realised that we as a team are uniquely positioned to help Amazon reach the next billion customers on earth by working backwards from the opportunities presented by emerging customers & selling partners. We are taking those innovations global to other Amazon marketplaces. We continue on our mission to ""transform daily lives and livelihoods, unleashing India's potential"". We also believe that we have an additional responsibility to “help Amazon become truly global in its perspective and innovations” by creating global best-in-class products/platforms that can serve our customers worldwide.

We, at Seller & Fulfilment Tech, build scalable and impactful Amazon-first innovations in the domains of seller experience & success, amazon managed fulfilment, external fulfilment (seller managed), global trade, supply chain, transportation and abuse prevention. We drive improvements across all the key elements of the Amazon flywheel - Selection, Pricing & Speed. We operate with a mental model of ""Get Big, Get Close, Get Fit"" by acting like ""cowboys"" to acquire scale (Get Big), build customer loyalty (Get Close), and improve operational efficiencies (Get Fit).

Talk to us if you want to join us on the journey of “building tech solutions that empower sellers to delight the next billion customers”.

This team defines, design and develop solutions for Fulfilment Center inbounding and Supply Chain Execution process. The optimisation processes thereby improves the fulfilment centre operations, Supply chain processes and delivery experience of our end customers and our Vendors who supply the great selection at Amazon. This also includes ML process to optimise Package free shipments and box/tote recommendations. This is a rare opportunity to be part of a growing team that is driving the growth of the amazon.in business.

This is a contractual position which is ideal for candidates who are looking to deal with scaling challenges at Amazon and ready to build mission critical system software applications and tools. It is also an opportunity for freelance candidates to become domain experts and have an enormous opportunity to make a large impact on the design, architecture and development of consumer products. Depending on individual performance this experience can lead to permanent positions as Software Development Engineers at Amazon.

Key job responsibilities

Designing and implementation of Software

Basic Qualifications


MCA (Masters in Computer Applications) or BS computer science.
1 to 2 year's experience developing highly interactive, internet applications
Good understanding of web design principles and best use of current web technologies and scalable dynamic user interfaces
Expertise in HTML5, CSS3, JavaScript, JSON/XML and web services is essential
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
Passion for writing great, simple, clean, efficient, quality code and solving complex and interesting problems


Preferred Qualifications


Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline
Experience with Photoshop, Illustrator, Ruby, PHP, Perl, SQL, Git and Linux would be considered a plus


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Haryana

Job ID: A3050636
Show more "
Software Developer -1 ( Full Stack),NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-08,https://in.linkedin.com/jobs/view/software-developer-1-full-stack-at-nxtwave-4281548573?position=15&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=7wLUvE6TcBhD%2FD%2BnOSYFbg%3D%3D,"Job Title: Software Developer -1 ( Full Stack)

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
"Software Engineer, Full Stack",DoorDash,"Pune, Maharashtra, India",Pune,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-full-stack-at-doordash-4190988410?position=16&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=BesOizXsOy8kgqjW3czlQw%3D%3D,"About the Team

Data is at the foundation of DoorDash's success. The Engineering team in India builds data tools for our internal and external consumers like Data as a Platform (DaaP) solution - which enables merchants and partners to retrieve the data they need from DoorDash and integrate it with their data pipeline, configuration tool which enables configuration management for ETLs, and few other internal tools to solve other data related use cases.

About the Role

DoorDash is building the world's most reliable on-demand, logistics engine for delivery. We are continuing to grow rapidly and expanding our Engineering offices globally! We are looking for Full Stack Engineers to build and maintain a large-scale scale 24x7 global infrastructure system of telemetry and experimentation that powers DoorDash's 3-sided marketplace of Consumers, Merchants, and Dashers.

As a part of Foundations Data, DoorDash is hiring a Full Stack Software Engineer to build end-to-end solutions for various in-house data applications supporting critical data initiatives. You'll collaborate cross-functionally, with multiple internal stakeholders and help solve complex problems.

We are building the Foundations Data team in India and you will have an opportunity to be part of a rapidly growing team with a greater opportunity for impact where you can help grow the team and shape the roadmap for the data at DoorDash. You will report directly to the Engineering Manager. This role is located in Pune, India. This will be a hybrid position.

You're excited about this opportunity because you will…


Build tools to be used by internal customers for data analytics and configurations.
Partner with Data Analysts, Data Scientists, ML Engineers and Infrastructure engineers to collaborate on exciting projects.
Collaborate with other engineers to support data needs of merchants and aggregators.
Support internal consumers by building solutions.


We're excited about you because you have...


3-5 years of software development experience on tech stacks including React, RESTful APIs/ gRPC and SQL.
Located in Pune, India
Bachelor's or Master's degree in Computer Science or related discipline.
Strong foundation in computer science and engineering: algorithms, data structures, programming, databases, design patterns, virtualization, etc.
Knowledge of frontend technologies such as JavaScript, HTML5, and CSS3, React.
Proficiency in object-oriented programming using Java or Kotlin or Python.
Ability to analyze and improve efficiency, scalability, security, and stability of system resources.
Experience in building large-scale microservice-based architectures + working with cloud services like AWS, GCP, or Azure
Excellent communication and interpersonal skills, and ability to collaborate with remote team members across time zones.


Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

If you need any accommodations, please inform your recruiting contact upon initial connection.

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

If you need any accommodations, please inform your recruiting contact upon initial connection.

We use Covey as part of our hiring and/or promotional process for jobs in certain locations.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: https://getcovey.com/nyc-local-law-144

To request a reasonable accommodation under applicable law or alternate selection process, please inform your recruiting contact upon initial connection.
Show more "
Software Engineering II [Frontend],Microsoft,"Noida, Uttar Pradesh, India",Noida,2025-08-06,https://in.linkedin.com/jobs/view/software-engineering-ii-frontend-at-microsoft-4280939260?position=17&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=LIyDhUgvDdOc0sT03M5SDQ%3D%3D,"At Xbox, we believe in our mission of reaching over 2 billion gamers worldwide.  Gaming today brings people from all walks of life and geographies together—centering them around the thing they love most—GAMES! 

  

The Xbox Experiences and Platform Commerce (XPC) team is responsible for ensuring publishers have low friction access to our ecosystem, rich insights into the publishing experience, and a world class platform to provide their content to Gamers around the world.  We work closely with partner teams across Xbox, as well as both internal and external game studios to further these goals.  We’re always striving to find new and innovative ways of incorporating the latest in design patterns, cloud tech, and machine learning to create better experiences – all while maintaining very high availability services and ensuring the safety and security of our customers’ data. 

We are looking for a Software Engineer to help us build store and creator experiences. In this role you will work with a diverse team of engineers to develop new platform features and deliver innovative gaming experiences in web. You will collaborate with geographically distributed program management, UX design, and engineers to implement and roll out features and solutions that delight our customers.  

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. 

Responsibilities

 Responsibilities include: 


Learn about various tools and technologies and effectively use them to deliver a wide variety of customer experiences.
Implement, validate, and release high quality product features.
Adhere to modern engineering principles and practices. 
Collaborate with other engineers and program managers to make impactful changes. 
Actively contribute to a flexible, diverse, and inclusive culture that brings out the best in the team.


Qualifications

Required: 


BS or MS in Computer Science or equivalent.
3+ years of experience in software development skills building end-user applications
Understanding of data structures, algorithms, threading, synchronization.
Experience building React, Angular or Typescript applications  
Good design and coding skills in JavaScript
A strong interest in bringing end user experiences to a gaming audience and an understanding of their needs 


Preferred:  


Experience using real time data signals to monitor and alert on product health 
Experience shipping web applications using React JS and Typescript  
Experience shipping cross-platform applications using React JS and Typescript  
Understanding of modern web app development against cloud service dependencies  
Technical knowledge and understanding of challenges related to the gaming space, including but not limited to responsive UX design across device form factors, navigational input including gamepad, touch, and mouse/keyboard.  


#GTA

Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
Python Developer,Capgemini,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/python-developer-at-capgemini-4283416622?position=18&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=%2FFXA%2BPMKu2ZEVQQE597Y5A%3D%3D,"Job Description

This role involves the development and application of engineering practice and knowledge in defining, configuring and deploying industrial digital technologies (including but not limited to PLM and MES) for managing continuity of information across the engineering enterprise, including design, industrialization, manufacturing and supply chain, and for managing the manufacturing data.

Job Description - Grade Specific

Focus on Digital Continuity and Manufacturing. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers.
Show more "
Software Engineer,Capgemini,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-at-capgemini-4279445776?position=19&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=5ChTQiuxsSwd6fUI0Z5qwA%3D%3D,"Key responsibilities of an Adobe CJA role include:

Data integration and management: Pulling data from various sources and preparing it for analysis within Adobe CJA.
Customer journey mapping: Visualizing customer interactions across touchpoints to identify key moments and potential pain points.
Advanced analytics: Utilizing CJA features like path analysis, cohort analysis, and attribution modeling to understand customer behavior and campaign effectiveness.
Dashboard development: Creating interactive dashboards to present key customer journey insights to stakeholders.
Reporting and analysis: Interpreting data to generate actionable insights and recommendations for improving customer experience.

Skills and qualifications for an Adobe CJA role:

Technical expertise: Strong understanding of Adobe Analytics platform, including CJA features, data models, and analysis techniques.
Data analysis skills: Proficiency in data manipulation, statistical analysis, and data visualization.
Show more "
Software Engineer,Capgemini,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-at-capgemini-4279451053?position=20&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=he09fi9C68V%2FNg6sxnBJVw%3D%3D,"Key Responsibilities:

Design and develop Agentic AI architectures that can autonomously plan, reason, and execute tasks.

Implement multi-agent communication protocols for agent-to-agent collaboration and coordination.

Work with Large Language Models (LLMs) such as LLaMA, GPT, etc., for language understanding, generation, and task planning.

Develop and integrate Retrieval-Augmented Generation (RAG) pipelines to enhance the reasoning capability of agents with external knowledge.

Perform fine-tuning of foundational models for specific domains, tasks, or use cases.

Design and experiment with lightweight models (e.g., Phi, Tiny LLMs) for efficiency in real-time or on-device scenarios.

Collaborate cross-functionally with Data Scientists, ML Engineers, and Product Teams to deliver end-to-end AI solutions.

Conduct rigorous testing and evaluation of agent behaviors, decision-making, and performance.







Must-Have Qualifications:

Proven experience in developing and deploying Agentic AI systems.

Strong experience with LLMs, particularly Meta’s LLaMA family or similar open-source models.

Hands-on experience with RAG (Retrieval-Augmented Generation) architectures and related tools like LangChain, Haystack, etc.

Knowledge and experience with model fine-tuning using frameworks like HuggingFace Transformers, PEFT, or LoRA.

Experience in implementing agent-to-agent communication frameworks and multi-agent task handling systems.

Proficiency in Python and AI/ML libraries such as PyTorch, TensorFlow, Transformers, etc.

Familiarity with prompt engineering and chaining logic for LLMs.

Show more "
Software Engineer,Capgemini,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-at-capgemini-4279449375?position=21&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=l11Tvt2DVXwWlO0bqG%2FkpA%3D%3D,"Develop and implement Generative AI / AI solutions on Google Cloud Platform
Work with cross-functional teams to design and deliver AI-powered products and services
Work on developing, versioning and executing Python code
Deploy models as endpoints in Dev Environment
Must Have Skills
Solid understanding of python
Experience with deep learning frameworks such as TensorFlow, PyTorch, or JAX
Experience with natural language processing (NLP) and machine learning (ML)
Experience on Cloud storage, compute engine, VertexAI, Cloud Function, Pub/Sub, Vertex AI etc
Hands on experience with Generative AI support in Vertex, specifically handson experience with Generative AI models like Gemini, vertex Search etc
Familiarity with Prompt Design and prompt tuning for Generative AI models
Ability to work on Vector Data Stores, custom embeddings and generate insights based on embeddings
Exposure and familiarity in developing endpoints and frameworks like Flask or FastAPI
Exposure and familiarity in using BigQuery (Basic understanding)
Hands-on experience with using LangChain - Chain of Thoughts, tools, simple and sequential chain

Show more "
Software Developer -1 ( Full Stack),NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-09,https://in.linkedin.com/jobs/view/software-developer-1-full-stack-at-nxtwave-4281551261?position=22&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=rZvRaWBa0HLKp%2Bc4LyhvoA%3D%3D,"Job Title: Software Developer -1 ( Full Stack)

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
Associate Software Engineer,Capgemini,"Hyderabad, Telangana, India",Hyderabad,2025-08-11,https://in.linkedin.com/jobs/view/associate-software-engineer-at-capgemini-4283164442?position=23&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=iGmzjTay6Ldo4sY17LyQSw%3D%3D,"Job Description

Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.


Applies scientific methods to analyse and solve software engineering problems.
He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.
His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.
The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.
The software engineer collaborates and acts as team player with other software engineers and stakeholders.


Job Description - Grade Specific

Is the entry level in Software Engineering with a foundational understanding on programming concepts, software design and software development principles. Consistently works to direction with reducing supervision, producing accurate and reliable results. They are expected to be eager to learn and know when to ask questions and check for understanding. Understands and follows work processes. Is aware of costs related to own work. Organises own time to deliver against tasks set by others with a short term horizon. Works co-operatively with others to achieve team goals and has a direct and positive impact on project performance. Actively seeking feedback to improve and starting to manage own career with support.
Show more "
Software Developer,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-02,https://in.linkedin.com/jobs/view/software-developer-at-nxtwave-4277153455?position=24&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=0vqqZbsENmJEQ68Z3BVexg%3D%3D,"Job Title: Software Developer

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
SDE-I,Amazon,"Chennai, Tamil Nadu, India",Chennai,2025-08-11,https://in.linkedin.com/jobs/view/sde-i-at-amazon-4184001188?position=25&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=9BP2iJ%2Fr3tajhz8dYJIiQw%3D%3D,"Description

We are looking for passionate and talented software engineers who have experience building innovative, critical, high volume applications that customers love. This is a high visibility team where you will get a chance to make a positive impact on customer experience.

IES Payments Tech Team’s vision is to delight our customers with the best payment experience in the world! To achieve this vision, we are in search of a talented technical engineer and craftsman who builds robust software that scales as well as client-facing features which are intuitive and simple to use.

Our team takes a world view of payments for all of Amazon and builds highly customized and seamless payment experiences for our global customers. This focus on geography and customer requires working on different technologies & back-end systems in order to meet the needs of our customers. Our back-end systems are always available and guarantee that our customer’s orders are never lost and always processed even when downstream services are down.

Our team is highly motivated and in need of a engineer who can take the technical reigns of the team and steer them in the direction of our vision.

You are a technical leader and craftsman with a proven track record of successful delivery. You are someone who will enjoy the challenge of working on complex and highly disparate technologies – from front-end Android development to back-end highly distributed systems. You are security-conscious and continually analyze software for potential threats to safeguard customer trust. You are interested in a high growth career opportunity and enjoy building software that brings smiles to our customers

Key job responsibilities


Work with the team to help solve business problems.
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, durability, cost, and security.
Use software engineering best practices to ensure a high standard of quality for all of the team deliverables.
Write high quality distributed system software.
Work in an agile, startup-like development environment, where you are always working on the most important stuff.


Basic Qualifications


1+ years of non-internship professional software development experience
1+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language


Preferred Qualifications


1+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Tamil Nadu

Job ID: A2926391
Show more "
Full Stack Developer - 1,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-11,https://in.linkedin.com/jobs/view/full-stack-developer-1-at-nxtwave-4282493197?position=26&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=EG5SrHxIPOhiSeOiBJdhvA%3D%3D,"Job Title: Full Stack Developer - 1

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
App Developer-Low Code,Microsoft,"Haryana, India",Haryana,2025-08-06,https://in.linkedin.com/jobs/view/app-developer-low-code-at-microsoft-4280812901?position=27&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=ELyNixk%2BbGcCzO4aFaN5PQ%3D%3D,"The Business & Industry Copilots group is a rapidly growing organization that is responsible for the Microsoft Dynamics 365 suite of products, Power Apps, Power Automate, Dataverse, AI Builder, Microsoft Industry Solution and more. Microsoft is considered one of the leaders in Software as a Service in the world of business applications and this organization is at the heart of how business applications are designed and delivered.

Join our dynamic team as a Low Code Engineer, where you'll play a pivotal role in driving innovation and efficiency through low-code/no-code solutions. You'll collaborate with cross-functional teams to develop and deploy advanced automated workflows, enhance user interactions, and lead the integration of AI agents within production services.

This is an exciting time to join our group Customer Experience - CXP and work on something highly strategic to Microsoft. The goal of the Customer Experience - CXP Engineering is to build the next generation of our applications running on Dynamics 365, AI, Copilot, and several other Microsoft cloud services to deliver high value, complete, and Copilot-enabled application scenarios across all devices and form factors. We innovate quickly and collaborate closely with our partners and customers in an agile, high-energy environment. Leveraging the scalability and value from Azure & Power Platform, we ensure our solutions are robust and efficient. If the opportunity to collaborate with a diverse engineering team, on enabling end-to-end business scenarios using cutting-edge technologies and to solve challenging problems for large scale 24x7 business SaaS applications excite you, please come and talk to us!

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond. 

To succeed in this role you will need to :


Solve Problems with Analytical Approach- Extracting actionable insights to understand their implications within the solution context; solving problems and making decisions through a swift, informed, and strategic approach.
Craft Automated Business Solutions-Developing solutions by employing low-code/no-code solutions and guiding projects through development to ensure alignment with business requirements.
Create Robust Low-Code/No-Code Solutions-Leveraging computer science principles to design, develop, and optimize scalable business applications with low-code/no-code solutions.
Drive Effective Stakeholder Relationships-Fostering a cooperative environment across diverse teams and stakeholders, influencing and managing social relationships and interactions to ensure clear understanding and alignment of mutual goals for program success.


Responsibilities

Low Code Solution Devlopment and Deploymnet


Engage with stakeholders to understand business objectives and translate them into program requirements and technical specifications.
Serve as a liaison between business and technical teams to ensure alignment of technical specifications with business goals.
Collaborate with product management, business stakeholders, and engineering teams to identify and address gaps with low-code/no-code solutions (e.g., Power Platforms).
Design application solutions using configurations established in low-code/no-code platforms (e.g., Power Automate) and develop advanced automated workflows.
Lead design and code reviews within the team and support the development of technical best practices and architectural guidelines.


User Support


Develop production services by configuring settings utilizing low-code/no-code solutions to meet stakeholder needs.
Coordinate the integration of AI agents within production services to enhance user interactions.
Develop rules that govern production services logic and workflows to ensure the application adapts to complex business processes and regulatory requirements.
Lead incident reviews and propose automation to prevent future issues.
Develop and deliver training sessions and materials on the capabilities of low-code/no-code solutions.


Industry Knowledge


Proactively research emerging trends and innovations in the low-code/no-code solution industry.
Evaluate new tools, platforms, and updates to assess their potential for improving efficiency, scalability, and functionality of the development process.


Qualifications

Required Qualifications


Bachelor's Degree AND atleast 1 yr of experience to maximum 3 years experience in low-code application development, engineering product/technical program management, data analysis, or product development


OR equivalent experience

Preferred Qualifications


Bachelor's Degree AND atleast 1 years experience in low-code application development, engineering product/technical program management, data analysis, or product development


OR equivalent experience


Atleast 1 year of experience using low-code/no-code programs (e.g., Dataverse, Power Applications).
Atleast 1 year of experience managing and configuring artificial intelligence solutions (e.g., chatbots).
Atleast 1 year of experience with programming/coding.
Certification with Microsoft platforms (e.g., Azure, Microsoft 365) or equivalent.
Project management certification (e.g., Project Management Professional, Six Sigma).


Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
Show more "
SDE(Full Stack)-2,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-04,https://in.linkedin.com/jobs/view/sde-full-stack-2-at-nxtwave-4260667389?position=28&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=Y4fOEw6jO16KgnIITFWZrw%3D%3D,"As a Fullstack SDE - II at NxtWave, you




Build applications at a scale and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Lead design and delivery of complex end-to-end features across frontend, backend, and data layers.
Make strategic architectural decisions on frameworks, datastores, and performance patterns.
Review and approve pull requests, enforcing clean-code guidelines, SOLID principles, and design patterns.
Build and maintain shared UI component libraries and backend service frameworks for team reuse.
Identify and eliminate performance bottlenecks in both browser rendering and server throughput.
Instrument services with metrics and logging, driving SLIs, SLAs, and observability.
Define and enforce comprehensive testing strategies: unit, integration, and end-to-end.
Own CI/CD pipelines, automating builds, deployments, and rollback procedures.
Ensure OWASP Top-10 mitigations, WCAG accessibility, and SEO best practices.
Partner with Product, UX, and Ops to translate business objectives into technical roadmaps.
Facilitate sprint planning, estimation, and retrospectives for predictable deliveries.
Mentor and guide SDE-1s and interns; participate in hiring.

Qualifications & Skills

3–5 years building production Full stack applications end-to-end with measurable impact.
Proven leadership in Agile/Scrum environments with a passion for continuous learning.
Deep expertise in React (or Angular/Vue) with TypeScript and modern CSS methodologies.
Proficient in Node.js (Express/NestJS) or Python (Django/Flask/FastAPI) or Java (Spring Boot).
Expert in designing RESTful and GraphQL APIs and scalable database schemas.
Knowledge of MySQL/PostgreSQL indexing, NoSQL (ElasticSearch/DynamoDB), and caching (Redis).
Knowledge of Containerization (Docker) and commonly used AWS services such as lambda, ec2, s3, api gateway etc.
Skilled in unit/integration (Jest, pytest) and E2E testing (Cypress, Playwright).
Frontend profiling (Lighthouse) and backend tracing for performance tuning.
Secure coding: OAuth2/JWT, XSS/CSRF protection, and familiarity with compliance regimes.
Strong communicator able to convey technical trade-offs to non-technical stakeholders.
Experience in reviewing pull requests and providing constructive feedback to the team.

Qualities we'd love to find in you:




The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus

Work Location: Hyderabad







About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education

NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
Frontend Developer,Capco,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/frontend-developer-at-capco-4281809837?position=29&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=liE5xokw%2BGUReA5Ynf49jA%3D%3D,"About Us

“Capco, a Wipro company, is a global technology and management consulting firm. Awarded with Consultancy of the year in the British Bank Award and has been ranked Top 100 Best Companies for Women in India 2022 by Avtar & Seramount. With our presence across 32 cities across globe, we support 100+ clients across banking, financial and Energy sectors. We are recognized for our deep transformation execution and delivery.

WHY JOIN CAPCO?

You will work on engaging projects with the largest international and local banks, insurance companies, payment service providers and other key players in the industry. The projects that will transform the financial services industry.

MAKE AN IMPACT

Innovative thinking, delivery excellence and thought leadership to help our clients transform their business. Together with our clients and industry partners, we deliver disruptive work that is changing energy and financial services.

#BEYOURSELFATWORK

Capco has a tolerant, open culture that values diversity, inclusivity, and creativity.

CAREER ADVANCEMENT

With no forced hierarchy at Capco, everyone has the opportunity to grow as we grow, taking their career into their own hands.

DIVERSITY & INCLUSION

We believe that diversity of people and perspective gives us a competitive advantage.

Job Title: Frontend Developer

Job Requirements:

Work location: Bengaluru

Working Hours: 12:30 PM – 9:30 PM IST

Role Description

Should be primarily experienced in backend development and should be able to design, create, and implement a solution that is domain-driven, abstracted, business-oriented, and scalable from scratch, while also able to debug & fix issues.

• Core Skills:

Hard Skills:

• C#/.NET (Primary), Azure Functions, T-SQL/SQL Server (inline SQL), REST APIs, Dependency Injection, OpenAPI documentation.

Nice to have:

• JWT, Azure APIM, Azure Data Factory, Azure Service Bus, Redis Caching, CI/CD YAML, Advanced Git

Competencies:

• API Development: Strong ability to build clean, well-documented, and secure REST APIs that adhere to our architectural standards.

• Database Interaction: Proficient in writing performant SQL queries and managing database schemas.

• Quality First: A commitment to writing unit and integration tests as part of their daily workflow, using frameworks like xUnit and/or NUnit.

• Reliability: Focuses on building reliable services with robust error handling, logging, and monitoring.




If you are keen to join us, you will be part of an organization that values your contributions, recognizes your potential, and provides ample opportunities for growth. For more information, visit www.capco.com. Follow us on Twitter, Facebook, LinkedIn, and YouTube.

Show more "
SDE - I,Navi,"Bengaluru, Karnataka, India",Bengaluru,2025-08-12,https://in.linkedin.com/jobs/view/sde-i-at-navi-4283385486?position=30&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=q9pUriDL39CqZa29Js2gyQ%3D%3D,"About the Team

Navi’s Engineering team builds the backbone of our financial products—spanning lending, payments, insurance, investments, and debt management. We operate as cross-functional teams that work closely with Product, Data, and Business functions to deliver reliable, high-performance systems at scale. Our engineers focus on solving real-world challenges through scalable architecture, automation, and long-term thinking—ensuring every Navi product is built to serve millions efficiently and seamlessly.




About the Role

This role involves building and maintaining robust backend systems, solving real-world technical challenges, and optimizing performance. It requires strong foundations in clean coding practices, peer reviews, and agile development. Best suited for someone who values ownership, quality, and adaptability in a high-performance environment.




What We Expect From You

Key Responsibilities

Implement assigned features and changes through performant and maintainable code, with appropriate test coverage (unit, contract, component).
Understand the design and architecture of the component/service and implement low-level designs (LLDs) following best practices.
Perform effective code reviews for peers.
Consider customer experience and product performance in implementation.
Develop awareness of how your work impacts key product metrics.
Handle on-call responsibilities effectively within the team.
Contribute to RCA discussions and support RCA documentation.
Proactively gather and understand requirements for assigned features.
Ask questions, clarify uncertainties, and document requirements accurately.
Collaborate effectively with developers in the team to implement features with quality.




Must Haves

Proficiency in at least one of the following languages: Java, Go, or Kotlin
Solid understanding of object-oriented design, design patterns, and data structures
Experience in implementing algorithms to solve real-world problems
Proven track record in building and maintaining backend systems
Ability to troubleshoot and optimize backend systems for better performance
Learn and contribute to distributed system design under mentorship.
Demonstrated expertise in unit testing, peer code reviews, and familiarity with agile methodologies
Good verbal and written communication and interpersonal skills
A history of delivering on-time with a focus on quality output
Emphasis on observability, ensuring systems are well-monitored and maintainable
At least 1+ years of software development experience




Preferred Skills

Familiarity with event-driven architectures and messaging systems (e.g., Kafka, RabbitMQ)
Knowledge of security best practices for backend services and API endpoints
Ability to quickly adapt to new and complex development environments
Strong analytical skills with the ability to deep dive into technical challenges




Inside Navi

We are shaping the future of financial services for a billion Indians through products that are simple, accessible, and affordable. From Personal & Home Loans to UPI, Insurance, Mutual Funds, and Gold — we’re building tech-first solutions that work at scale, with a strong customer-first approach.




Founded by Sachin Bansal & Ankit Agarwal in 2018, we are one of India’s fastest-growing financial services organisations. But we’re just getting started!




Our Culture

The Navi DNA

Ambition. Perseverance. Self-awareness. Ownership. Integrity.

We’re looking for people who dream big when it comes to innovation. At Navi, you’ll be empowered with the right mechanisms to work in a dynamic team that builds and improves innovative solutions. If you’re driven to deliver real value to customers, no matter the challenge, this is the place for you.

We chase excellence by uplifting each other—and that starts with every one of us.




Why You'll Thrive at Navi

At Navi, it’s about how you think, build, and grow. You’ll thrive here if:

You’re impact-driven : You take ownership, build boldly, and care about making a real difference.
You strive for excellence : Good isn’t good enough. You bring focus, precision, and a passion for quality.
You embrace change : You adapt quickly, move fast, and always put the customer first.

Show more "
Associate Software Engineer,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-06,https://in.linkedin.com/jobs/view/associate-software-engineer-at-nxtwave-4279990753?position=31&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=ISvdqt0z0h8CkUKo5a%2FB0w%3D%3D,"Job Title: Associate Software Developer

As a Fullstack SDE1 at NxtWave, you

Get first hand experience of building applications and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Design, implement, and ship user-centric features spanning frontend, backend, and database systems under guidance.
Define and implement RESTful/GraphQL APIs and efficient, scalable database schemas.
Build reusable, maintainable frontend components using modern state management practices.
Develop backend services in Node.js or Python, adhering to clean-architecture principles.
Write and maintain unit, integration, and end-to-end tests to ensure code quality and reliability.
Containerize applications and configure CI/CD pipelines for automated builds and deployments.
Enforce secure coding practices, accessibility standards (WCAG), and SEO fundamentals.
Collaborate effectively with Product, Design, and engineering teams to understand and implement feature requirements..
Own feature delivery from planning through production, and mentor interns or junior developers.




Qualifications & Skills

1+ years of experience building full-stack web applications.
Proficiency in JavaScript (ES6+), TypeScript, HTML5, and CSS3 (Flexbox/Grid).
Advanced experience with React (Hooks, Context, Router) or equivalent modern UI framework.
Hands-on with state management patterns (Redux, MobX, or custom solutions).
Strong backend skills in Node.js (Express/Fastify) or Python (Django/Flask/FastAPI).
Expertise in designing REST and/or GraphQL APIs and integrating with backend services.
Solid knowledge of MySQL/PostgreSQL and familiarity with NoSQL stores (Elasticsearch, Redis).
Experience using build tools (Webpack, Vite), package managers (npm/Yarn), and Git workflows.
Skilled in writing and maintaining tests with Jest, React Testing Library, Pytest, and Cypress.
Familiar with Docker, CI / CD tools (GitHub Actions, Jenkins), and basic cloud deployments.
Product-first thinker with strong problem-solving, debugging, and communication skills.




Qualities we'd love to find in you:

The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus




Work Location: Hyderabad




About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education




NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
Software Development Engineer (Python),Adobe,"Noida, Uttar Pradesh, India",Noida,2025-08-07,https://in.linkedin.com/jobs/view/software-development-engineer-python-at-adobe-4281337051?position=32&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=yH35rAprNDJl%2BYI7gjOjTw%3D%3D,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Our Company

Changing the world through digital experiences is what Adobe's all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We're passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We're on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Adobe Document Cloud Services in building cloud services and cloud platform from ground up to help Adobe expand the footprint of Adobe Document Cloud to billions of users across devices and surfaces. With all the innovation happening in machine learning domain around Documents, Adobe Document Cloud is leading and redefining the way world interacts with documents and document workflows.

Adobe Document Cloud Services team is looking for a dedicated, highly motivated engineer and technical problem solver to join a high-caliber fast paced team. The engineer is encouraged to have deep experience of building low latency, high performance distributed ML services and systems.

What you will do:


Contribute to the development and deployment of ML services from zero to production.
Assist in designing, developing, and testing large-scale, high-performance ML services serving users worldwide.


What You Need To Succeed


Min. 2+ years of experience in software engineering.
Proficiency in Python.
B.S./B.E./B.Tech. in Computer Science or an equivalent engineering degree.
Understanding of distributed systems and RESTful service development
Excellent software design skills
Strong problem-solving skills.
Able to communicate technical details clearly
Motivated self-starter with the ability to learn and adapt to new technologies
Work closely and seamlessly with various engineering teams, product management, experience design and quality engineering to ensure we deliver great compelling solutions.
At ease with ambiguity and able to adapt and change direction/technologies to leverage new learnings.
Be a mentor and role model for junior engineers.


Preferred skills:


Exposure to ML services or LLMs.
Experience with backend development in Python.
Familiarity with CI/CD processes and DevOps practices.
Basic knowledge of Docker and Kubernetes.
Exposure to monitoring tools like New Relic, Grafana, etc.


More reasons why Adobe life is the good life

At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely.

If you're looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer. Adobe is an equal opportunity employer.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Show more "
React JS,Virtusa,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-13,https://in.linkedin.com/jobs/view/react-js-at-virtusa-4256682272?position=33&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=P0qlCwq68nE%2F2WoPl2OJeA%3D%3D,"Responsibilities

Develop and maintain web applications using HTML5, CSS, and JavaScript.

Utilize SCSS, Bootstrap Tailwind CSS and jQuery to create responsive and visually appealing designs.

Build and manage complex front-end architectures with React Webpack and TypeScript

Ensure code quality and consistency using tools like Visual Studio Code Eslint Flow and Prettier

Collaborate with back end developers to integrate Node js services

Write and maintain unit and integration tests using Jest and Enzyme

Develop and document UI components with StoryBook

Manage state using Redux MobX and Recoil

Implement GraphQL APIs with Nexus

Utilize PrimeReact for UI components

Conduct end-to-end testing with Cypress and Puppeteer

Manage project dependencies and scripts using npm

Requirements

Proven experience as a Front-End Developer or similar role

Proficiency in HTML5 CSS JavaScript, and modern front-end frameworks.

Experience with SCSS Bootstrap Tailwind CSS and jQuery

Strong knowledge of React Webpack and TypeScript

Familiarity with Visual Studio Code Eslint Flow and Prettier

Experience with Node.js and related frameworks

Proficient in testing frameworks like Jest and Enzyme

Experience with StoryBook for UI component development

Knowledge of state management libraries such as Redux MobX and Recoil

Familiarity with GraphQL and Nexus

Experience With Prime React And Other UI Component Libraries

Proficiency in end to end testing tools like Cypress and Puppeteer

Strong understanding of npm and package management

Preferred Qualifications

Bachelors degree in Computer Science Information Technology or a related field

Excellent problem solving skills and attention to detail

Strong communication and teamwork abilities

Ability to work in a fast-paced and dynamic environment
Show more "
Software Development Engineer -II (Backend),Groww,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/software-development-engineer-ii-backend-at-groww-4279460207?position=34&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=JErW80zELwa9W8wjy%2F4IeQ%3D%3D,"About Groww:

We are a passionate group of people focused on making financial services accessible to every Indian through a multi-product platform. Each day, we help millions of customers take charge of their financial journey. Customer obsession is in our DNA. Every product, every design, every algorithm down to the tiniest detail is executed keeping the customersʼ needs and convenience in

mind. Our people are our greatest strength. Everyone at Groww is driven by ownership, customer-centricity, integrity and the passion to constantly challenge the status quo.

Are you as passionate about defying conventions and creating something extraordinary as we are? Letʼs chat.




Our Vision

Every individual deserves the knowledge, tools, and confidence to make informed financial decisions. At Groww, we are making sure every Indian feels empowered to do so through a cutting-edge multi-product platform offering a variety of financial services.

Our long-term vision is to become the trusted financial partner for millions of Indians.




Our Values

Our culture enables us to be what we are — Indiaʼs fastest-growing financial services company. It fosters an environment where collaboration, transparency, and open communication take center-stage and hierarchies fade away. There is space for every individual to be themselves and feel motivated to bring their best to the table, as well as craft a promising career for themselves.

The values that form our foundation are:

• Radical customer centricity

• Ownership-driven culture

• Keeping everything simple

• Long-term thinking

• Complete transparency




EXPERTISE AND QUALIFICATIONS

What youʼll do

The Software Development Engineer's core responsibilities include working on highly maintainable and unit-tested software components/systems that address real-world problems.

• Experienced in microservices-based architecture, can work on cloud infrastructures like GCP, AWS, etc

• Should take the e2e ownership of product/feature right from design, code, and deployment.

• Ensure quality at every level be it problem-solving, design, code, or bug fixes.

•Should be able to collaborate with product managers, architects, and other stakeholders to ensure smooth execution of sprints.

• Own and unblock users on production issues, able to troubleshoot and fix production issues on priority.

• Can mentor and help other team members and ensure that the overall productivity of the team is high.




What are we looking for :

• Bachelor’s / Master's degree in Computer Science Engineering or allied branches, or equivalent experience.

• 3-5 years of experience in building scalable restful/soap microservice services.

• Good at LLD/HLD and implementation. Understanding of design patterns.

• Strong problem-solving skills.

• Good understanding of data structures & algorithms and their space & time complexities.

• Strong hands-on and practical working experience with Java and Springboot

• Excellent coding skills - should be able to convert the design into code fluently.

• Strong technical aptitude and a good knowledge of CS fundamentals.

You are expected to demonstrate good learnability and adopt technologies that help build large-scale, performant, reliable, and sustainable systems.

Show more "
Software development engineer 1,Amazon,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/software-development-engineer-1-at-amazon-4279478221?position=35&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=MPWyNPTgC9y%2BdyCF30f4Kw%3D%3D,"Description

Come and be the pioneer of Amazon NA Supply Chain technology innovation!

If you are looking for an opportunity to solve deep technical problems and build innovative solutions in a fast-paced environment while working with smart, passionate business & technical leaders, then this might be the role for you.

At Amazon, we are committed to being the most customer-centric company on earth. North America Supply Chain (NASC) Planning & Execution org is comprised of dynamic teams that shape network planning and execution through the development and application of innovative mechanisms and techniques. Our goal is to enhance the Amazon Fulfilment network to ultimately drive the best customer experience in a reliable and cost-efficient manner that is truly a world-class. NASC is aggressively innovating in a number of areas aimed at propelling our customers’ experience by ensuring that we have robust plans in North America Operations and beyond for optimal execution. NASC tech team is hiring a Software Development Engineer (SDE I) who will be at the centre of the development of state-of-the-art product suites and make a long-lasting footprint on our organization's path towards Hands Off the Wheel automated optimization.

Our newly developed software systems will include services that make business decisions in NACF Operations that impact billions of dollars per year, integrate with upstream and downstream systems across the supply chain network, manage business rules to enable strategic planning for network-level operational capacity, and improve experience for millions of online shoppers. We have an opportunity to build software that scales the business, leads the industry through innovation and delights millions of customers worldwide. We will leverage cutting edge technologies in big data, optimization techniques, machine learning, real time analytics and high volume, low latency, high availability services.

This is a contractual position which is ideal for candidates who are looking to deal with scaling challenges at Amazon and ready to build mission critical system software applications and tools. It is also an opportunity for freelance candidates to become domain experts and have an enormous opportunity to make a large impact on the design, architecture and development of consumer products. Depending on individual performance this experience can lead to permanent positions as Software Development Engineers at Amazon.

Key job responsibilities

Designing and implementation of Software

Basic Qualifications


MCA (Masters in Computer Applications) or BS computer science.
1 to 2 year's experience developing highly interactive, internet applications
Good understanding of web design principles and best use of current web technologies and scalable dynamic user interfaces
Expertise in HTML5, CSS3, JavaScript, JSON/XML and web services is essential
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
Passion for writing great, simple, clean, efficient, quality code and solving complex and interesting problems


Preferred Qualifications


Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline
Experience with Git, Linux, aWS and Java would be considered a plus


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Karnataka

Job ID: A3049168
Show more "
Software Developer - Frontend,IBM,"Pune, Maharashtra, India",Pune,2025-08-12,https://in.linkedin.com/jobs/view/software-developer-frontend-at-ibm-4268545364?position=36&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=IEQunG6NWd0OUVPZw2nLcw%3D%3D,"Introduction

The IBM Ceph Storage team is seeking a talented Frontend Developer to join our team. The ideal candidate will have experience with Angular, TypeScript, JavaScript, SCSS, and Python. The successful candidate will be responsible for designing, developing, and maintaining the frontend of our Ceph management application.

Your Role And Responsibilities


Design and develop high-quality, scalable, and maintainable frontend code using Angular, TypeScript, and SCSS
Collaborate with other Ceph teams to ensure seamless integration and provide the best user experience for the consumer
Develop and maintain reusable UI components and libraries
Participate in code reviews and contribute to the improvement of the codebase
Troubleshoot and resolve frontend-related issues
Stay up-to-date with the latest frontend technologies and trends
Work closely with the design team to ensure visually appealing and user-friendly


Preferred Education

Associate's Degree/College Diploma

Required Technical And Professional Expertise


2+ years of experience in frontend development
Strong knowledge of Angular, TypeScript, JavaScript, SCSS, and HTML/CSS
Should have hands-on experince with Linux
Experience with version control systems such as Git
Strong problem-solving skills and attention to detail
Excellent communication and collaboration skills
Ability to work in a fast-paced environment and prioritize tasks effectively


Preferred Technical And Professional Experience


Experience with backend development, especially in Python
Knowledge of DevOps practices and tools
Familiarity with containerization using Docker
Experience with testing frameworks such as Jest or Cypress
Knowledge of accessibility guidelines and best practices
Show more "
Software development engineer 1,Amazon,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/software-development-engineer-1-at-amazon-4279472757?position=37&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=9E91NGf%2BOI1Xajqwfnvxvw%3D%3D,"Description

Come and be the pioneer of Amazon NA Supply Chain technology innovation!

If you are looking for an opportunity to solve deep technical problems and build innovative solutions in a fast-paced environment while working with smart, passionate business & technical leaders, then this might be the role for you.

At Amazon, we are committed to being the most customer-centric company on earth. North America Supply Chain (NASC) Planning & Execution org is comprised of dynamic teams that shape network planning and execution through the development and application of innovative mechanisms and techniques. Our goal is to enhance the Amazon Fulfilment network to ultimately drive the best customer experience in a reliable and cost-efficient manner that is truly a world-class. NASC is aggressively innovating in a number of areas aimed at propelling our customers’ experience by ensuring that we have robust plans in North America Operations and beyond for optimal execution. NASC tech team is hiring a Software Development Engineer (SDE I) who will be at the centre of the development of state-of-the-art product suites and make a long-lasting footprint on our organization's path towards Hands Off the Wheel automated optimization.

Our newly developed software systems will include services that make business decisions in NACF Operations that impact billions of dollars per year, integrate with upstream and downstream systems across the supply chain network, manage business rules to enable strategic planning for network-level operational capacity, and improve experience for millions of online shoppers. We have an opportunity to build software that scales the business, leads the industry through innovation and delights millions of customers worldwide. We will leverage cutting edge technologies in big data, optimization techniques, machine learning, real time analytics and high volume, low latency, high availability services.

This is a contractual position which is ideal for candidates who are looking to deal with scaling challenges at Amazon and ready to build mission critical system software applications and tools. It is also an opportunity for freelance candidates to become domain experts and have an enormous opportunity to make a large impact on the design, architecture and development of consumer products. Depending on individual performance this experience can lead to permanent positions as Software Development Engineers at Amazon.

Key job responsibilities

Designing and implementation of Software

Basic Qualifications


MCA (Masters in Computer Applications) or BS computer science.
1 to 2 year's experience developing highly interactive, internet applications
Good understanding of web design principles and best use of current web technologies and scalable dynamic user interfaces
Expertise in HTML5, CSS3, JavaScript, JSON/XML and web services is essential
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
Passion for writing great, simple, clean, efficient, quality code and solving complex and interesting problems


Preferred Qualifications


Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline
Experience with Git, Linux, aWS and Java would be considered a plus


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Karnataka

Job ID: A3049567
Show more "
Backend Developer - SDE 2,Groww,Greater Bengaluru Area,Greater Bengaluru Area,2025-08-12,https://in.linkedin.com/jobs/view/backend-developer-sde-2-at-groww-4283381973?position=38&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=aWegYY3gZC7nfxpTrncSrA%3D%3D,"About Groww

We are a passionate group of people focused on making financial services accessible to every Indian through a multi-product platform. Each day, we help millions of customers take charge of their financial journey.

Customer obsession is in our DNA. Every product, every design, every algorithm down to the tiniest detail is executed keeping the customers’ needs and convenience in mind.

Our people are our greatest strength. Everyone at Groww is driven by ownership, customer-centricity, integrity and the passion to constantly challenge the status quo.

Are you as passionate about defying conventions and creating something extraordinary as we are? Let’s chat.




Our Vision

Every individual deserves the knowledge, tools, and confidence to make informed financial decisions. At Groww, we are making sure every Indian feels empowered to do so through a cutting-edge multi-product platform offering a variety of financial services.

Our long-term vision is to become the trusted financial partner for millions of Indians.




Our Values

Our culture enables us to be what we are — India’s fastest-growing financial services company. It fosters an environment where collaboration, transparency, and open communication take center-stage and hierarchies fade away. There is space for every individual to be themselves and feel motivated to bring their best to the table, as well as craft a promising career for themselves.




The values that form our foundation are:

Radical customer centricity
Ownership-driven culture
Keeping everything simple
Long-term thinking
Complete transparency




As a Backend Engineer, you will:

The Software Development Engineer's core responsibilities include working on highly maintainable and unit-tested software components/systems that address real-world problems.
You will be working in a fast-paced and agile work environment delivering quality solutions that have an immediate business impact.
Complete ownership of the projects you deliver while collaborating with technical and non-technical stakeholders on all elements of the development process.




What are we looking for :

3+ years experience.
Strong problem-solving skills.
Good understanding of data structures & algorithms and their space & time complexities.
Hands-on solid and practical working experience with Java.
Excellent coding skills - should be able to convert the design into code fluently.
Strong technical aptitude and a good knowledge of CS fundamentals.
B Tech in Computer Science or equivalent from a reputed college.
You are expected to demonstrate good learnability and adopt technologies that help build large-scale, performant, reliable and sustainable systems.

Show more "
Software Engineer,NVIDIA,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/software-engineer-at-nvidia-4257830695?position=39&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=MSL7x%2BsHzIJRkCIeRfZYRg%3D%3D,"The NVIDIA SW groups are looking for a highly motivated, dynamic Software Engineer to help us develop/test/automate/implement softwares for our cutting-edge technology. Are you passionate about new technology and looking forward to work on next-generation NVIDIA Products? Do you love to provide innovative solutions and have fun while working on complex problems. Nvidia is looking for great software engineers like you to join us in our engineering groups.

What You'll Be Doing


Work on the complete Product life cycle and in-process design, develop build, and improve our software stack.
Triage and debug complex issues.
Improve the system performance of Nvidia products.
Building and customizing existing infrastructure to enable the effort of system tunning, debugging, automation, and validation across workloads.
Analyzing performance bottlenecks and implementing optimization techniques.
Collaborate with various teams on new product features and improvements of existing products.


What We Need To See


BTECH/MTECH with 3+ years of experience in C/C++ /Python/Java/Golang
Strong programming skills, OOPS, Data structures, and Algorithms.
Experience in Windows / Linux / embedded OS environment.
Excellent problem-solving and analytical skills.
If you have experience in at least a few of the following areas, we will have an excellent match for our needs:
System Software /Embedded/Firmware/Device Driver/Kernel.
Cloud/UI/Full-Stack/Backend/Distributed Systems
SRE/DevOps/Kubernetes
Automation/Tools development/Test development
AI/ML/LLM/DL/Speech/NLP
Good interpersonal skills and ability to work as an excellent teammate.
Excellent communication skills to collaborate with cross-cultural teams and work in a matrix organization.

With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most brilliant and talented people in the world working for us. If you're creative and independent, with a genuine passion for technology, we want to hear from you.

JR1979695


Show more "
Software Engineer II,Flipkart,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-ii-at-flipkart-4283071734?position=40&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=2dhzKKljpW7rqlkxFVlt%2Fw%3D%3D,"About the role

At Flipkart, SDE-2 are engineers who create features based on product requirements. You’re expected to design and code in multiple tech components related to your functional area. You’re required to learn the best practices and design principles and patterns to make the code-base maintainable and extensible. You must also develop a deep understanding of non-functional requirements, such as reliability and availability, scale, horizontal scalability, etc. over time and make tech stack decisions accordingly. We are looking for engineers who are well rounded - quality conscious, product thinkers, business cognizant and smart – not mere coders. Engineers get to significantly amplify their impact with the scale that Flipkart operates at.





What you’ll do

:● Design components by translating product requirements, break down project into tasks an

dprovide accurate estimate

s● Independently come up with different solutions, extensible Low level design. Write modular

,extensible, readable and performant cod

e● Choose the right Data Structures, tools and tech stacks and be able to do High Leve

lDesigning with guidance

.● Build, develop, mentor and coach junior team member

s● Collaborate with teams by contributing to the shared vision and working closely wit

hcross-functional stakeholders




.
What you’ll nee

d:● B.Tech or M.Tech or equivalent with at least 3-year of experien

ce● Build abstractions and contracts with separation of concerns for a larger scop

e.● Extensive programming experience in any one programming language like Java, Ruby, Clojure, Scala,C or C++, SQL e

tc● Strong object-oriented programming skill

s.● Experience with multi-threading and concurrency programmi

ng● Ability to work with complex business flows and dealing with huge amounts of dat

a.● Prior work experience in an agile environment or continuous integration and continuous delive

ry(CI or C

D)● Experience of building robust and scalable web-application is good to hav




e.
Show more "
Platform Software Engineer (100% REMOTE),Ticketmaster,"Gurugram, Haryana, India",Gurugram,2025-08-12,https://in.linkedin.com/jobs/view/platform-software-engineer-100%25-remote-at-ticketmaster-4245351647?position=41&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=qikfq8PzoXzV6eSadF6iUw%3D%3D,"Job Summary:


Title: Platform Software Engineer (100% REMOTE)
Location: Remote (India)


Who are we?
Live Nation Entertainment is the world’s leading live entertainment and eCommerce company, comprised of four market leaders: Ticketmaster.com, Live Nation Concerts, Front Line Management Group and Live Nation Network.  Ticketmaster.com is the global event ticketing leader and one of the world’s top five eCommerce sites, with over 26 million monthly unique visitors.  Live Nation Concerts produces over 20,000 shows annually for more than 2,000 artists globally.  Front Line is the world’s top artist management company, representing over 250 artists.  These businesses power Live Nation Network, the leading provider of entertainment marketing solutions, enabling over 800 advertisers to tap into the 200 million consumers Live Nation delivers annually through its live event and digital platforms. For additional information, visit www.livenation.com/investors.
Who are you?
Passionate and motivated.  Driven, with an entrepreneurial spirit.  Resourceful, innovative, forward thinking and committed. At Live Nation Entertainment, our people embrace these qualities, so if this sounds like you then please read on! 

THE TEAM

Core Data Services team is at the center of Data and Analytics initiatives. We are building a modern data platform to support enterprise data needs. Our mission and yours too should you choose to, is to empower and enable our data community of data engineers, data scientists, analysts, product teams and decision makers to create value.
The Core Data Services team consists of Platform Engineering, Data Engineering, Data Enablement and Operations teams. We are building a highly functional, performant modern enterprise Data Lake while supporting our current data platforms so the focus is on maximizing functionality, creating value and content/data assets, cost optimizations and usability of the data delivery and services and all this is our measure of our success and defines us The Core Data Services Team! We are looking for a Data Engineer - Platform, You!

WHAT THIS ROLE WILL DO
This is a hands-on software engineering role that will build highly secure and scalable API's and has automation skills to design, develop, deploy, and maintaining testable, secure API's.
The platform would provide:

The foundation of all critical software is built on.
Security products for building the platform for data engineers.
The ability to empower our product teams to take ownership of how they deliver software robustly and at scale.
Participate in on-call rotations/Pagerduty for platform support.


WHAT THIS PERSON WILL BRING:


Strong hands-on API programming experience with one or many languages, preferably Python, DJango, Flask, etc and writing production software and automations.
Hands on experience with system design, API development, testing, and operational stability Hands on experience building continuous integration (CI) with common tools such as GitHub Actions.
Hands on experience utilizing AWS services, serverless, k8s, batch and real time event orchestration, etc.
Hands on experience with All phases of the software and system development life cycle and agile methodologies like Jira, Confluence.
Collaborate with cross-functional teams to deliver data solutions and provide technical support and guidance to team members.
Stay up to date with the latest engineering technologies and trends.




Show more "
Software Developer,Emerson,"Pune, Maharashtra, India",Pune,2025-08-13,https://in.linkedin.com/jobs/view/software-developer-at-emerson-4245686642?position=42&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=mTy31t7Kpr7CYet2bUnkEQ%3D%3D,"Job Description

In this Role, Your Responsibilities Will Be:


Understand the existing code around Azure functions specifically, including App Services, Cloud Services (Extended Support), Azure Storage accounts, and Microsoft Entra and be able to work with management on maintaining, and migrating some of those to other technologies.
Support, update, and create Azure Pipelines.
Fundamental product analysis and design, source code development, and project driven development.
Determine coding design requirements from function and detailed specification.
Analyze software bugs and affect code repairs.
Design, develop, and deliver specified software features.
Produce usable documentation and test procedures.
Analize and resolve production emergency situations with regard to hosted environments.


Who You Are:

You quickly and decisively act in constantly evolving, unexpected situations. You adjust communication content and style to meet the needs of diverse partners. You always keep the end in sight; puts in extra effort to meet deadlines. You analyze multiple and diverse sources of information to define problems accurately before moving to solutions. You observe situational and group dynamics and select best-fit approach.

For This Role, You Will Need:


Bachelor’s degree or higher in Computer Science or Engineering
3 years of experience. Highly skilled and self-motivated candidates with less experience will be considered.


Preferred Qualifications that Set You Apart:


Self-starter.
Strong grounding in Web development.
Docker and Kubernetes experience welcome
Strong programming skills in .NET technology stack.
Angular, ASP.NET, and WEB API experience.
C#, in both .Net Framework and .NET Core (.NET 8/9)
Experience with Microsoft SQL and Azure SQL Database
Experience with Cosmo / Mongo a plus
Experience with Log4Net, especially custom appenders a plus.
Strong problem-solving skills.
Azure Cloud DevOps experience a plus.
Experience with liquid pipeline operations or volumetric accounting a plus.
Knowledge of oil and gas pipeline industry would be a plus.
Flexibility to work harmoniously with a small development team.
Ability to work with remote leadership in US Timezones.


Our Offer to You:

By joining Emerson, you will be given the opportunity to make a difference through the work you do.

Emerson's compensation and benefits programs are designed to be competitive within the industry and local labor markets. We also offer a comprehensive medical and insurance coverage to meet the needs of our employees.

We are committed to creating a global workplace that supports diversity, equity and embraces inclusion. We welcome foreign nationals to join us through our Work Authorization Sponsorship.

We attract, develop, and retain exceptional people in an inclusive environment, where all employees can reach their greatest potential. We are dedicated to the ongoing development of our employees because we know that it is critical to our success as a global company.

We have established our Remote Work Policy for eligible roles to promote Work-Life Balance through a hybrid work set up where our team members can take advantage of working both from home and at the office.

Safety is paramount to us, and we are relentless in our pursuit to provide a Safe Working Environment across our global network and facilities.

Through our benefits, development opportunities, and an inclusive and safe work environment, we aim to create an organization our people are proud to represent.

Our Commitment to Diversity, Equity & Inclusion

At Emerson, we are committed to fostering a culture where every employee is valued and respected for their unique experiences and perspectives. We believe a diverse and inclusive work environment contributes to the rich exchange of ideas and diversity of thoughts, that inspires innovation and brings the best solutions to our customers.

This philosophy is fundamental to living our company’s values and our responsibility to leave the world in a better place. Learn more about our Culture & Values and about Diversity, Equity & Inclusion at Emerson.

If you have a disability and are having difficulty accessing or using this website to apply for a position, please contact: idisability.administrator@emerson.com.

WHY EMERSON

Our Commitment to Our People

At Emerson, we are motivated by a spirit of collaboration that helps our diverse, multicultural teams across the world drive innovation that makes the world healthier, safer, smarter, and more sustainable. And we want you to join us in our bold aspiration.

We have built an engaged community of inquisitive, dedicated people who thrive knowing they are welcomed, trusted, celebrated, and empowered to solve the world’s most complex problems — for our customers, our communities, and the planet. You’ll contribute to this vital work while further developing your skills through our award-winning employee development programs. We are a proud corporate citizen in every city where we operate and are committed to our people, our communities, and the world at large. We take this responsibility seriously and strive to make a positive impact through every endeavor.

At Emerson, you’ll see firsthand that our people are at the center of everything we do. So, let’s go. Let’s think differently. Learn, collaborate, and grow. Seek opportunity. Push boundaries. Be empowered to make things better. Speed up to break through. Let’s go, together.

About Emerson

Emerson is a global leader in automation technology and software. Through our deep domain expertise and legacy of flawless execution, Emerson helps customers in critical industries like life sciences, energy, power and renewables, chemical and advanced factory automation operate more sustainably while improving productivity, energy security and reliability.

With global operations and a comprehensive portfolio of software and technology, we are helping companies implement digital transformation to measurably improve their operations, conserve valuable resources and enhance their safety.

We offer equitable opportunities, celebrate diversity, and embrace challenges with confidence that, together, we can make an impact across a broad spectrum of countries and industries. Whether you’re an established professional looking for a career change, an undergraduate student exploring possibilities, or a recent graduate with an advanced degree, you’ll find your chance to make a difference with Emerson. Join our team – let’s go!
Show more "
Software development engineer 1,Amazon,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/software-development-engineer-1-at-amazon-4279473659?position=43&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=t0bt717w0qYUUWQan7Z8oA%3D%3D,"Description

Come and be the pioneer of Amazon NA Supply Chain technology innovation!

If you are looking for an opportunity to solve deep technical problems and build innovative solutions in a fast-paced environment while working with smart, passionate business & technical leaders, then this might be the role for you.

At Amazon, we are committed to being the most customer-centric company on earth. North America Supply Chain (NASC) Planning & Execution org is comprised of dynamic teams that shape network planning and execution through the development and application of innovative mechanisms and techniques. Our goal is to enhance the Amazon Fulfilment network to ultimately drive the best customer experience in a reliable and cost-efficient manner that is truly a world-class. NASC is aggressively innovating in a number of areas aimed at propelling our customers’ experience by ensuring that we have robust plans in North America Operations and beyond for optimal execution. NASC tech team is hiring a Software Development Engineer (SDE I) who will be at the centre of the development of state-of-the-art product suites and make a long-lasting footprint on our organization's path towards Hands Off the Wheel automated optimization.

Our newly developed software systems will include services that make business decisions in NACF Operations that impact billions of dollars per year, integrate with upstream and downstream systems across the supply chain network, manage business rules to enable strategic planning for network-level operational capacity, and improve experience for millions of online shoppers. We have an opportunity to build software that scales the business, leads the industry through innovation and delights millions of customers worldwide. We will leverage cutting edge technologies in big data, optimization techniques, machine learning, real time analytics and high volume, low latency, high availability services.

This is a contractual position which is ideal for candidates who are looking to deal with scaling challenges at Amazon and ready to build mission critical system software applications and tools. It is also an opportunity for freelance candidates to become domain experts and have an enormous opportunity to make a large impact on the design, architecture and development of consumer products. Depending on individual performance this experience can lead to permanent positions as Software Development Engineers at Amazon.

Key job responsibilities

Designing and implementation of Software

Basic Qualifications


MCA (Masters in Computer Applications) or BS computer science.
1 to 2 year's experience developing highly interactive, internet applications
Good understanding of web design principles and best use of current web technologies and scalable dynamic user interfaces
Expertise in HTML5, CSS3, JavaScript, JSON/XML and web services is essential
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
Passion for writing great, simple, clean, efficient, quality code and solving complex and interesting problems


Preferred Qualifications


Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline
Experience with Git, Linux, aWS and Java would be considered a plus


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Karnataka

Job ID: A3049172
Show more "
SDE 1,CSG,India,India,2025-08-07,https://in.linkedin.com/jobs/view/sde-1-at-csg-4281376638?position=44&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=5oBy4%2BoirB95KzLMwhlAoQ%3D%3D,"Hi, I'm Christy Anne, your Recruiter and guide to joining CSG! We are excited to learn more about you and your unique background.

We are looking for a Job Profile Software Dev Engineer Senior/Lead:

To be considered for this role, candidates should meet the following criteria:


Must have 2-4 years’ experience on:
C#, ASP.NET MVC
MS-SQL Tables, Views, Stored Procedures
JavaScript, NodeJS, Python
CSS, HTML, Responsive CSS
Must have working knowledge of:
Cloud Services such as Amazon Web Services.
Front-end – debugging tools and procedures.
Web
Services – Restful, WCF, ASP.NET Web API, SOAP
Git
Nice to have:
1+ experience with AWS, Lambda and ASP.Net Core.
PostgreSQL


Is this opportunity right for you? We’re looking for candidates who:


Must have 2-4 years’ experience in a Software Development role.
Must have bachelor’s degree in computer science or related field.


CSGer Perks & Benefits


Work from Home, in-office, or hybrid
Employee Belonging Groups
Healthcare: Dental, Medical, and Vision
Paid Vacation, Volunteer, and Holiday Time Off
And so much more!
View More Benefits (https://www.csgi.com/careers/)


If you would like to be considered for employment opportunities with CSG and need special assistance due to a disability or accommodation for a disability throughout any aspect of the application process, please call us at +1 (402) 431-7440 or email us at accommodations@csgi.com. CSG provides accommodations for persons with disabilities in employment, including during the hiring process and any interview and/or testing processes.

Our Story

CSG empowers companies to build unforgettable experiences, making it easier for people and businesses to connect with, use and pay for the services they value most. For over 40 years, CSG's technologies and people have helped some of the world's most recognizable brands solve their toughest business challenges and evolve to meet the demands of today's digital economy.

By channeling the power of all, we make ordinary customer and employee experiences extraordinary. Our people [CSGers] are fearlessly committed and connected, high on integrity and low on ego, making us the easiest company to do business with and the best place to work. We power a culture of integrity, innovation, and impact across our locations, representing the most authentic version of ourselves to build a better future together. That's just who we are. Learn more about CSG Inclusion & Impact here

Our Guiding Principles

Impact

Always help and empower others, whether they’re colleagues or customers. When our employees set their minds to something, great things happen.

Integrity

Do what’s right for our customers and our people while being authentic. We treat everyone with trust and respect—that’s just who we are.

Inspiration

Be bold in the way you think and passionate about the work you do. Test out innovative ideas without the fear of failure.

Location(s):

IN.Bangalore.Remote

Location(s):

India Remote
Show more "
SDE (Full Stack)= 2,NxtWave,"Hyderabad, Telangana, India",Hyderabad,2025-08-04,https://in.linkedin.com/jobs/view/sde-full-stack-%3D-2-at-nxtwave-4266110697?position=45&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=3WYGS7a1uFMODW1DeRd4jQ%3D%3D,"As a Fullstack SDE - II at NxtWave, you




Build applications at a scale and see them released quickly to the NxtWave learners (within weeks)
Get to take ownership of the features you build and work closely with the product team
Work in a great culture that continuously empowers you to grow in your career
Enjoy freedom to experiment & learn from mistakes (Fail Fast, Learn Faster)
NxtWave is one of the fastest growing edtech startups. Get first-hand experience in scaling the features you build as the company grows rapidly
Build in a world-class developer environment by applying clean coding principles, code architecture, etc.

Responsibilities

Lead design and delivery of complex end-to-end features across frontend, backend, and data layers.
Make strategic architectural decisions on frameworks, datastores, and performance patterns.
Review and approve pull requests, enforcing clean-code guidelines, SOLID principles, and design patterns.
Build and maintain shared UI component libraries and backend service frameworks for team reuse.
Identify and eliminate performance bottlenecks in both browser rendering and server throughput.
Instrument services with metrics and logging, driving SLIs, SLAs, and observability.
Define and enforce comprehensive testing strategies: unit, integration, and end-to-end.
Own CI/CD pipelines, automating builds, deployments, and rollback procedures.
Ensure OWASP Top-10 mitigations, WCAG accessibility, and SEO best practices.
Partner with Product, UX, and Ops to translate business objectives into technical roadmaps.
Facilitate sprint planning, estimation, and retrospectives for predictable deliveries.
Mentor and guide SDE-1s and interns; participate in hiring.

Qualifications & Skills

3–5 years building production Full stack applications end-to-end with measurable impact.
Proven leadership in Agile/Scrum environments with a passion for continuous learning.
Deep expertise in React (or Angular/Vue) with TypeScript and modern CSS methodologies.
Proficient in Node.js (Express/NestJS) or Python (Django/Flask/FastAPI) or Java (Spring Boot).
Expert in designing RESTful and GraphQL APIs and scalable database schemas.
Knowledge of MySQL/PostgreSQL indexing, NoSQL (ElasticSearch/DynamoDB), and caching (Redis).
Knowledge of Containerization (Docker) and commonly used AWS services such as lambda, ec2, s3, api gateway etc.
Skilled in unit/integration (Jest, pytest) and E2E testing (Cypress, Playwright).
Frontend profiling (Lighthouse) and backend tracing for performance tuning.
Secure coding: OAuth2/JWT, XSS/CSRF protection, and familiarity with compliance regimes.
Strong communicator able to convey technical trade-offs to non-technical stakeholders.
Experience in reviewing pull requests and providing constructive feedback to the team.

Qualities we'd love to find in you:




The attitude to always strive for the best outcomes and an enthusiasm to deliver high quality software
Strong collaboration abilities and a flexible & friendly approach to working with teams
Strong determination with a constant eye on solutions
Creative ideas with problem solving mind-set
Be open to receiving objective criticism and improving upon it
Eagerness to learn and zeal to grow
Strong communication skills is a huge plus

Work Location: Hyderabad







About NxtWave

NxtWave is one of India’s fastest-growing ed-tech startups, revolutionizing the 21st-century job market. NxtWave is transforming youth into highly skilled tech professionals through its CCBP 4.0 programs, regardless of their educational background.

NxtWave is founded by Rahul Attuluri (Ex Amazon, IIIT Hyderabad), Sashank Reddy (IIT Bombay) and Anupam Pedarla (IIT Kharagpur). Supported by Orios Ventures, Better Capital, and Marquee Angels, NxtWave raised $33 million in 2023 from Greater Pacific Capital.

As an official partner for NSDC (under the Ministry of Skill Development & Entrepreneurship, Govt. of India) and recognized by NASSCOM, NxtWave has earned a reputation for excellence.

Some of its prestigious recognitions include:

Technology Pioneer 2024 by the World Economic Forum, one of only 100 startups chosen globally
‘Startup Spotlight Award of the Year’ by T-Hub in 2023
‘Best Tech Skilling EdTech Startup of the Year 2022’ by Times Business Awards
‘The Greatest Brand in Education’ in a research-based listing by URS Media
NxtWave Founders Anupam Pedarla and Sashank Gujjula were honoured in the 2024 Forbes India 30 Under 30 for their contributions to tech education

NxtWave breaks learning barriers by offering vernacular content for better comprehension and retention. NxtWave now has paid subscribers from 650+ districts across India. Its learners are hired by over 2000+ companies including Amazon, Accenture, IBM, Bank of America, TCS, Deloitte and more.




Know more about NxtWave: https://www.ccbp.in

Read more about us in the news – Economic Times | CNBC | YourStory | VCCircle

Show more "
"Software Engineer III, Google Ads",Google,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/software-engineer-iii-google-ads-at-google-4270779451?position=46&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=pVxt8UzMSgDmuw1uUSJgiQ%3D%3D,"Minimum qualifications:


Bachelor’s degree or equivalent practical experience.
2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree.


Preferred qualifications:


Master's degree or PhD in Computer Science or related technical fields.
2 years of experience with data structures or algorithms.
Experience developing accessible technologies.


About The Job

Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.

With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.

Google Ads is helping power the open internet with the best technology that connects and creates value for people, publishers, advertisers, and Google. We’re made up of multiple teams, building Google’s Advertising products including search, display, shopping, travel and video advertising, as well as analytics. Our teams create trusted experiences between people and businesses with useful ads. We help grow businesses of all sizes from small businesses, to large brands, to YouTube creators, with effective advertiser tools that deliver measurable results. We also enable Google to engage with customers at scale.

Responsibilities


Write product or system development code.
Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies.
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.



Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
Show more "
Software development engineer 1,Amazon,"Bengaluru, Karnataka, India",Bengaluru,2025-08-07,https://in.linkedin.com/jobs/view/software-development-engineer-1-at-amazon-4279476411?position=47&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=7k36oa1XCb7jqEPM4tOkbA%3D%3D,"Description

Come and be the pioneer of Amazon NA Supply Chain technology innovation!

If you are looking for an opportunity to solve deep technical problems and build innovative solutions in a fast-paced environment while working with smart, passionate business & technical leaders, then this might be the role for you.

At Amazon, we are committed to being the most customer-centric company on earth. North America Supply Chain (NASC) Planning & Execution org is comprised of dynamic teams that shape network planning and execution through the development and application of innovative mechanisms and techniques. Our goal is to enhance the Amazon Fulfilment network to ultimately drive the best customer experience in a reliable and cost-efficient manner that is truly a world-class. NASC is aggressively innovating in a number of areas aimed at propelling our customers’ experience by ensuring that we have robust plans in North America Operations and beyond for optimal execution. NASC tech team is hiring a Software Development Engineer (SDE I) who will be at the centre of the development of state-of-the-art product suites and make a long-lasting footprint on our organization's path towards Hands Off the Wheel automated optimization.

Our newly developed software systems will include services that make business decisions in NACF Operations that impact billions of dollars per year, integrate with upstream and downstream systems across the supply chain network, manage business rules to enable strategic planning for network-level operational capacity, and improve experience for millions of online shoppers. We have an opportunity to build software that scales the business, leads the industry through innovation and delights millions of customers worldwide. We will leverage cutting edge technologies in big data, optimization techniques, machine learning, real time analytics and high volume, low latency, high availability services.

This is a contractual position which is ideal for candidates who are looking to deal with scaling challenges at Amazon and ready to build mission critical system software applications and tools. It is also an opportunity for freelance candidates to become domain experts and have an enormous opportunity to make a large impact on the design, architecture and development of consumer products. Depending on individual performance this experience can lead to permanent positions as Software Development Engineers at Amazon.

Key job responsibilities

Designing and implementation of Software

Basic Qualifications


MCA (Masters in Computer Applications) or BS computer science.
1 to 2 year's experience developing highly interactive, internet applications
Good understanding of web design principles and best use of current web technologies and scalable dynamic user interfaces
Expertise in HTML5, CSS3, JavaScript, JSON/XML and web services is essential
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
Passion for writing great, simple, clean, efficient, quality code and solving complex and interesting problems


Preferred Qualifications


Bachelor’s degree in Computer Science, Computer Engineering or related technical discipline
Experience with Git, Linux, aWS and Java would be considered a plus


Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - ADCI - Karnataka

Job ID: A3049570
Show more "
Software Engineer,Capgemini,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-at-capgemini-4279441958?position=49&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=N0hJrbVXec1FFA8%2B2QWW6A%3D%3D,"Your Role

Experience in developing digital marketing / digital analytics solutions using Adobe products.
Experience in Adobe Experience Cloud products and recent experience with Adobe
Experience Platform or similar CDP
Good knowledge of Data Science workspace and building intelligent Services on AEP
Strong knowledge of datasets in Adobe Experience Platform, load data into Platform through data source connectors, APIs, and streaming ingestion connectors
Experience in creating all required Adobe XDM (Experience Data Model) in JSON based on approved data model for all loading data files.
Knowledge on utilizing Adobe Experience Platform (AEP) UI & POSTMAN to automate all customer schema data lake & profile design setups within each sandbox environment.
Experience in configuration within Adobe Experience Platform all necessary identities & privacy settings and creating new segments within AEP to meet customer use cases.
Test/Validate the segments with the required destinations.
Managing customer data by using Real-Time Customer Data Platform (RTCDP), and analyze customer data by using Customer Journey Analytics (CJA)

Your Profile

Experience with creating connection, data views, and dashboard in CJA
Hands-on experience in configuration and integration of Adobe Marketing Cloud modules like Audience Manager, Analytics, Campaign and Target
Adobe Experience Cloud tool certifications (Adobe Campaign, Adobe Experience Platform, Adobe Target, Adobe Analytics) are desirable.
Proven ability to communicate in both verbal and writing in a high performance, collaborative environment.
Experience with data analysis, modeling, and mapping to coordinate closely with Data Architect(s)

Show more "
Software Engineer,NVIDIA,"Pune, Maharashtra, India",Pune,2025-08-07,https://in.linkedin.com/jobs/view/software-engineer-at-nvidia-4257835058?position=50&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=yGTUBLbnCo4pJEcSgAUwZA%3D%3D,"The NVIDIA SW groups are looking for a highly motivated, dynamic Software Engineer to help us develop/test/automate/implement softwares for our cutting-edge technology. Are you passionate about new technology and looking forward to work on next-generation NVIDIA Products? Do you love to provide innovative solutions and have fun while working on complex problems. Nvidia is looking for great software engineers like you to join us in our engineering groups.

What You'll Be Doing


Work on the complete Product life cycle and in-process design, develop build, and improve our software stack.
Triage and debug complex issues.
Improve the system performance of Nvidia products.
Building and customizing existing infrastructure to enable the effort of system tunning, debugging, automation, and validation across workloads.
Analyzing performance bottlenecks and implementing optimization techniques.
Collaborate with various teams on new product features and improvements of existing products.


What We Need To See


BTECH/MTECH with 3+ years of experience in C/C++ /Python/Java/Golang
Strong programming skills, OOPS, Data structures, and Algorithms.
Experience in Windows / Linux / embedded OS environment.
Excellent problem-solving and analytical skills.
If you have experience in at least a few of the following areas, we will have an excellent match for our needs:
System Software /Embedded/Firmware/Device Driver/Kernel.
Cloud/UI/Full-Stack/Backend/Distributed Systems
SRE/DevOps/Kubernetes
Automation/Tools development/Test development
AI/ML/LLM/DL/Speech/NLP
Good interpersonal skills and ability to work as an excellent teammate.
Excellent communication skills to collaborate with cross-cultural teams and work in a matrix organization.

With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most brilliant and talented people in the world working for us. If you're creative and independent, with a genuine passion for technology, we want to hear from you.

JR1979695


Show more "
"Software Engineer 2, Backend",Intuit,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/software-engineer-2-backend-at-intuit-4267157750?position=51&pageNum=0&refId=ik7647JacB71MMWWP9G7Og%3D%3D&trackingId=PsevqgvsJ2LjfVDyXxSFUA%3D%3D,"Overview

Overview

We're cultivating a culture that prioritizes innovators, risk-takers, and imaginative thinkers. In pursuit of becoming AI-native, we recognize that fostering a ""builder"" mindset is essential. This means seeking out those who can seamlessly integrate AI and emerging technologies to efficiently and effectively solve our customers' problems.

At Intuit, we hold a global leadership position in financial management solutions. We've been at the forefront of inventing Virtual Platforms and democratizing cloud computing for small businesses and their patrons alike. Our 40 years of expertise have rooted us in the startup mentality, positively disrupting ourselves as we constantly identify cutting-edge technology and design paradigms. Our teams are dynamic, focused on delivering creative solutions with a side of fun.

What you'll bring

Qualifications


BS/MS in Computer Science or related area or equivalent experience.
2+ years of experience developing systems/software for large businesses using Java/J2EE, Python, or Go
Experience with databases, cloud, APIs, and other technologies to ensure that the application is scalable, secure, and performant.
Understanding of the Software Development Life Cycle (SDLC)
Familiarity with web services and experience with unit testing & test-driven development (TDD)
Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences
Basic understanding of AI capabilities, specifically GenAI
Knowledge and awareness of AI concepts
Ability to work collaboratively across analytics, engineering, product, design, and AI.
Strong problem-solving skills and analytical mindset
Ability to stay up-to-date with advances in AI technologies and incorporate them into software development best practices


How you will lead

Responsibilities


Be responsible for roughly 80-90% hands-on coding and serve as a technical leader by mentoring junior engineers and applying technical expertise to challenging programming and design problems
Contribute to the design and architecture of projects, and develop backend software using best practices for architecture, design, coding standards, and follows CI/CD practices.
Work cross-functionally with various Intuit teams to drive forward results, and have experience with Agile Development, SCRUM, or Extreme Programming methodologies.
Work collaboratively with cross-functional teams to develop and implement AI-based solutions
Show more "
Data Science,Network18 Media & Investments Limited,"Gurugram, Haryana, India",Gurugram,2025-08-12,https://in.linkedin.com/jobs/view/data-science-at-network18-media-investments-limited-4283761601?position=1&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=GIKhuGdhBWymUZbhbIuqow%3D%3D,"Be a part of India’s largest and most admired news network!




Network18 is India's most diversified Media Company in the fast growing Media market. The Company has a strong Heritage and we possess a strong presence in Magazines, Television and Internet domains. Our brands like CNBC, Forbes and Moneycontrol are market leaders in their respective segments. The Company has over 7,000 employees across all major cities in India and has been consistently managed to stay ahead of the growth curve of the industry.




Network 18 brings together employees from varied backgrounds under one roof united by the hunger to create immersive content and ideas. We take pride in our people, who we believe are the key to realizing the organization’s potential. We continually strive to enable our employees to realize their own goals, by providing opportunities to learn, share and grow.




Role Overview:

We are seeking a passionate and skilled Data Scientist with over a year of experience to join our dynamic team. You will be instrumental in developing and deploying machine learning models, building robust data pipelines, and translating complex data into actionable insights. This role offers the opportunity to work on cutting-edge projects involving NLP, Generative AI, data automation, and cloud technologies to drive business value.




Key Responsibilities:

Design, develop, and deploy machine learning models, with a strong focus on NLP (including advanced techniques and Generative AI) and other AI applications.
Build, maintain, and optimize ETL pipelines for automated data ingestion, transformation, and standardization from various sources
Work extensively with SQL for data extraction, manipulation, and analysis in environments like BigQuery.
Develop solutions using Python and relevant data science/ML libraries (Pandas, NumPy, Hugging Face Transformers, etc.).
Utilize Google Cloud Platform (GCP) services for data storage, processing, and model deployment.
Create and maintain interactive dashboards and reporting tools (e.g., Power BI) to present insights to stakeholders.
Apply basic Docker concepts for containerization and deployment of applications.
Collaborate with cross-functional teams to understand business requirements and deliver data-driven solutions.
Stay abreast of the latest advancements in AI/ML and NLP best practices.

Required Qualifications & Skills:

1 to 4 years of hands-on experience as a Data Scientist or in a similar role.
Solid understanding of machine learning fundamentals, algorithms, and best practices.
Proficiency in Python and relevant data science libraries.
Good SQL skills for complex querying and data manipulation.
Demonstrable experience with Natural Language Processing (NLP) techniques, including advanced models (e.g., transformers) and familiarity with Generative AI concepts and applications.
Excellent problem-solving and analytical skills.
Strong communication and collaboration skills.

Preferred Qualifications & Skills:

Familiarity and hands-on experience with Google Cloud Platform (GCP) services, especially BigQuery, Cloud Functions, and Vertex AI.
Basic understanding of Docker and containerization for deploying applications.
Experience with dashboarding tools like Power BI and building web applications with Streamlit.
Experience with web scraping tools and techniques (e.g., BeautifulSoup, Scrapy, Selenium).
Knowledge of data warehousing concepts and schema design.
Experience in designing and building ETL pipelines.




Disclaimer: Please note Network18 and related group companies do not use the services of vendors or agents for recruitment. Please beware of such agents or vendors providing assistance. Network18 will not be responsible for any losses incurred.

“We correspond only from our official email address”

Show more "
Data Scientist,Danone,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/data-scientist-at-danone-4282126896?position=2&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=5yoN%2FjSuTxxT0ePt3g4Jiw%3D%3D,"About Danone Group:




Mission: ‘Bringing Health through Food to as Many people as Possible’

Danone is a global leader in food and beverages, focusing on Essential Dairy and Plant-based products, Waters, and Specialized Nutrition. Our mission is to bring health through food to as many people as possible by creating nutritious products, promoting healthy eating habits, and operating sustainably.




With nearly 90,000 employees and products available in over 120 markets, Danone generated €27.6 billion in sales in 2023. Our Renew Danone strategy aims to foster long-term value through innovation and community support.




Danone is committed to making a positive impact economically, socially, and environmentally. In 2020, we became the first listed company to adopt the ‘Société à Mission’ status, reflecting our vision for a sustainable future.




More information can be found at www.danone.com.




About Danone India:

Danone operates in India as Nutricia International Pvt. Ltd, focusing on nutrition with a range of products catering to infants, toddlers, pregnant mothers, as well as adults. The company features well-known brands such as Aptamil, Dexolac, and Protinex. Danone employs over 1,000 individuals across India and generates a turnover exceeding €150 million. The company's head office is located in Mumbai, with a manufacturing facility situated in Lalru, Punjab.




Danone India is a Great Place To Work® certified organization, which reflects our commitment to creating a workplace where people are empowered to contribute meaningfully, grow professionally, and feel a true sense of belonging.




More information can be found at https://www.danone.in/




Job Summary:

Work on the project of transformation of Demand Planning at global level in the roadmap of the digitalization for the Supply Chain. Creating and developing the ML models for all Danone categories\




Roles & Responsibilities:




Be part of the design and development of the ML core models and the analytics behind them
Understand and capture cross country needs
Be able to build the common approach of ML scalable models for the demand planning teams of different countries
Support with all the analytics needs for the adoption of the ML models
Build outstanding best in class ML models for Demand Planning that are able to cope with more complex and less steady environments
Set up KPI's to track ML and Statistical models performance
Select and understand the best approach of automatization for the overall Demand process driven by Statistical and Machine Learning capabilities
Ensures collaboration of all teams in order to guarantee scalability of the models
Keeps a close control of the ML developments to ensure cost compliance
Responsible of the Continuous Improvement of the ML models and create the strategy of ML vs Statistical approach
Responsible for the region's continuous improvement of ML and Statistical models in order to improve business performance
Create standard ways of measure and manage strategies to find and fix root causes in forecast bias/accuracy
Develop capabilities and skills on Machine Learning understanding across the regions
Build, maintain, fine tune and audit Statistical & ML models to guarantee adaptability to new business context providing service for all regions
Assist regions in processes and tools to embrace Statistical and ML technology
Shield key processes and know-how on Statistical and ML
Ensures standardization between different countries
Guarantee highest ML utilization




Job Specifications:

Education: Mathematics/Physics/Engineering with a master’s in business/data analytics or proven track record on Data Science
Proven track record of minimum 5 years as a data scientist
Great analytical skills
Coding capabilities in R and/or Phyton
Relationship/ Network builder
Change management
Project management
Experience with Continuous Improvement




Main Interfaces

Cross country demand planning teams
IS/IT project managers and developers
Supply chain cross functions

Show more "
Data Scientist,Unilever,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/data-scientist-at-unilever-4282325097?position=3&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=xlGFlxv%2BEFB%2BgjiUZ2QEXw%3D%3D,"JOB TITLE: Data Scientist

JOB FUNCTION: R&D

SCOPE: Global

WORK LOCATION: Unilever Research India – R&D Bangalore, Whitefield

About Unilever

With 3.4 billion people in over 190 countries using our products every day, Unilever is a business that makes a real impact on the world. Work on brands that are loved and improve the lives of our consumers and the communities around us. We are driven by our purpose: to make sustainable living commonplace, and it is our belief that doing business the right way drives superior performance. At the heart of what we do is our people – we believe that when our people work with purpose, we will create a better business and a better world.

At Unilever, your career will be a unique journey, grounded in our inclusive, collaborative, and flexible working environment. We don’t believe in the ‘one size fits all’ approach and instead we will equip you with the tools you need to shape your own future.

Category Or Function Introduction

HomeCare is a global business with leading household cleaning and laundry brands such as OMO, Sunlight and Comfort. Our aim is to offer products that are unmissably superior, sustainable and great value.

We are organised to deliver growth and margin across three core categories: Fabric Cleaning, Fabric Enhancer, and Home & Hygiene. We have a portfolio of strong global brands, and a global geographical footprint.

Our strength is in emerging markets where we lead the industry through market development.

Within R&D, our team of world-leading scientists, researchers and professionals creates innovations that drive growth for our business and deliver positive impacts for people, society and our planet.

For more than 100 years, we have been using our differentiated science and technology to create the superior products and experiences our consumers love.

Job Purpose

Unilever is the place where you can bring your purpose to life with the work that you do – creating a better business and a better world. If you are passionate about leveraging data analytics power to drive consumer insights and developing modelling capabilities to empower our scientists for innovating superior products, then this role is just for you!

What Will Your Main Responsibilities Be


Analyse complex data sets using a diverse set of machine learning techniques. Build UI solutions to deploy these solutions for the end users.
Develop data analysis and visualization solutions to generate faster insights, thereby helping business team to make informed decision.
Execute data modeling projects working together with project SMEs; manage stakeholder expectations.
Support and manage activities and expectation on data capture and data quality. Ensure data quality compliance with R&D Data Governance standards
Translate business needs into technical specifications, especially for R&D lab and experimental data.


What You Need To Succeed

Experiences & Qualifications


Bachelor’s or master’s degree in STEM subject (Science, Technology, Engineering, or Maths, Computer science, Data Science, Statistics.)
Minimum 2-4 years of working experience in the field of Data science. Experience in data processing / handling, insight building and digital solutions.
Should have working experience in the field of Power BI and/ Python dash.
Having knowledge of experimental data capture systems like LIMS will is plus.
Having python/dash/flask application development skills is plus.


Skills


Expert knowledge in Excel, Power BI. Experience in large data management.
Good to moderate knowledge of scripting and standard modeling practices of developing ML models using Python.
Good to moderate knowledge in interface designing with an ability to understand user’s requirements and develop a mock-up UI wireframe.
Working experience with modelling software such as JMP and DOE are an added advantage.


Leadership


Strong interpersonal and communication skills, both written and oral.
A good team player with ability to work successfully across multiple business units and formats, effectively collaborate with global teams across time-zone.
Energize by delivering fantastic results and be an example to others – with both results and resilience.
Responsible for own wellbeing and delivering high standards of work. Must focus on the Consumer and what they need.


Our commitment to Equality, Diversity & Inclusion

Unilever embraces diversity and encourages applicants from all walks of life! This means giving full and fair consideration to all applicants and continuing development of all employees regardless of age, disability, gender reassignment, race, religion or belief, sex, sexual orientation, marriage and civil partnership, and pregnancy and maternity.

""All official offers from Unilever are issued only via our Applicant Tracking System (ATS). Offers from individuals or unofficial sources may be fraudulent—please verify before proceeding.""
Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4282057513?position=4&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=panw2wQb5CA7pNdHgJMTMw%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Title: Data Scientist

Location: Bangalore

Reporting to: Manager- Analytics/ Senior Manager-Analytics

1. Purpose of the role

Drive AB InBev's pricing strategy by developing and refining data science models, specifically elasticity models, to provide actionable insights that guide business in making optimal pricing decisions.

2. KEY TASKS AND ACCOUNTABILITIES




Understand the business problem and translate that to an analytical problem; participate in the solution design process.
Manage the full AI/ML lifecycle, including data preprocessing, feature engineering, model training, validation, deployment, and monitoring.
Develop reusable and modular Python code adhering to OOP (Object-Oriented Programming) principles.
Design, develop, and deploy machine learning models into production environments on Azure.
Collaborate with data scientists, software engineers, and other stakeholders to meet business needs.
Ability to communicate findings clearly to both technical and business stakeholders.

3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

B. Tech /BE/ Masters in CS/IS/AI/ML/ Statistics

Previous work experience required




Minimum 3 years of relevant experience

Technical skills required

Must Have

Strong expertise in Python, including advanced knowledge of OOP concepts.
Exposure to AI/ML methodologies with a previous hands-on experience in ML concepts like forecasting, clustering, regression, classification, optimization using Python
Azure Tech Stack, Databricks, ML Flow in any cloud platform Airflow for orchestrating and automating workflows
MLOPS concepts and containerization tools like Docker
Experience with version control tools such as Git.
Consistently display an intent for problem solving
Strong communication skills (vocal and written)
Ability to effectively communicate and present information at various levels of an organization.

Good To Have

Preferred industry exposure in Pricing and Revenue management Domain
Product building experience

Other Skills required

Passion for solving problems using data
Detail oriented, analytical and inquisitive
Ability to learn on the go
Ability to work independently and with others

We dream big to create future with more cheers

Show more "
Data scientist- Python- AI/ML GEN AI- Across india,Capgemini Engineering,"Mumbai, Maharashtra, India",Mumbai,2025-08-04,https://in.linkedin.com/jobs/view/data-scientist-python-ai-ml-gen-ai-across-india-at-capgemini-engineering-4277353126?position=5&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=SwZutEAJBiM84u7aZSrwkQ%3D%3D,"• Develop strategies/solutions to solve problems in logical yet creative ways, leveraging state-of-the-art machine learning, deep learning and GEN AI techniques.

• Technically lead a team of data scientists to produce project deliverables on time and with high quality.

• Identify and address client needs in different domains, by analyzing large and complex data sets, processing, cleansing, and verifying the integrity of data, and performing exploratory data analysis (EDA) using state-of-the-art methods.

• Select features, build and optimize classifiers/regressors, etc. using machine learning and deep learning techniques.

• Enhance data collection procedures to include information that is relevant for building analytical systems, and ensure data quality and accuracy.

• Perform ad-hoc analysis and present results in a clear manner to both technical and non-technical stakeholders.

• Create custom reports and presentations with strong data visualization and storytelling skills to effectively communicate analytical conclusions to senior officials in a company and other stakeholders.

• Expertise in data mining, EDA, feature selection, model building, and optimization using machine learning and deep learning techniques.

• Strong programming skills in Python.

• Excellent communication and interpersonal skills, with the ability to present complex analytical concepts to both technical and non-technical stakeholders.







Primary Skills :

- Excellent understanding and hand-on experience of data-science and machine learning techniques & algorithms for supervised & unsupervised problems, NLP and computer vision and GEN AI. Good applied statistics skills, such as distributions, statistical inference & testing, etc.

- Excellent understanding and hand-on experience on building Deep-learning models for text & image analytics (such as ANNs, CNNs, LSTM, Transfer Learning, Encoder and decoder, etc).

- Proficient in coding in common data science language & tools such as R, Python.

- Experience with common data science toolkits, such as NumPy, Pandas, Matplotlib, StatsModel, Scikitlearn, SciPy, NLTK, Spacy, OpenCV etc.

- Experience with common data science frameworks such as Tensorflow, Keras, PyTorch, XGBoost,etc.

- Exposure or knowledge in cloud (Azure/AWS).

- Experience on deployment of model in production.

Show more "
Data Scientist,Societe Generale Global Solution Centre,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-scientist-at-societe-generale-global-solution-centre-4275901017?position=6&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=yGs82wtkSjWBL3X4yiO5KQ%3D%3D,"JD: Data Scientist
Responsibilities:
Leverage strong ML model experience in complex data environments to achieve business objectives in innovative and efficient ways.
Utilize a solid background in mathematics and statistics to inform model development and evaluation.
Design, architect, and develop robust machine learning solutions, with a focus on integrating Large Language Models (LLMs) where applicable.
Collaborate effectively within Agile Scrum teams, contributing to iterative development and continuous improvement.
Document business processes, workflows, and requirements clearly and comprehensively.
Engage in close collaboration with various domains within the organization to ensure alignment and understanding of business needs.
Participate in collaborative conceptualization sessions to brainstorm and refine project ideas.
Mandatory Skills:
Proficiency in Python, Machine Learning, REST API, and SQL.
Experience with data processing, cleansing, and verification to ensure data integrity for analysis.
Conduct data quality checks and exploratory analyses to inform model development.
Demonstrated programming skills in relevant languages, particularly Python and API development.
Build end-to-end machine learning models, including data structures and transformation processes.
Strong understanding of statistical modeling techniques (e.g., Regression, Clustering, Decision Trees, Logistic Regression).
Familiarity with machine learning algorithms (e.g., KNN, Random Forests, Ensemble Methods, Bayesian/Markov Networks).
Knowledge of data mining concepts and experience with data visualization tools and dashboards.
Preferred Skills:
Experience with Large Language Models (LLMs) such as GPT, BERT, or similar architectures.
Understanding of natural language processing (NLP) techniques and their applications in business contexts.
Familiarity with advanced research topics, including deep learning, kernel methods, spectral methods, and forecasting.
Ability to integrate end-to-end ML solutions into product suites and business functions, with a focus on LLM applications.
Design technical frameworks based on various use cases, particularly those involving text data and language understanding.
Identify opportunities to automate analytical processes, data extraction, and flow processes, especially in the context of LLMs.
Propose hypotheses and design experiments to address specific problems, leveraging LLM capabilities where relevant.
Additional Responsibilities:
Stay updated with the latest advancements in machine learning and natural language processing, particularly in the context of LLMs.
Mentor junior team members on best practices in machine learning and LLM implementation.
Contribute to the development of best practices and standards for machine learning and LLM projects within the organization.

Why Join Us

We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Business Insight

At Société Générale, we are convinced that people are drivers of change, and that the world of tomorrow will be shaped by all their initiatives, from the smallest to the most ambitious. Whether you’re joining us for a period of months, years or your entire career, together we can have a positive impact on the future. Creating, daring, innovating, and taking action are part of our DNA. If you too want to be directly involved, grow in a stimulating and caring environment, feel useful on a daily basis and develop or strengthen your expertise, you will feel right at home with us!

Still hesitating?

You should know that our employees can dedicate several days per year to solidarity actions during their working hours, including sponsoring people struggling with their orientation or professional integration, participating in the financial education of young apprentices, and sharing their skills with charities. There are many ways to get involved.

We are committed to support accelerating our Group’s ESG strategy by implementing ESG principles in all our activities and policies. They are translated in our business activity (ESG assessment, reporting, project management or IT activities), our work environment and in our responsible practices for environment protection.

Show more "
Data Science (AI/ML) for Bangalore & Chennai location.,Infosys Finacle,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-science-ai-ml-for-bangalore-chennai-location-at-infosys-finacle-4284133646?position=7&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Y4ib8nFdzCc%2FRV33XvZftQ%3D%3D,"🚀 Data Science (AI/ML) – Infosys Finacle




📍 Location: [Bangalore/Chennai]

Experience: [2-15 years]




Are you passionate about leveraging AI and data science to transform banking technology? Join Infosys Finacle and help drive innovation in the financial services industry!




What You’ll Do:

Work on cutting-edge AI solutions in partnership with top industry leaders
Propose innovative solutions and adapt quickly in a dynamic learning environment
Build AI algorithms and design experiments to merge, manage, and extract actionable insights from large data sets
Use predictive modeling to enhance customer experiences, optimize revenue, improve ad targeting, and achieve other business goals
Develop Explainable and Responsible AI models
Conduct research to develop prototypes and proof of concepts
Identify opportunities to apply data science insights across various teams and functions
Inspire others with your enthusiasm for solving complex problems with algorithms




What We’re Looking For:

2 to 10+ years of relevant experience in data science or analytics
Strong analytical and problem-solving skills
Proficiency with statistical programming languages such as Python, SQL, etc.
In-depth knowledge of advanced statistical techniques (regression, distributions, statistical tests, etc.)
Experience with machine learning algorithms including regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks
Ability to deploy models as APIs
Excellent communication and presentation skills to convey complex ideas to non-technical stakeholders




Ready to Make an Impact?




Email your CV and details to sweta.singh09@infosys.com




Interview process: -3 rounds




1-Online Coding Assessment (120 Mins).

2-Technical Round

3-Hiring manager Round




🌐 Why Infosys Finacle?

Build core banking platforms used by global financial institutions
Learn, grow, and innovate with the best minds in the industry
Be a part of a global digital banking transformation




About Finacle

Finacle is an industry leader in digital banking solutions. We partner with emerging and established financial institutions to inspire better banking. Our cloud-native solution suite and SaaS services help banks to engage, innovate, operate, and transform better. We are a business unit of EdgeVerve Systems, a wholly-owned product subsidiary of Infosys – a global technology leader with over USD 15 billion in annual revenues. We are differentiated by our functionally rich solution suite, composable architecture, culture, and entrepreneurial spirit of a start-up. We are also known for an impeccable track record of helping financial institutions of all sizes drive digital transformation at speed and scale.

Today, financial institutions in more than 100 countries rely on Finacle to help more than a billion people and millions of businesses to save, pay, borrow, and invest better.




Finacle website (https://www.edgeverve.com/finacle/solutions/)




Disclaimer: - Edgeverve Systems does not engage with external manpower agencies or charge any fees from candidates for recruitment. If you encounter such scams, please report them immediately.

Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4282052980?position=8&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=FvrxdoGmBkYtzHy0teLEWw%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Description

Job Title: Data Scientist – Predictive Forecasting

Location: Bangalore

Reporting to: Senior Manager Analytics

1) Purpose of the role

We are seeking a talented Data Scientist specializing in Statistical modelling, Predictive modelling, Time Series Forecasting to join our dynamic analytics team. The ideal candidate will have a strong background in statistical modeling and machine learning, with a focus on time series analysis. You will be responsible for developing predictive models for Business Cycles and Monthly Performance Monitoring, generating actionable insights from Forecasts, and driving business value through data-driven decision-making.




2) Key tasks & accountabilities




Develop and Implement Models:
Design and implement and Maintain time series forecasting models to predict key business metrics.
Utilize advanced statistical techniques and machine learning algorithms to improve model accuracy.
Data Analysis and Insight Generation:
Analyze large and complex datasets to identify trends, patterns, and anomalies.
Generate actionable insights that inform business strategies and operational improvements.
Collaborate with Cross-Functional Teams:
Work closely with deployment and development data scientists, and other stakeholders to understand business needs.
Communicate Findings:
Present analysis results and insights to stakeholders in a clear and concise manner.
Prepare reports, visualizations, and dashboards to communicate data findings.
Continuous Improvement:
Monitor model performance and implement enhancements as necessary.
Stay updated with the latest developments in data science, machine learning, and time series forecasting.




3) Qualifications, Experience, Skills




Level of educational attainment required.

Bachelor’s or master’s degree in data science, Statistics, Mathematics, Computer Science, or a related field.




Previous work experience

Minimum of 2 years of experience in data science or a related role.
Proven experience with time series analysis and forecasting techniques is a plus




Technical Skills required




Python (Data Structures, Control Flow, OOPs, Modules and Packages, Exception Handling, VENV)
MLOPs Fundamentals (Model Development, VCS, CI, CD, Serving, Monitoring & Logging, Registry, Data and Model Lineage)
Experience with machine learning frameworks (e.g., scikit-learn, TensorFlow is a plus).
Familiarity with data visualization tools (e.g., Power BI, matplotlib, plotly, streamlet).
Data Analysis Tools - Pandas, Excel (Pivot Tables, Charts, Macros, Conditional Formatting, Shortcuts)
Insights presentation - PowerPoint
Version Control System (Git) - Basic Commands, Branching and Merging, Pull Requests & Code Reviews




Other Skills required




Excellent problem-solving and analytical skills.
Strong communication and presentation abilities.
Ability to work collaboratively in a team environment.




And above all of this, an undying love for beer!




We dream big to create future with more cheers.

Show more "
Data Scientist,Visa,Greater Bengaluru Area,Greater Bengaluru Area,2025-08-05,https://in.linkedin.com/jobs/view/data-scientist-at-visa-4280080738?position=9&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=1KILobWxsj%2BHwwyikCe%2F3Q%3D%3D,"Data Scientist - Credit Card Analytics (3-5yrs)

Bangalore, India
Full-time
Job Family Group: Product Development

Company Description

Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid.

Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.

Job Description

Visa Consulting and Analytics (VCA) is Visa's consulting division, serving Visa's clients (including card issuers, acquirers, and merchants) and solving their strategic problems focused on improving performance and profitability. Drawing on our expertise in strategy consulting, payments, data analytics, marketing, operational and macroeconomics, VCA drives high impact and tangible financial results.

The individual will be part of VCA Data Science team, under Managed Services vertical and will be responsible for delivering data analytics projects with Visa client. The team is involved in a comprehensive range of analytics services for our client, that address unique challenges in areas such as strategic growth, cards profitability, product acquisitions, customer engagement and portfolio management.

What a Data Scientist, Visa Consulting & Analytics does at Visa:

The Data Scientist will be a member of VCA Data Science team in Asia Pacific and will report to the squad lead. This position will be embedded at client office and based in Bangalore.

The individual will be accountable for delivery and implementation of analytics strategies as well as high-impact solutions for the client. He/she will bring in deep expertise from credit cards and retail banking with a strong background in data analysis to solve complex problems and unlock business value.

Key responsibilities include:

Execute and deliver data analytics projects for the Visa client
Drive credit card portfolio strategies with the use of client data and/or other sources of data e.g. Visa data, third party etc.
Act as analytics advocate within our partners, advising teams and sharing best practices and case studies.
Continually look at the environment to challenge our assumptions around new sources of data, potential analytics partners, tools, talent, and infrastructure.
Explore leading methodologies, best practices and import successful methodologies from other international markets
Effectively interact with clients and manage internal/external stakeholder communication

Why this is important to Visa

As payments consulting arm of Visa, VCA is growing a team of highly specialized experts who can provide best-in-class payment expertise and data-driven strategies to clients. We’re building a high-performing team of data scientists, data analysts and statisticians helping major organizations adapt and evolve to meet the changes taking place in technology, finance, and commerce with cutting-edge, creative, and advanced analytic solutions. The purpose of the team is to help Visa’s clients grow their business and solve problems by providing consulting services using data.

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

We are looking for a motivated, analytical minded individual with a track record of using data and analytics to unlock business value. A successful candidate should have accumulated a variety of industry experience, be curious about banking and cards industry, should be results-driven and client-centric.




• Degree in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent

• Minimum 3+ years of analytics experience in applying statistical solutions to business problems

• Experience in card payments and/or retail banking domain

• Hands on experience with one or more data analytics/programming tools such as SAS/Hadoop/R/SQL/Python/Hive

• Outstanding problem-solving skills, with demonstrated ability to think creatively and strategically

• Presentation and data storytelling skills including strong hold on MS Excel and PowerPoint

• Self-motivated, results oriented individual with ability to handle multiple projects concurrently

• Experience in working closely with data science community

Additional Information

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Show more "
Data Scientist 1,Uber,"Bengaluru, Karnataka, India",Bengaluru,2025-08-06,https://in.linkedin.com/jobs/view/data-scientist-1-at-uber-4281428228?position=10&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Lq2yewtrblNAmGpg7SsZXw%3D%3D,"About The Role

Communication Platform enables all the messages (SMS OTP, Whatsapp, Notifications, Voice Call, Chat) among our users. This role will help improve our communications products in improving the Deliverability, reliability and reach of the messages by optimising the cost at the same time. Improving effieciency of communications among our users will helop improve trip conversion and in turn revenue for the organization.

What The Candidate Will Need / Bonus Points

---- What the Candidate Will Do ----


Build scalable analytical frameworks to support product analytics for Uber's Communications Platform
Own new product experimentation including plan creation, roll-out, and monitoring
Be an invaluable partner to cross-functional teams such as engineering, product management, various data teams to deploy data quality across critical pipelines and to set up processes to triage data issues
Develop and track metrics and reporting functions to measure and monitor products performance on our platform
Effectively and proactively communicate insights and drive projects to drive towards team goals
Proactively seek out opportunities to build new solutions to tackle challenges
Create and drive data quality standards and frameworks to ensure inclusion into pipeline engineering efforts


Basic Qualifications


2+ years of experience (Bachelor) OR 1+ years of experience (Masters) in a data-focused role such as product analytics, business analytics, business operations, or data science
Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience
Experience in programming and/or query languages
Past experience with a Product / Tech company serving millions of customers on multiple platforms and countries


Preferred Qualifications


SQL mastery. Write efficient and complex code in SQL
Experience in Python/R and experimentation, A/B testing, and statistical modelling
Experience in Payments or Compliance with a Product / Tech company
Proven ability to handle and visualise large datasets, explore and utilize raw data feeds
Love of data - you just go get the data you need and turn it into an insightful story.
A well-organized, structured approach to problem-solving
Strong sense of ownership, accountability, and entrepreneurial spirit
Great communicator, problem-solver & confident in decision making
Independent & autonomous, while still a strong teammate
Enthusiastic, self-starting and thrives in changing, agile environments
Show more "
Data Scientist - AGM/ DGM/ GM,UltraTech Cement,"Mumbai, Maharashtra, India",Mumbai,2025-08-12,https://in.linkedin.com/jobs/view/data-scientist-agm-dgm-gm-at-ultratech-cement-4281265788?position=12&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=ylCuWKg4IQa%2FF9jKEhXxeA%3D%3D,"Key Result Areas:

Continuously assess and provide inputs to refine data science practices and strategies to ensure alignment with evolving business needs (New Fuels, Raw material, Equipment design or technology, or Product innovation) and Industry 4.0 technological advancements.
Facilitate the redesign of business processes through digital solutions such as Generative AI and Knowledge graph, adopting a design thinking approach for ideation and employing Agile methodology for efficient execution.
Utilize tools and methodologies eg: Python, PowerBI, Orange, GPTs for analyzing trends & patterns within big data sets to inform business decisions across functions & at all levels. Clean, preprocess, & transform the data to ensure it's of high quality, with missing values handled & outliers addressed.
Employ advanced analytics techniques for predictive modeling & machine learning algorithms like Neural Networks, XGBoost, Autoencoders etc to improve process and equipment reliability & resilience to ever-increasing external sources of variability.
Test, iterate, and deploy above tools as part of Pilot programs, inline with digital strategy roadmap.
Conduct hands-on testing and validation of AI/ML models to gauge their effectiveness and refine their performance continually.
Work closely with different business units to understand their needs and integrate data science solutions into their digital strategy.
Implement continuous monitoring processes for AI models to ensure performance accuracy, detect drift, and make timely adjustments.
Ensure seamless handover of solutions to Digital Execution team for scale up, and continuously monitor for improvement areas. Document the entire project, including data sources, methodologies, model architecture, and any decisions made throughout the process.




Qualifications: B.E/B.tech/ PG in data science

Location: Worli, Mumbai

Show more "
Data Scientist,LTIMindtree,"Bengaluru, Karnataka, India",Bengaluru,2025-08-10,https://in.linkedin.com/jobs/view/data-scientist-at-ltimindtree-4282455821?position=13&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=NAxRFz4aa770Jnrvu7xG%2Fg%3D%3D,"Job Description

We are seeking a talented AI Engineer with a strong background in signal processing vibration analysis and acousticnoise control The ideal candidate will have experience in deploying AI solutions on edge and IoT devices This role will involve designing developing and implementing AI algorithms to process and analyze various signal types and control noise in realtime applications Experience with Generative AI and Predictive Analytics particularly within the Oil Gas OG and Manufacturing sectors is a plus




Key Responsibilities




Develop and implement AI algorithms for signal processing vibration analysis and acousticnoise control

Design and deploy AI models on edge and IoT devices

Collaborate with crossfunctional teams to integrate AI solutions into existing systems and products

Perform data analysis and interpretation to improve and optimize AI models

Work on realtime data processing and ensure efficient deployment on resourceconstrained devices

Conduct research and stay updated on the latest advancements in AI signal processing noise control Generative AI and Predictive Analytics

Troubleshoot and resolve issues related to AI models and deployment on edge devices




Qualifications

Bachelors or Masters degree in Electrical Engineering Computer Science Mechanical Engineering or a related field

Proven experience in signal processing vibration analysis and acousticnoise control

Strong programming skills in Python MATLAB or similar languages

Experience with AI frameworks and libraries such as TensorFlow PyTorch or similar

Knowledge of deploying AI models on edge and IoT devices

Familiarity with microcontroller programming and embedded systems

Strong analytical and problem solving skills

Excellent communication and teamwork abilities

Experience with Generative AI and Predictive Analytics

Knowledge of the Oil Gas OG and Manufacturing sectors is a plus

Show more "
Data Scientist,McKinsey & Company,"Gurugram, Haryana, India",Gurugram,2025-08-12,https://in.linkedin.com/jobs/view/data-scientist-at-mckinsey-company-4283536266?position=14&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Bqor2jevOnFEKl%2FNv1G7Bw%3D%3D,"Who You'll Work With

Driving lasting impact and building long-term capabilities with our clients is not easy work. You are the kind of person who thrives in a high performance/high reward culture - doing hard things, picking yourself up when you stumble, and having the resilience to try another way forward.

In return for your drive, determination, and curiosity, we'll provide the resources, mentorship, and opportunities you need to become a stronger leader faster than you ever thought possible. Your colleagues—at all levels—will invest deeply in your development, just as much as they invest in delivering exceptional results for clients. Every day, you'll receive apprenticeship, coaching, and exposure that will accelerate your growth in ways you won’t find anywhere else.

When you join us, you will have:


Continuous learning: Our learning and apprenticeship culture, backed by structured programs, is all about helping you grow while creating an environment where feedback is clear, actionable, and focused on your development. The real magic happens when you take the input from others to heart and embrace the fast-paced learning experience, owning your journey.
A voice that matters: From day one, we value your ideas and contributions. You’ll make a tangible impact by offering innovative ideas and practical solutions. We not only encourage diverse perspectives, but they are critical in driving us toward the best possible outcomes.
Global community: With colleagues across 65+ countries and over 100 different nationalities, our firm’s diversity fuels creativity and helps us come up with the best solutions for our clients. Plus, you’ll have the opportunity to learn from exceptional colleagues with diverse backgrounds and experiences.
World-class benefits: On top of a competitive salary (based on your location, experience, and skills), we provide a comprehensive benefits package to enable holistic well-being for you and your family.


Your Impact

At McKinsey you will work on real-world, high-impact projects across a variety of industries.

You will have the opportunity to collaborate with QB/Labs teams and build complex and innovative ML systems to accelerate our work in AI and help solve business problems at speed and scale.

You will experience the best environment to grow as a technologist and a leader.

You will develop a sought-after perspective connecting technology and business value by working on real-life problems across a variety of industries and technical challenges to serve our clients on their changing needs.

You will be surrounded by inspiring individuals as part of diverse and multidisciplinary teams.

You will develop a holistic perspective of AI by partnering with the best design, technical, and business talent in the world as your team members.

While we advocate for using the right tech for the right task, we often leverage the following technologies: Python, PySpark, the PyData stack, Airflow, Databricks, our own open-source data pipelining framework called Kedro, Dask/RAPIDS, container technologies such as Docker and Kubernetes, cloud solutions such as AWS, GCP, Azure, and more.

You will work with other data scientists, data/ML engineers, designers, project managers and business subject matter experts on interdisciplinary projects across various industry sectors to enable business ambitions with data & analytics.

You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritizing impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.

As a Data Scientist, you will:


Solve the hardest business problems with our clients in multiple industries worldwide while leading research and development of state-of-the-art Machine Learning and statistical methods
Play a leading role in bringing the latest advances in AI and deep learning to our clients, collaborating with industry executives and QuantumBlack experts to find and execute opportunities to improve business performance using data and advanced machine learning models
Identify machine learning R&D initiatives that have high potential of applicability in industry
Work with QuantumBlack leadership and client executives to understand business problems and map them to state-of-the-art analytics and AI solutions
Work closely with other data scientists, data engineers, machine learning engineers and designers to build end-to-end analytics solutions for our clients that drive real impact in the real world
Perhaps most importantly, you will work in one of the most talented and diverse data science teams in the world


Your Qualifications and Skills


Bachelor's or master's level in a discipline such as: computer science, machine learning, applied statistics, mathematics, engineering or artificial intelligence
2+ years of deep technical experience in machine learning, advanced analytics and statistics
Advanced programming expertise in Python
Proven application of advanced analytical, data science and statistical methods in realworld engagements
Knowledge in Engineering standards, QA/Risk Management
Experience and expertise In GenAI application development (RAG, Agentic flows, etc.) using API integration and orchestration tools such as Langchains, Crew.AI, AutoGen will be an added advantage
Willingness to travel both domestic and international
Good presentation and communication skills, with a knack for explaining complex analytical concepts and insights to technical as well as non-technical audiences
Show more "
Data Scientist,EXL,India,India,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-at-exl-4266437972?position=15&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=cZP0HV92i0n8j7UouZ96OA%3D%3D,"Location - Bangalore/ Gurgaon




Skills/ Qualifications Required:




Relevant experience in data science/ data analytics role with an end-to-end understanding of ML based project’s development & implementation
Proficient in building and deploying Machine Learning (Predictive & Prescriptive modelling), NLP
Expertise in Demand Forecasting
Proficient in tools / languages like SQL, Python & PySpark
Good understanding of Probability & Statistics
Hands-on experience in Azure
Good communication skills




Job Responsibilities

Data collation, processing, cleaning & transformation along with feature engineering and model development.
Hands-on with model training, evaluation & fine tuning.
Ensure output’s thorough quality check & provide analytics driven insights and next steps in involved project(s)
Develop & implement various customer segmentation, LTV & marketing campaign optimization models.
Actively own & manage client deliverables.
Effectively engage with client & translate client business requirements into equivalent analytical problems.
Understand data and different platforms used by the client.
Actively contribute towards design methodology for problem solving.
Analyze large & complex data sets to derive valuable insights.

Show more "
AI Engineer [T500-19607],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-07,https://in.linkedin.com/jobs/view/ai-engineer-t500-19607-at-mcdonald-s-4281607390?position=16&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=ouhPT798sVTfchLQwPA0nQ%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Company Description:

McDonald’s is on a mission to build a data- and AI-powered organization that scales innovation and accelerates the Arches. The AI Hub, part of the Enterprise Data, Analytics, and AI (EDAA) team, is central to that mission—designing, deploying, and scaling AI-driven products that improve guest experiences, restaurant operations, and business decision-making. The Opportunity We’re seeking a Manager, AI/ML Engineering focused on the development, refinement, and deployment of AI models and algorithms that power enterprise AI initiatives. With an emphasis on aligning technical solutions with business strategy, this position plays a pivotal role in delivering scalable AI products across domains. The role collaborates with cross-functional teams to design machine learning models, optimize performance, and guide delivery from prototype to production. The role contributes directly to evolving AI architectures and drives innovation in enterprise AI solutions.




Key Responsibilities:

Design and build scalable end-to-end AI Systems, focusing on backend development Design, develop, and refine advanced AI models and algorithms, especially generative AI approaches. Includes writing code on AI product component modules, or prototypes, typically in python, but also leveraging database technologies including vector, relational, NOSQL, messaging queues, front end interfaces, etc. Will make heavy use of various GenAI platform API’s.
Lead the execution of AI model lifecycle activities from development to deployment, including training, validation, and tuning
Ensure alignment with enterprise AI architecture and evolving AI strategy
Collaborate with data scientists, LLMOps / MLOps engineers, product managers, and business stakeholders to translate use cases into deployable AI solutions
Contribute to the development of scalable AI pipelines and model deployment workflows across cloud or hybrid infrastructure
Monitor model performance in production and implement updates or retraining processes to ensure continued relevance and accuracy
Apply best practices for reproducibility, version control, documentation, and ethical AI considerations
Mentor junior AI engineers and foster continuous learning and knowledge sharing within AI teams
Stay current with advances in AI/ML research and tools, translating new capabilities into practical enterprise use
Coach and mentor junior AI engineers and support cross-functional teams in AI product delivery
Support enterprise AI governance and model risk management processes




Qualifications Required:

Bachelor’s degree in computer science, Data Science, or a related field; master’s or PhD preferred
5+ years of experience in AI/ML model development or AI System engineering (backend or full stack)
Strong expertise in some variety of programming languages, with an emphasis on Python. Advanced proficiency with some AI/ML frameworks (e.g., Lang Chain, TensorFlow, PyTorch)
Deep understanding of machine learning algorithms, statistical modeling, data structures and distributed systems
Experience working with cloud AI platforms and services (e.g., AWS SageMaker, Google AI Platform, Azure ML)
Familiarity with MLops including model versioning, reproducibility, and monitoring
Ability to clearly communicate technical concepts to both technical and non-technical stakeholders
Strong collaboration skills with cross-functional teams in fast-paced environments
Demonstrated ability to contribute to innovation and continuous improvement in AI practices




Our Commitment to Values:

Serve: Customers and people first.
Inclusion: Everyone is welcome.
Integrity: We do what’s right.
Community: We give back.
Family: We support each other




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Machine Learning Engineer,Tata Technologies,"Pune, Maharashtra, India",Pune,2025-08-05,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-tata-technologies-4280134590?position=17&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=mRgTJiptJ37ISf8sov0clQ%3D%3D,"Location -Pune

Experience - 3 to 6 Years

Qualification - Graduate (B.E/B Tech)




JD .

Lead the architecture, design, and development of components and services to enable Machine Learning at scale
Build data sets from multiple data sources and write data flows using Python and R, SQL/Spark
Exposure to Streaming/Event based architecture
Implementing analytic models on Big data infrastructure
Stay up-to-date on ML, Big Data technologies sharing learnings with the teams
Build reusable code and libraries for future use and optimize application for maximum speed and scalability
Integration of user-facing elements developed by front-end developers with server-side logic
Implementation of security and data protection measures
Exposure in at least one cloud platform on related data services (AWS / Azure / GCP)

Skills – (highlighted are mandatory skill)

Python, R,
SQL,
Spark,
Hadoop, Big data tool,
NodeJS,
Javascript




Job Responsibility:

Apache Spark experience a major plus (Spark RDDs, Spark DataFrames, Spark SQL)
Leverage Spark ecosystem knowledge to design, and develop capabilities to deliver solutions using Scala, Python, Kafka and other things in the Spark ecosystem
Expert in Python, R, NodeJS framework
Good understanding in front-end technologies, such as angular, JavaScript, HTML5, and CSS3
Should design the solution Approach and Come out with optimized effort estimates.
Defining the technical specifications for the implementation of the frontend and backend solution
Should be able to create extensible APIs and scalable python modules

Show more "
Data Scientist,Media.net,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-at-media-net-4275687771?position=18&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=EnfutCsp0xM418kkmJBQBg%3D%3D,"Role : Data Scientist II




About Media.net :

Media.net is a leading, global ad tech company that focuses on creating the most transparent and efficient path for advertiser budgets to become publisher revenue. Our proprietary contextual technology is at the forefront of enhancing Programmatic buying, the latest industry-standard in ad buying for digital platforms.




The Media.net platform powers major global publishers and ad-tech businesses at scale across ad formats like display, video, mobile, native, as well as search. Media.net’s U.S. HQ is based in New York, and the Global HQ is in Dubai. With office locations and consultant partners across the world, Media.net takes pride in the value-add it offers to its 50+ demand and 21K+ publisher partners, in terms of both products and services.




Data Science is at the heart of Media.net. The team uses advanced statistical and machine learning and deep learning models, large scale distributed computing along with tools from mathematics, economics, auction theory to build solutions that enable us to match users with relevant ads in the most optimal way thereby maximizing revenue for our customers and for Media.net.




Some of the challenges the team deals with:

How do you use information retrieval, machine learning models to estimate click through rate and revenue given the information regarding the position of the slot, user device, location and content of the page. How do you scale the same for thousands of domains, millions of urls?
How do you match ads to page views considering contextual information? How do you design learning mechanisms to continuously learn from user feedback in the form of clicks and conversions? How do you deal with the extremely sparse data? What do you do for new ads and new pages? How do we design better explore-exploit frameworks? How do you design learning algorithms that are fast and scalable?
How do you combine contextual targeting with behavioral user-based targeting?
How do you establish a unique user identity based on multiple noisy signals so that behavioral targeting is accurate?
Can you use NLP to find more genetic trends based on the content of the page and as?




What is in it for you?




Understand business requirements, analyze and extract relevant information from large amounts of historical data.
Use your knowledge of Information retrieval, NLP, Machine Learning (including Deep Learning) to build prototype solutions keeping scale, speed and accuracy in mind.
Work with engineering teams to implement the prototype. Work with engineers to design appropriate model performance metrics and create reports to track the same.
Work with the engineering teams to identify areas of improvement, jointly develop research agenda and execute on the same using cutting edge algorithms and tools.
You will need to understand a broad range of ML algorithms and appreciation on how to apply them to complex practical problems. You will also need to have enough theoretical background and a good grasp of algorithms to be able to critically evaluate existing ML algorithms and be creative when there is a need to go beyond textbook solutions.




Who should apply for this role ?




PhD/Research Degree or BS/MS in Computer Science, Statistics, Artificial Intelligence, Machine learning, Operations Research or related field.
3- 5 years of experience in building Machine Learning/AI/Information Retrieval models
Extensive knowledge and practical experience in machine learning, data mining, artificial intelligence, statistics.
Understanding of supervised and unsupervised algorithms including but not limited to linear models, decision trees, random forests, gradient boosting machines etc.
Excellent analytical and problem-solving abilities.
Good knowledge of scientific programming in Python.
Experience with Apache Spark is desired.
Excellent verbal & written communication skills

Bonus Points:

Publications or presentation in recognized Machine Learning and Data Mining journals/conferences such as ICML
Knowledge in several of the following: Math/math modeling, decision theory, fuzzy logic, Bayesian techniques, optimization techniques, statistical analysis of data, information retrieval, natural language processing, large scale data processing and data mining
Ability deal with ambiguity & break them down into research problems
Strong theoretical and research acumen
Show more "
Data Scientist,HCLTech,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-scientist-at-hcltech-4279889600?position=19&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=q%2ByIp%2FviLc0hlZgv6QDkpQ%3D%3D,"Dear Candidate,

Greetings from HCL Tech!!

We are hiring Data scientist – Machine Learning requirement

Below is the JD for your perusal:

JD:

• Develop and implement AI models capable of accurate predictions.

• Analyze input data to identify key factors influencing rapid movements, utilizing data-driven insights.

• Establish and maintain a continuous learning framework to update models based on planner feedback.

Skills:

• Expert in AI and machine learning model development

• Strong programming knowledge in Python




If interested, kindly revert this mail with the details in the below format along with updated resume

Name

Contact Number

Email ID

Current Location

Preferred Location

Total Experience

Relevant Experience

Current Organisation

Current CTC

Expected CTC

Notice Period




Regards

Durga Karunakaran

HCL Technologies Ltd.

Show more "
Data Scientist,Protium,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-scientist-at-protium-4284055487?position=20&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=LYyQeUZ1woongFR9inX3Lw%3D%3D,"Company Description

Protium is a leading engineering-led, risk-focused lender operating in India. With a full stack approach, Protium offers lending services to MSMEs, consumers, and educational institutions through various channels including digital interfaces and dedicated sales teams. Protium uses proprietary models to assess revenues and growth, providing secured and unsecured lending solutions to small businesses and consumers in tier 1, 2, and 3 cities.




Role Description

This is a full-time on-site role for a Data Scientist - Credit Risk at Protium in Bengaluru. The Data Scientist will be responsible for tasks such as data analysis and visualization to assess credit risk, develop risk models, and provide insights for lending decisions.




Qualifications

2-3 years of experience in credit risk based roles in financial or lending industry.
Data Science and Data Analysis skills
Statistics knowledge
SQL / Python knowledge
Strong analytical and problem-solving skills
Excellent communication and presentation abilities
Bachelor's/Master’s degree in Data Science, Statistics, or related field

Show more "
Data Scientist,Marsh McLennan,"Pune, Maharashtra, India",Pune,2025-08-12,https://in.linkedin.com/jobs/view/data-scientist-at-marsh-mclennan-4283541592?position=21&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=wGx0wh5Kq%2FcgJofySq%2BsXw%3D%3D,"Oliver Wyman is seeking candidates for the following position based in the Pune/Mumbai/ Gurgaon office:




We are seeking an experienced Data Scientist to collaborate with cross-functional stakeholders and translate strategic business goals into impactful data science solutions. The ideal candidate will analyze complex datasets, build scalable machine learning models, and develop automated data pipelines to drive data-driven decision-making across the organization. This role requires strong technical expertise, business acumen, and the ability to work within enterprise environments adhering to data governance, security, and compliance standards.




Key Responsibilities:

Partner with business groups and technology teams to understand strategic objectives and translate them into actionable data science projects aligned with enterprise goals.
Analyze large volumes of structured and unstructured data to extract insights, assess data quality, and perform advanced data wrangling and feature engineering.
Design, develop, and implement efficient, scalable, and maintainable code for data manipulation and machine learning model development using Python (Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch) or R.
Develop and maintain automated ETL pipelines leveraging cloud-based platforms such as Databricks, AWS S3, Athena, Glue, or equivalent enterprise data platforms.
Utilize GenAI and ChatGPT APIs to automate data ingestion and processing workflows; familiarity with large language models (LLM), retrieval-augmented generation (RAG), Power BI, and Tableau is a plus.
Build and integrate RESTful APIs to enable seamless and secure data exchange between internal systems and external partners.
Create and maintain automation scripts for data extraction, transformation, and reporting using Python and other scripting languages.
Write optimized SQL queries and manage enterprise-grade database systems; experience with data warehousing solutions such as Redshift, Snowflake, or Azure Synapse is required.
Demonstrate expertise in data modeling, transformation, storytelling, and visualization using Power BI, Tableau, or similar BI tools.
Communicate complex technical insights and analyses clearly and concisely to both technical and non-technical stakeholders, supporting data-driven decision-making.
Apply machine learning, statistical modeling, and time-series forecasting techniques (classification, regression, clustering, random forest, gradient boosting, etc.) to build, calibrate, and validate predictive models.
Deliver end-to-end data pipelines and deploy machine learning models in production environments following enterprise best practices for scalability, monitoring, and governance.
Ensure compliance with data privacy, security policies, and regulatory requirements (e.g., GDPR, HIPAA) during data handling and model deployment.
Collaborate with data engineering, IT, and security teams to ensure robust data infrastructure and governance frameworks.




Required Qualifications:

Bachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related quantitative field.
4+ years of hands-on experience with cloud-based data science and engineering technologies, including platforms like Databricks, AWS S3, Athena, Glue, or comparable enterprise cloud services.
Strong programming skills in Python with expertise in libraries such as Pandas, NumPy, Scikit-learn, TensorFlow, or PyTorch.
Proficient in SQL and experienced with enterprise database management and data warehousing technologies (e.g., Databricks, Redshift, Snowflake, Azure Synapse).
Experience designing and developing automated data pipelines and workflows; familiarity with Git, CI/CD, and DevOps principles.
Proven ability to design, implement, and deploy machine learning models and data workflows in production environments.
Strong analytical, problem-solving, and communication skills, with the ability to translate complex technical concepts for diverse audiences.
Experience working in enterprise environments with strict data governance, security, and compliance requirements.




Preferred Skills:

Experience with GenAI, ChatGPT API integration, and working knowledge of large language models (LLM) and retrieval-augmented generation (RAG).
Proficiency in data visualization tools such as Power BI, Tableau, or equivalent.
Familiarity with REST API development and integration.
Knowledge of time-series forecasting and advanced machine learning algorithms including ensemble methods and deep learning.
Exposure to containerization (Docker), orchestration (Kubernetes), and cloud ML platforms (e.g., Azure ML, Databricks AI Platform).
Experience in agile project delivery and collaborative team environments.




About Oliver Wyman:




Oliver Wyman is a global leader in management consulting. With offices in 70 cities across 30 countries, Oliver Wyman combines deep industry knowledge with specialized expertise in strategy, operations, risk management, and organization transformation. The firm has more than 7,000 professionals around the world who work with clients to optimize their business, improve their operations and risk profile, and accelerate their organizational performance to seize the most attractive opportunities. Oliver Wyman is a business of Marsh McLennan [NYSE: MMC]. For more information, visit www.oliverwyman.com. Follow Oliver Wyman on X @OliverWyman.




Marsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, caste, disability, ethnic origin, family duties, gender orientation or expression, gender reassignment, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law.




Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local office or working onsite with clients at least three days per week. Office-based teams will identify at least one “anchor day” per week on which their full team will be together in person.

Show more "
Data Scientist 1,Uber,"Hyderabad, Telangana, India",Hyderabad,2025-08-06,https://in.linkedin.com/jobs/view/data-scientist-1-at-uber-4281429105?position=22&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=5q812Zpj4hlE6jOs5%2FFDkw%3D%3D,"About The Role

Communication Platform enables all the messages (SMS OTP, Whatsapp, Notifications, Voice Call, Chat) among our users. This role will help improve our communications products in improving the Deliverability, reliability and reach of the messages by optimising the cost at the same time. Improving effieciency of communications among our users will helop improve trip conversion and in turn revenue for the organization.

What The Candidate Will Need / Bonus Points

---- What the Candidate Will Do ----


Build scalable analytical frameworks to support product analytics for Uber's Communications Platform
Own new product experimentation including plan creation, roll-out, and monitoring
Be an invaluable partner to cross-functional teams such as engineering, product management, various data teams to deploy data quality across critical pipelines and to set up processes to triage data issues
Develop and track metrics and reporting functions to measure and monitor products performance on our platform
Effectively and proactively communicate insights and drive projects to drive towards team goals
Proactively seek out opportunities to build new solutions to tackle challenges
Create and drive data quality standards and frameworks to ensure inclusion into pipeline engineering efforts


Basic Qualifications


2+ years of experience (Bachelor) OR 1+ years of experience (Masters) in a data-focused role such as product analytics, business analytics, business operations, or data science
Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience
Experience in programming and/or query languages
Past experience with a Product / Tech company serving millions of customers on multiple platforms and countries


Preferred Qualifications


SQL mastery. Write efficient and complex code in SQL
Experience in Python/R and experimentation, A/B testing, and statistical modelling
Experience in Payments or Compliance with a Product / Tech company
Proven ability to handle and visualise large datasets, explore and utilize raw data feeds
Love of data - you just go get the data you need and turn it into an insightful story.
A well-organized, structured approach to problem-solving
Strong sense of ownership, accountability, and entrepreneurial spirit
Great communicator, problem-solver & confident in decision making
Independent & autonomous, while still a strong teammate
Enthusiastic, self-starting and thrives in changing, agile environments
Show more "
"Scientist , Research & Development",Kenvue,Mumbai Metropolitan Region,Mumbai Metropolitan Region,2025-08-13,https://in.linkedin.com/jobs/view/scientist-research-development-at-kenvue-4267191985?position=23&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=5KMxCzBhIyPjex5Nv2grZg%3D%3D,"Kenvue Is Currently Recruiting For a

Scientist , Research & Development

What We Do

At Kenvue, we realize the extraordinary power of everyday care. Built on over a century of heritage and rooted in science, we’re the house of iconic brands - including NEUTROGENA®, AVEENO®, TYLENOL®, LISTERINE®, JOHNSON’S® and BAND-AID® that you already know and love. Science is our passion; care is our talent.

Who We Are

Our global team is ~ 22,000 brilliant people with a workplace culture where every voice matters, and every contribution is appreciated. We are passionate about insights, innovation and committed to delivering the best products to our customers. With expertise and empathy, being a Kenvuer means having the power to impact millions of people every day. We put people first, care fiercely, earn trust with science and solve with courage – and have brilliant opportunities waiting for you! Join us in shaping our future–and yours. For more information, click here.

Role Reports To

Manager - R&D Essential Health

Location:

Asia Pacific, India, Maharashtra, Greater Mumbai

Work Location:

Fully Onsite

What You Will Do

Kenvue is currently recruiting for:

R&D Scientist - Womens Health

This position reports into R&D Manager, Women’s Health and is based at Mumbai.

Who We Are

Our global team is ~ 22,000 brilliant people with a workplace culture where every voice matters, and every contribution is appreciated. We are passionate about insights, innovation and committed to delivering the best products to our customers. With expertise and empathy, being a Kenvuer means having the power to impact millions of people every day. We put people first, care fiercely, earn trust with science and solve with courage - and have brilliant opportunities waiting for you! Join us in shaping our future-and yours. For more information, click here.

Role reports to: R&D Manager

Location: Mumbai

Travel %: 25%

Key Responsibilities

The R&D Scientist - Womens Health is responsible for working independently to identify, assess, and develop new scientific concepts and technologies. You will conduct research of a complex nature, ensuring quality conduct of projects and making timely technical decisions:


Execute research and development projects focused on womens health, including the design and execution of experiments
Collaborate with cross-functional teams to drive innovation and develop new products in the womens health space
Stay current with the latest advancements in womens health research and incorporate new findings into project strategies
Analyze and interpret complex data to draw meaningful conclusions and make recommendations for further research
Understanding sanitary product ingredient, design & construction design on product performance and being able to adapt to meet required criteria.
Present research findings to internal and external stakeholders in a clear and compelling manner
Identifying, assessing, and developing new scientific concepts and technologies for Womens Health
Independently conduct complex projects, analyzing data and evaluating various factors to drive innovation and continuous improvement in materials, processes, and scientific procedures
Embed clear consumer insight into new innovation, develop prototypes and impactful demo’s to bring science to life.
Maintain accurate records of project information and ensure proper retention of records and raw data


Required Qualifications

What we are looking for


Master's Degree or equivalent in a related field
Minimum 2-3 years of proven experience in research and development
Strong analytical skills
Excellent communication and presentation skills
Ability to work collaboratively in a fast-paced environment
Candidates having experience in Femcare product designing, end-to-end prototype development for sanitary pads, diapers would be preferred.


Desired Qualifications


Background in Engineered Products, Textiles or Materials
Experiencing in developing and implementing products across women’s health portfolio


What’s In It For You


Competitive Benefit Package*
Paid Company Holidays, Paid Vacation, Volunteer Time & More!
Learning & Development Opportunities
Kenvuer Impact Networks
This list could vary based on location/region
Note: Total Rewards at Kenvue include salary, bonus (if applicable) and benefits. Your Talent Access Partner will be able to share more about our total rewards offerings and the specific salary range for the relevant location(s) during the recruitment & hiring process.


Kenvue is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment based on merit without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

If you are an individual with a disability, please check our Disability Assistance page for information on how to request an accommodation.
Show more "
AI Engineer,Fusemachines,"Pune, Maharashtra, India",Pune,2025-08-08,https://in.linkedin.com/jobs/view/ai-engineer-at-fusemachines-4282134885?position=24&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=skao5Fcey4NpKF%2F0e0MVcw%3D%3D,"About Fusemachines

Fusemachines is a 10+ year old AI company, dedicated to delivering state-of-the-art AI products and solutions to a diverse range of industries. Founded by Sameer Maskey, Ph.D., an Adjunct Associate Professor at Columbia University, our company is on a steadfast mission to democratize AI and harness the power of global AI talent from underserved communities. With a robust presence in four countries and a dedicated team of over 400 full-time employees, we are committed to fostering AI transformation journeys for businesses worldwide. At Fusemachines, we not only bridge the gap between AI advancement and its global impact but also strive to deliver the most advanced technology solutions to the world.

Location: Remote (Full-time)

Role Overview:

We are seeking a highly skilled and motivated MLOps Engineer with a strong background in computer vision. In this role, you will be responsible for the full lifecycle of our machine learning models, from development and optimization to deployment and scaling. You will build and maintain the infrastructure that allows our cutting-edge computer vision algorithms to run reliably and efficiently in production. The ideal candidate will have a deep understanding of both MLOps principles and 3D computer vision, with hands-on experience in containerization, model optimization, and scalable systems.

Key Responsibilities:


Design, build, and maintain robust, scalable, and automated MLOps pipelines for model training, evaluation, and deployment (CI/CD for ML)
Containerize machine learning applications using Docker for scalable and reproducible deployments
Deploy and manage ML models at scale
Optimize deep learning models for inference performance, including techniques like quantization, pruning, and distillation
Work with and extend state-of-the-art AI models for tasks such as:
Depth estimation and 6D object pose estimation
Image and video segmentation
Dense point tracking and feature matching
Develop and maintain monitoring systems to track model performance, detect data drift, and ensure the reliability of production systems
Collaborate with AI researchers and software engineers to transition models from research to production
Manage and optimize pipelines for processing large-scale 3D data, including point clouds, LiDAR, and stereoscopic imagery
Apply a strong mathematical understanding of spatial transformations, rigid body rotations, and coordinate frame alignment to ensure algorithmic integrity in production


Required Qualifications:


Bachelor's in Computer Science, Engineering, or a related field
Proven experience in an MLOps, DevOps, or similar role with a focus on machine learning
Strong programming skills in Python and/or C++
A portfolio of projects or publications in the field of computer vision or MLOps
Hands-on experience with model optimization techniques (quantization, etc.) and frameworks (e.g., TensorRT, ONNX Runtime)
Hands-on experience with containerization technologies
Experience with CI/CD tools (e.g., Jenkins, GitLab CI, CircleCI) and version control (Git)
Solid understanding of general computer vision and 3D computer vision principles
Experience with deep learning frameworks such as PyTorch or TensorFlow
A strong mathematical foundation in spatial transformations, rigid body rotations, coordinate frame alignment, and triangulation


Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by applicable federal, state, or local laws.

Powered by JazzHR

CKEyAqRgGj
Show more "
Senior Data Scientist - Operational research,Myntra,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-05,https://in.linkedin.com/jobs/view/senior-data-scientist-operational-research-at-myntra-4280064252?position=25&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=aoN87z7aospV8DIthfLl9g%3D%3D,"About Team

The Myntra Data Science team is at the forefront of innovation, delivering cutting-edge solutions that drive significant revenue and enhance customer experiences across various touchpoints. Every quarter, our models impact millions of customers, leveraging real-time, near-real-time, and offline solutions with diverse latency requirements. These models are built on massive datasets, allowing for deep learning and growth opportunities within a rapidly expanding organization. By joining our team, you'll gain hands-on experience with an extensive e-commerce platform, learning to develop models that handle millions of requests per second with sub-second latency.

We take pride in deploying solutions that not only utilize state-of-the-art machine learning techniques—such as graph neural networks, diffusion models, transformers, representation learning, optimization methods, and Bayesian modeling—but also contribute to the research community with multiple peer-reviewed publications.

Roles and Responsibilities

Design, develop, and deploy advanced machine learning models and algorithms for Forecasting, Operations Research, and Time Series applications.
Build and implement scalable solutions for supply chain optimization, demand forecasting, pricing, and trend prediction.
Develop efficient forecasting models leveraging traditional and deep learning-based time series analysis techniques.
Utilize optimization techniques for large-scale nonlinear and integer programming problems.
Hands-on experience with optimization solvers like CPLEX, Gurobi, COIN-OR, or similar tools.
Collaborate with Product, Engineering, and Business teams to understand challenges and integrate ML solutions effectively.
Maintain and optimize machine learning pipelines, including data cleaning, feature extraction, and model training.
Implement CI/CD pipelines for automated testing, deployment, and integration of machine learning models.
Work closely with the Data Platforms team to collect, process, and analyze data crucial for model development.
Stay up to date with the latest advancements in machine learning, forecasting, and optimization techniques, sharing insights with the team.

Qualifications & Experience

Experience with a Bachelor’s degree in Statistics, Operations Research, Mathematics, Computer Science, or a related field.
Strong foundation in data structures, algorithms, and efficient processing of large datasets.
Proficiency in Python for data science and machine learning applications.
Experience in developing and deploying forecasting and time series models.
Knowledge of ML frameworks such as TensorFlow, PyTorch, and Scikit-learn.
Hands-on experience with optimization solvers and algorithms for supply chain and logistics problems.
Strong problem-solving skills with a focus on applying OR techniques to real-world business challenges.
Good to have research publications in Machine Learning, Forecasting, or Operations Research.
Familiarity with cloud computing services (AWS, Google Cloud) and distributed systems.
Strong communication skills with the ability to work independently and collaboratively in a team environment.

Nice to Have

Experience with Generative AI and Large Language Models (LLMs).
Knowledge of ML orchestration tools such as Airflow, Kubeflow, and MLflow.
Exposure to NLP and Computer Vision applications in an e-commerce setting.
Understanding of ethical considerations in AI, including bias, fairness, and privacy.

Exceptional candidates are encouraged to apply, even if they don’t meet every listed qualification. We value potential and a strong willingness to learn.

Show more "
Data Scientist,Recro,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-at-recro-4282497829?position=26&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Glz4b8iJ1Iy2Z%2BkV2e432A%3D%3D,"Note: We are hiring Y25 Company

Role Overview

We are looking for a Senior AI/Data Scientist with 3-5 years of experience who is passionate about

building AI and machine learning solutions for real-world business problems.

As part of our AI team, you will design, develop and deploy advanced machine learning models,

Generative AI applications and AI-powered decision systems. You will work with structured and

unstructured data, develop predictive models, AI-driven insights and business-aware

Generative AI agents that enhance productivity and decision-making.

Key Responsibilities

• Build Gen AI-enabled solutions using online and offline LLMs, SLMs and TLMs tailored to

domain-specific problems.

• Deploy agentic AI workflows and use cases using frameworks like LangGraph, Crew AI etc.

• Apply NLP, predictive modelling and optimization techniques to develop scalable machine

learning solutions.

• Integrate enterprise knowledge bases using Vector Databases and Retrieval Augmented

Generation (RAG).

• Apply advanced analytics to address complex challenges in Healthcare, BFSI and

Manufacturing domains.

• Deliver embedded analytics within business systems to drive real-time operational insights.




Required Skills & Experience

• 3–5 years of experience in applied Data Science or AI roles.

• Experience working in any one of the following domains: BFSI, Healthcare/Health Sciences,

Manufacturing or Utilities.

• Proficiency in Python, with hands-on experience in libraries such as scikit-learn, TensorFlow

• Practical experience with Gen AI (LLMs, RAG, vector databases), NLP and building scalable

ML solutions.

• Experience with time series forecasting, A/B testing, Bayesian methods and hypothesis

testing.

• Strong skills in working with structured and unstructured data, including advanced feature

engineering.

• Familiarity with analytics maturity models and the development of Analytics Centre of

Excellence (CoE’s).

• Exposure to cloud-based ML platforms like Azure ML, AWS SageMaker or Google Vertex AI.

• Data visualization using Matplotlib, Seaborn, Plotly; experience with Power BI is a plus.




What We Look for (Values & Behaviours)

• AI-First Thinking – Passion for leveraging AI to solve business problems.

• Data-Driven Mindset – Ability to extract meaningful insights from complex data.

• Collaboration & Agility – Comfortable working in cross-functional teams with a fast-paced

mindset.

• Problem-Solving – Think beyond the obvious to unlock AI-driven opportunities.

• Business Impact – Focus on measurable outcomes and real-world adoption of AI.

• Continuous Learning – Stay updated with the latest AI trends, research and best practices.

Why Join Us?

• Work on cutting-edge AI & GenAI projects.

• Be part of a high-Caliber AI team solving complex business challenges.

• Exposure to global enterprises and AI-driven decision-making.

• Competitive compensation and fast-track career growth in AI.

• Get mentored by best-in-class AI leaders who will help shape you into a top AI professional

Show more "
"Data Scientist Product, Analytics, Insights and Measurement",Google,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-product-analytics-insights-and-measurement-at-google-4283040318?position=27&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=vY0lJP94BnPklXdW7mn69g%3D%3D,"Minimum qualifications:


Bachelor's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field.
5 years of work experience with analysis applications (extracting insights, performing statistical analysis, or solving business problems), and coding (Python, R, SQL) or 2 years work experience with a Master's degree.


Preferred qualifications:


Master's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field.
Experience with privacy-preserving technologies and data regulations.
Understanding of digital advertising measurement concepts, including attribution modeling, incrementality testing, and media mix modeling (MMM).


About The Job

Help serve Google's worldwide user base of more than a billion people. Data Scientists provide quantitative support, market understanding and a strategic perspective to our partners throughout the organization. As a data-loving member of the team, you serve as an analytics expert for your partners, using numbers to help them make better decisions. You will weave stories with meaningful insight from data. You'll make critical recommendations for your fellow Googlers in Engineering and Product Management. You relish tallying up the numbers one minute and communicating your findings to a team leader the next.

Responsibilities


Driving business growth and help the team to empower advertisers with the tools and insights they need to navigate the evolving digital advertising landscape.
Develop quantitative models and frameworks to assess the business opportunity associated with improvements in attribution, incrementality testing, full-funnel measurement, and online-to-offline (O2O) measurement.
Quantify the impact of data deprecation and regulatory changes on Ads performance. Develop metrics to track the effectiveness of the mitigation strategies and data durability initiatives.
Define success metrics for the efforts to create a unified measurement platform. Analyze the impact of closing measurement gaps and enhance the customer value proposition.



Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
Show more "
Data Scientist,Recro,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-scientist-at-recro-4283871722?position=28&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=ULXay8pz3c%2FvtzXhUPLS1w%3D%3D,"About Us:

At Recro, we connect top tech talent with innovative companies. We are hiring for our client, a product-based company in the retail domain, seeking a Data Scientist who can apply scientific thinking to real-world business problems and drive impactful solutions.

Key Responsibilities

Investigate the feasibility of applying scientific principles and concepts to solve complex business challenges.
Independently design and develop new algorithms for well-defined retail problems, and optimize existing algorithms for better performance.
Collaborate with the product team to implement new modules, maintain production pipelines, and ensure timely releases.
Build Proof of Concepts (POCs) using new ideas or technologies, and promote innovative solutions with internal and external stakeholders.
Work closely with Data Engineering, Advisory, and Product teams to identify improvement areas and drive process efficiency.

Mandatory Skills & Experience

Retail Experience & Business Acumen – At least one retail project experience, even if it’s 30–50% of your overall work experience.
Machine Learning – End-to-end development of at least one ML model independently.
Programming & Tools – Strong hands-on experience with SQL and Python (PySpark is a plus).

Preferred Qualifications

Experience with large-scale data processing frameworks.
Exposure to cloud platforms (AWS, Azure, or GCP).
Strong analytical and problem-solving skills.

Why Join?

Opportunity to work on impactful projects in the retail analytics domain.
Collaborative work culture with innovative and agile teams.
Scope to experiment, innovate, and bring ideas to life.

Show more "
Data Scientist ( IBM Data Stage),Genpact,"Gurugram, Haryana, India",Gurugram,2025-08-06,https://in.linkedin.com/jobs/view/data-scientist-ibm-data-stage-at-genpact-4280787626?position=29&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=fz0l74IBO5ojqJJ84CN0WQ%3D%3D,"Location: Gurgaon / Noida




Inviting applications for the role of Manager -Data Scientist ( IBM Data Stage)




Responsibilities :




Proven experience of consulting experience (client facing) related to Data migration/ data integration/ETL implementation in projects. Experience must include complete knowledge of SDLC like mapping, ETL design, development, testing etc.
Expertise on IBM Infosphere Data Stage version 11.0 and above, Quality Stage, Data Architect, Business Glossary.
Experience implementing database solutions on MS SQL Server, Oracle, DB2 and Fabric required.
Knowledge on UNIX scripting
Good knowledge on Data Warehouse concepts
Expertise with implementing ETL solutions. Certification would be preferred.
Strong experience on Design, Development, Unit Testing of the DataStage code.
Strong knowledge on the Performance tuning of the DS Jobs and SQL.
End to End ETL Development, transforming and loading data warehouse and mart tables
Complex SQL Development Scripts




Minimum qualifications :




Proven ETL experience (client facing) related to data warehouse/Analytics / Datastage, other any ETL tool.
Expertise on Infosphere Data Stage version 11.0 and above, Quality Stage ,Data Architect, Business Glossary and DB2.
Expertise with implementing ETL solutions in IBM DataStage. Certification would be preferred.
Experience in implementing database solutions on MS SQL Server, Oracle and DB2 required.
Strong experience on Design, Development, Unit Testing of the DataStage code.
Strong knowledge on the Performance tuning of the DS Jobs.




Preferred qualifications :




Experience in implementing database solutions on MS SQL Server, Oracle and DB2 required.
Microsoft/IBM Cloud experience

Show more "
Data Scientist,Impetus,"Gurugram, Haryana, India",Gurugram,2025-08-07,https://in.linkedin.com/jobs/view/data-scientist-at-impetus-4281490874?position=30&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=9pzNdDY5GPynORxryu44BQ%3D%3D,"About Impetus




Impetus Technologies is a digital engineering company focused on delivering expert services and products to help enterprises achieve their transformation goals. We solve the analytics, AI, and cloud puzzle, enabling businesses to drive unmatched innovation and growth.

Founded in 1991, we are cloud and data engineering leaders providing solutions to fortune 100 enterprises, headquartered in Los Gatos, California, with development centers in NOIDA, Indore, Gurugram, Bengaluru, Pune, and Hyderabad with over 3000 global team members. We also have offices in Canada and Australia and collaborate with a number of established companies, including American Express, Bank of America, Capital One, Toyota, United Airlines, and Verizon.




Job Role- Data Scientist




Experience- 3.5+ years- 15 years




Locations- Indore, Bangalore, Pune, Gurgaon, Noida, Hyderabad




Job Description

Hands on experience of working with LLM (Large Language Models) or LangChain and OpenAI in particular.
Implementing and fine tuning the AI- generated text prompts using LLMs (eg:-GPT4)
Skilled in AI-specific utilities like ChatGPT, Hugging Face Transformers, etc.
Ability to understand business requirements.
Usecase derivation and solution creation from structured/unstructured data
Story telling, Business communication and Documentation
Programming Skills – Python, Scikit-Learn, TensorFlow, PyTorch, Keras
Exploratory Data Analysis
Machine Learning and Deep Learning Algorithms
Model building, Hyperparameter tuning and Model performance metrics
MLOps, Data Pipeline, Data engineering
Statistics Knowledge (Probability Distributions, Hypothesis Testing)
Time series modeling, Forecasting, Image/Video Analytics, Natural Language Processing (NLP).
ML services from Clouds such as AWS, GCP, Azure and Databricks
Optional - Big Data -Basic knowledge on Spark, Hive




Roles & Responsibilities

Acquire skills required for building Machine learning models and deploy them for production.

Feature Engineering, EDA, Pipeline creation, Model training and hyperparameter tuning with structured and unstructured data sets.

Develop Cloud based applications including LLM/GenAI and deploy them into production.




Qualification

Degree – Graduates/Postgraduate in CSE/IT or related field

Show more "
Decision Scientist,PhonePe,"Bengaluru, Karnataka, India",Bengaluru,2025-08-10,https://in.linkedin.com/jobs/view/decision-scientist-at-phonepe-4245296810?position=31&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Sr4Bb2RapC797owlzciF1A%3D%3D,"About PhonePe Limited:

Headquartered in India, its flagship product, the PhonePe digital payments app, was launched in Aug 2016. As of April 2025, PhonePe has over 60 Crore (600 Million) registered users and a digital payments acceptance network spread across over 4 Crore (40+ million) merchants. PhonePe also processes over 33 Crore (330+ Million) transactions daily with an Annualized Total Payment Value (TPV) of over INR 150 lakh crore.

PhonePe’s portfolio of businesses includes the distribution of financial products (Insurance, Lending, and Wealth) as well as new consumer tech businesses (Pincode - hyperlocal e-commerce and Indus AppStore Localized App Store for the Android ecosystem) in India, which are aligned with the company’s vision to offer every Indian an equal opportunity to accelerate their progress by unlocking the flow of money and access to services.

Culture:

At PhonePe, we go the extra mile to make sure you can bring your best self to work, Everyday!. And that starts with creating the right environment for you. We empower people and trust them to do the right thing. Here, you own your work from start to finish, right from day one. PhonePe-rs solve complex problems and execute quickly; often building frameworks from scratch. If you’re excited by the idea of building platforms that touch millions, ideating with some of the best minds in the country and executing on your dreams with purpose and speed, join us!

Position: Decision Scientist

Roles and Responsibilities:-


Regular analysis of the transaction and customer behaviour data to identify the key fraud trends and develop strategies to prevent the fraud and reduce genuine customer impact.
Develop key fraud metrics across different merchant categories and communicate portfolio trends with the respective stakeholders.
Support ad hoc analytical projects.
Interact with cross functional teams (product, tech, operation, compliance, business) to develop fraud risk solutions.
Proactively identify opportunities to enhance the current fraud risk management process.
Explore new tools and features for better fraud prevention.
Work closely with the business team in developing strategies for the new product launch.


Skills and Qualifications:-


Bachelor’s in engineering or Master's degree in Management, Maths, Statistics or related quantitative discipline.
You must have 3+ years of experience in data analytics / risk analytics / business analytics.
Proficient in SQL. Should be able to write queries to manipulate and consolidate data from multiple data sources.
Excellent Excel skills.
Strong quantitative abilities, distinctive problem-solving and excellent analytical skills.
Strong organisational, communication, presentation and project management skills.
Good working knowledge of programming languages like Python, R, SAS.
Theoretical and practical knowledge of statistical techniques such as regression, segmentation, forecasting.
Working experience with BI tools (QlikView/Tableau/PowerBI/ QlikSense etc) will be an added advantage.


PhonePe Full Time Employee Benefits (Not applicable for Intern or Contract Roles)


Insurance Benefits - Medical Insurance, Critical Illness Insurance, Accidental Insurance, Life Insurance
Wellness Program - Employee Assistance Program, Onsite Medical Center, Emergency Support System
Parental Support - Maternity Benefit, Paternity Benefit Program, Adoption Assistance Program, Day-care Support Program
Mobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy
Retirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment
Other Benefits - Higher Education Assistance, Car Lease, Salary Advance Policy


Our inclusive culture promotes individual expression, creativity, innovation, and achievement and in turn helps us better understand and serve our customers. We see ourselves as a place for intellectual curiosity, ideas and debates, where diverse perspectives lead to deeper understanding and better quality results. PhonePe is an equal opportunity employer and is committed to treating all its employees and job applicants equally; regardless of gender, sexual preference, religion, race, color or disability. If you have a disability or special need that requires assistance or reasonable accommodation, during the application and hiring process, including support for the interview or onboarding process, please fill out this form.

Read more about PhonePe on our blog.

Life at PhonePe

PhonePe in the news
Show more "
Data Scientist (3-5),PhonePe,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/data-scientist-3-5-at-phonepe-4252691572?position=32&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=FNJ3%2BwooIgfugtSwSMWDPQ%3D%3D,"About PhonePe Limited:

Headquartered in India, its flagship product, the PhonePe digital payments app, was launched in Aug 2016. As of April 2025, PhonePe has over 60 Crore (600 Million) registered users and a digital payments acceptance network spread across over 4 Crore (40+ million) merchants. PhonePe also processes over 33 Crore (330+ Million) transactions daily with an Annualized Total Payment Value (TPV) of over INR 150 lakh crore.

PhonePe’s portfolio of businesses includes the distribution of financial products (Insurance, Lending, and Wealth) as well as new consumer tech businesses (Pincode - hyperlocal e-commerce and Indus AppStore Localized App Store for the Android ecosystem) in India, which are aligned with the company’s vision to offer every Indian an equal opportunity to accelerate their progress by unlocking the flow of money and access to services.

Culture:

At PhonePe, we go the extra mile to make sure you can bring your best self to work, Everyday!. And that starts with creating the right environment for you. We empower people and trust them to do the right thing. Here, you own your work from start to finish, right from day one. PhonePe-rs solve complex problems and execute quickly; often building frameworks from scratch. If you’re excited by the idea of building platforms that touch millions, ideating with some of the best minds in the country and executing on your dreams with purpose and speed, join us!

Job Description

We are seeking a motivated and skilled Data Scientist with 3 years of experience to join our dynamic team. The ideal candidate will have a strong foundation in machine learning, with a focus on implementing algorithms at scale. Additionally, knowledge of computer vision and natural language processing will be ideal

Key Responsibilities:


Develop and implement machine learning models, offline batch models as well as real time online and edge compute models
Analyze complex datasets and extract meaningful insights to drive business decisions
Collaborate with cross-functional teams to identify and solve business problems using data-driven approaches
Communicate findings and recommendations to stakeholders effectively


Required Qualifications:


Bachelor's or Master's degree in Computer Science, Data Science, Statistics, or a related field
3+ years of experience in a Data Scientist role
Strong proficiency in Python and SQL
Solid understanding of machine learning algorithms and statistical modeling techniques
Knowledge of Natural Language Processing (NLP) and Computer Vision (CV) concepts and algorithms
Hands-on experience implementing and deploying machine learning algorithms
Experience with data visualization tools and techniques
Strong analytical and problem-solving skills
Excellent communication skills, both written and verbal


Preferred Qualifications:


Experience with PySpark and other big data processing frameworks
Knowledge of deep learning frameworks (e.g., TensorFlow, PyTorch)


Technical Skills:


Programming Languages: Python (required), SQL (required), Java (basic knowledge preferred)
Machine Learning: Strong foundation in traditional ML algorithms, and a working knowledge of NLP and Computer Vision
Big Data: Deep knowledge of PySpark
Data Storage and Retrieval: Familiarity with databases/mlflow preferred
Mathematics: Strong background in statistics, linear algebra, and probability theory
Version Control: Git


Soft Skills:


Excellent communication skills to facilitate interactions with stakeholders
Ability to explain complex technical concepts to non-technical audiences
Strong problem-solving and analytical thinking
Self-motivated and able to work independently as well as in a team environment
Curiosity and eagerness to learn new technologies and methodologies


We're looking for a motivated individual who is passionate about data science and eager to take on challenging tasks. If you thrive in a fast-paced environment and are excited about leveraging cutting-edge technologies in machine learning to solve real-world problems, we encourage you to apply!

PhonePe Full Time Employee Benefits (Not applicable for Intern or Contract Roles)


Insurance Benefits - Medical Insurance, Critical Illness Insurance, Accidental Insurance, Life Insurance
Wellness Program - Employee Assistance Program, Onsite Medical Center, Emergency Support System
Parental Support - Maternity Benefit, Paternity Benefit Program, Adoption Assistance Program, Day-care Support Program
Mobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy
Retirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment
Other Benefits - Higher Education Assistance, Car Lease, Salary Advance Policy


Our inclusive culture promotes individual expression, creativity, innovation, and achievement and in turn helps us better understand and serve our customers. We see ourselves as a place for intellectual curiosity, ideas and debates, where diverse perspectives lead to deeper understanding and better quality results. PhonePe is an equal opportunity employer and is committed to treating all its employees and job applicants equally; regardless of gender, sexual preference, religion, race, color or disability. If you have a disability or special need that requires assistance or reasonable accommodation, during the application and hiring process, including support for the interview or onboarding process, please fill out this form.

Read more about PhonePe on our blog.

Life at PhonePe

PhonePe in the news
Show more "
AI/ML,KiwiTech,"Noida, Uttar Pradesh, India",Noida,2025-08-12,https://in.linkedin.com/jobs/view/ai-ml-at-kiwitech-4283565394?position=33&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=nH65L%2FV6WGIHpBiv2TBIeQ%3D%3D,"Job Description


3+ years of experience in ML and AI, with a strong track record of leading and delivering complex ML and AI projects.
In-depth knowledge of ML and AI concepts, algorithms, and techniques, including supervised and unsupervised learning, reinforcement learning, and neural networks.
Proficiency in programming languages such as Python, R, or Scala, along with ML and AI libraries and frameworks (e.g., TensorFlow, PyTorch, scikit-learn).
Experience in applying ML and AI techniques to solve real-world problems in areas such as recommendation systems, fraud detection, natural language processing, or computer vision.
Strong understanding of data engineering principles and experience working with large-scale datasets.
Excellent leadership and people management skills, with the ability to motivate and inspire a team of data scientists and engineers.
Proven ability to translate business requirements into ML and AI solutions and effectively communicate technical concepts to non-technical stakeholders.
Strong analytical and problem-solving skills, with the ability to think strategically and drive innovation.
Excellent communication, presentation, and interpersonal skills.


Minimum Qualification


Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
A Ph.D. is a plus.
Show more "
Data Scientist,Yum! India Global Services Private Limited,"Gurugram, Haryana, India",Gurugram,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-at-yum%21-india-global-services-private-limited-4282487699?position=34&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=cp%2BtbxmAIXj4va368zmErA%3D%3D,"Looking for immediate joners or serving notice period would be preferred




Purpose of the Role

At Yum! We’re looking for a Data Scientist II to add to our dynamic and rapidly scaling team. We’d want you to be part of our mission to optimize our digital channels and technology innovations with the end goal of creating competitive advantages for our restaurants around the globe and other engagements. We’re looking for a solid analytics professional who brings fresh ideas from experience and is eager to tackle new challenges in our company.




As a Data Scientist II, you will:

Analyze data and generate analytical outputs to deliver insights, evaluate the hypothesis and complete root cause analysis of the business problem.
Should have strong analytical skillset to design end to end solution leveraging the latest machine learning (ML) techniques, including data preparation, exploratory data analysis, feature engineering, model selection, model development, model evaluation, cross-validation, and deployment
Effectively present the analytics approach and insights to a larger business audience.
Solve business problems which involves:
Brainstorm with clients and internal teams to define a problem
Translate the business problem into an analytical problem
Identify internal and external data requirements for solving the analytical problem
Solving the analytical problem using concepts from mathematics, statistics, Artificial Intelligence and Machine learning
Create, maintain and enhance artefacts that can help communicate the solution to clients like dashboards, power point decks, excel sheets etc.
Mentor team and handle day to day project deliverables and timeline.

Minimum Requirements:

Bachelor’s degree / master’s degree in engineering, quantitative field such as statistics, business analytics or equivalent past work experience
4-6 years of experience in data science, leading teams, building hands-on Analytical models
Advanced SQL skills, excellent programming skills in Python. Strong working knowledge of Python’s numerical, data analysis, or AI frameworks.
Hands-on experience working with regression, clustering, decision trees and related models.
Ability to use data and metrics to back up assumptions, evaluate the hypothesis and complete root cause analysis of the business problem.
Experience in integrating business analysis with technical solutions that involve advanced analytics solutions, demand forecasting, segmentation, churn prediction, predictive maintenance, and route optimization, etc.

Show more "
AI/ML Engineer,Awign,"Maharashtra, India",Maharashtra,2025-08-10,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-awign-4282727909?position=35&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=K8aqNpAf2caFy2V1O2uW9g%3D%3D,"We are seeking a highly skilled AI/ML Engineer with expertise in AWS AI/ML services and a strong understanding of Generative AI using Amazon Bedrock. The ideal candidate will have experience in building, deploying, and optimizing AI/ML models on AWS, integrating LLMs into applications, and leveraging AWS services for scalable AI solutions.

Key Responsibilities
Design, develop, and deploy AI/ML models on AWS, leveraging SageMaker, Bedrock, and related services.
Build LLM-based applications using Amazon Bedrock and fine-tune models for specific use cases.
Implement RAG (Retrieval-Augmented Generation) and integrate vector databases like OpenSearch, Pinecone, or FAISS.
Develop scalable, production-ready ML pipelines using AWS services (Lambda, Step Functions, S3, DynamoDB, etc.).
Utilize Bedrock, SageMaker, and custom fine-tuned models to deliver business-driven AI solutions.
Work with cross-functional teams to integrate ML models into real-world applications.
Ensure AI solutions adhere to best practices for security, compliance, and cost optimization.
Stay updated with the latest trends in GenAI, prompt engineering, and AI model optimization.

Required Skills
Strong expertise in AWS AI/ML stack – Amazon Bedrock, SageMaker, Lambda, Step Functions, S3, DynamoDB, etc.
Experience with Generative AI models (GPT, Claude, Mistral, LLaMA, etc.) and fine-tuning techniques.
Hands-on experience in Python, TensorFlow, PyTorch, or Hugging Face.
Knowledge of vector databases and embedding models.
Experience in building secure and scalable AI applications using AWS.
Familiarity with MLOps practices, CI/CD for ML models, and cloud automation.
Strong problem-solving skills and ability to work in a fast-paced environment.

Good to Have
Experience with LangChain, Prompt Engineering, and RAG techniques.
Understanding of data governance, AI ethics, and responsible AI practices.
Certification in AWS Machine Learning Specialty/ Associate or relevant AI certifications.

Relevant Skills
vector databases, models, mlops, ml, pytorch, s3, lambda, tensorflow, ci/cd, amazon




Show more "
Data Scientist (Python and AI/ML),EXL,"Noida, Uttar Pradesh, India",Noida,2025-08-14,https://in.linkedin.com/jobs/view/data-scientist-python-and-ai-ml-at-exl-4285700271?position=36&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=NBT%2FepbvXp2sR7gRTaUfhQ%3D%3D,"We are seeking a skilled Data Scientist with experience in Python, AI/ML to design, develop, and deploy cutting-edge machine learning solutions. You will work closely with data scientists, analysts, and engineering teams to translate business needs into scalable AI-driven applications.




Key Responsibilities:

Design, implement, and optimize machine learning models and algorithms.
Work with large datasets to perform data cleaning, preprocessing, and feature engineering.
Develop and maintain Python-based AI/ML pipelines and APIs for integration with production systems.
Apply deep learning frameworks (e.g., TensorFlow, PyTorch, Keras) for NLP, computer vision, or predictive analytics.
Evaluate model performance using statistical and ML metrics; fine-tune hyperparameters for optimal results.




Key Qualifications:

- A seasoned resource with 4+ years of experience in Python, AI & ML

- Strong proficiency in Python and libraries such as NumPy, Pandas, Scikit-learn, Matplotlib, Seaborn.

- Experience with ML/DL frameworks like TensorFlow, PyTorch, or Keras.

- Good understanding of data preprocessing, feature selection, and model evaluation techniques.

- Understanding of Generative AI and LLM fine-tuning.

- Exposure to big data technologies (Spark, Hadoop).

- Familiarity with cloud AI services (GCP, AWS, Azure ML/AI Platform) is a plus.

- Knowledge of SQL/NoSQL databases and basic data engineering concepts.

- Strong problem-solving skills and ability to work in agile environments

Show more "
Data Scientist,Yulu,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-at-yulu-4283426315?position=37&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=dJ95j3NtGAlBW44BjcURrg%3D%3D,"About Yulu

Yulu is India’s leading shared micro-mobility platform, revolutionizing urban transportation through smart, sustainable, and electric-first mobility solutions. With a rapidly growing fleet of tech-enabled electric two-wheelers and a robust battery-swapping infrastructure, Yulu makes last-mile commutes not only efficient but also planet-friendly.

Our IoT-driven platform and smart electric vehicles are helping cities reduce traffic congestion and carbon emissions while empowering millions with affordable and reliable transportation.

Backed by industry giants like Bajaj Auto and Magna International, Yulu operates at the intersection of mobility, technology, and sustainability. Our mission is to reduce congestion, cut emissions, and transform how India moves — one ride at a time.

With millions of rides completed, thousands of EVs on the road, and a rapidly expanding footprint, we’re not just building EVs — we’re building the future of urban mobility in India.




🔗 Learn more: www.yulu.bike




Role Summary

Yulu is looking for a Data Scientist to work on developing and refining statistical models and Machine Learning algorithms to address real-world challenges. You will collaborate with cross-functional teams to identify analytical needs, perform exploratory data analysis, and optimize model performance. The role also involves building and maintaining data pipelines, ensuring data quality, and staying up-to-date with emerging AI/ML technologies. If you are passionate about using data to solve impactful problems and transform urban mobility, join us in our mission to reduce traffic congestion and air pollution!




Key Responsibilities

Collect, clean, and preprocess data from diverse sources to ensure quality and accuracy.
Develop and refine statistical models and Machine Learning (ML) algorithms to solve real-world problems.
Collaborate with cross-functional teams (e.g., data engineering, product, and business) to identify and understand analytical needs.
Perform exploratory data analysis (EDA) to uncover patterns, trends, and relationships in datasets.
Evaluate model performance using appropriate metrics, and iterate to optimize accuracy and efficiency.
Document analyses, methodologies, and best practices to maintain clear records for future reference.
Stay up-to-date with emerging AI/ML technologies and actively explore new approaches—especially in the areas of deep learning, Generative AI, and Large Language Models (LLMs).
Present findings and insights to both technical and non-technical stakeholders in a clear, concise manner.




Qualifications

Strong grounding in statistics, math, and machine learning
Hands-on Python: pandas, NumPy, scikit-learn
Comfortable working with data in SQL and/or pandas (joins, windows, groupbys)
Clear written and verbal communication
Experience with GenAI/LLMs (prompts, embeddings, simple RAG)
Visualization: Streamlit, Matplotlib/Seaborn (or Plotly)
Operations Research basics: vehicle routing, task assignment (e.g.,
Hungarian), Job Scheduling
Good software habits: Git, environments, basic tests; any cloud/warehouse exposure




We assure you

Be a part of an innovative company that values professional growth, trustworthy colleagues, a fun environment in the office, and well-being for the employees
A culture that fosters growth, integrity, and innovation

Show more "
Associate Data Scientist,Birlasoft,"Mulshi, Maharashtra, India",Mulshi,2025-08-14,https://in.linkedin.com/jobs/view/associate-data-scientist-at-birlasoft-4259503950?position=38&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=m6dJXJDuYbPxWlnRvjDK2g%3D%3D,"Area(s) of responsibility

Key Responsibilities


Design, develop, extend and maintain end-to-end data workflows and pipelines in Dataiku DSS.
Collaborate with data scientists and analysts to operationalize machine learning models.
Leverage Generative AI models and tools within Dataiku to build advanced AI-powered applications and analytics solutions.
Integrate Dataiku with various data sources (databases, cloud storage, APIs).
Develop and optimize SQL queries and Python/R scripts for data extraction and transformation across relational and NoSQL databases
Work extensively with cloud data warehouses like Amazon Redshift and/or Snowflake for data ingestion, transformation, and analytics.
Implement automation and scheduling of data workflows.
Monitor and troubleshoot data pipelines to ensure data quality and reliability.
Document technical solutions and best practices for data processing and analytics.
Show more "
Research Scientist ( 82209151 ),Reliance Industries Limited,"Vadodara, Gujarat, India",Vadodara,2025-08-08,https://in.linkedin.com/jobs/view/research-scientist-82209151-at-reliance-industries-limited-4281804993?position=39&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=7NSTK181YFU37DcD%2FPEs0A%3D%3D,"Job Responsibilities :


Ensure completion of experiments and generate accurate and reproducible data from experiments. Develop relevant models and validation of the same.
Supervise and execute laboratory / pilot plant experiments pertaining to the relevant research area such as sample preparation using various methods, sample characterization using various analysis & evaluation of the concerned samples.
Organize facilities for experiments in research such as chemicals, equipment, analytical methods etc.
Participate in pilot plant operations / studies, utilize results as boundary conditions for model development
Support to plant operations
Collect data and conduct relevant analysis
Uploading reports on portal
Preparation of Internal Technical Report



Job Title: Chemical Engineer, J Level position, Vadodara Job Purpose

To ensure smooth, safe, and efficient operation of semi-batch and continuous pilot-scale plants for inorganic material production, facilitating seamless scale-up from laboratory to commercial scale while maintaining process safety, quality, and reliability.

Job Description


Operate and monitor inorganic material production processes on semi-batch and continuous pilot-scale plants, ensuring safe and stable operations.
Collaborate closely with the laboratory chemistry team to translate lab-scale processes into pilot-scale and ultimately commercial processes.
Compile and analyse pilot plant data, prepare technical reports, and present findings in team meetings.
Develop basic engineering and process design packages using appropriate tools and methodologies.
Identify opportunities for product quality enhancement and implement corrective actions for process optimization.
Oversee routine maintenance activities, coordinate with the maintenance team to expedite planned and unplanned interventions.
Ensure strict implementation of safety procedures, including work permit systems for maintenance and operational activities.
Prepare, review, and modify Standard Operating Procedures (SOPs) to ensure compliance with plant operations.
Actively participate in critical Process Hazard Analyses (PHA), HAZOP studies, and prepare Management of Change (MOC) documentation as needed.



Skills and Competencies


Strong problem-solving and analytical abilities.
Teamwork and people management skills with the ability to collaborate across functions.
Effective planning and decision-making skills.
Excellent interpersonal, communication, and technical presentation skills.



Education


B.Tech / M.Tech in Chemical Engineering



Experience


1–2 years of experience in material synthesis processes involving chemical reactions, filtration, drying, calcination, and powder milling.



Education Requirement :

PhD in Biology/Chemistry/Chemical Engineering with specialization in relevant research area

Experience Requirement :

Minimum 2-3 Years Of Research Experience

Skills & Competencies :


Conduct literature survey in the area of research and compile information for dissemination & critical analysis.
Develop work method and prepare SOPs for experiments in research including designing & planning of experiments.
Prepare/Use simulation models.
Study technology offers/ process engineering documents
Perform process engineering design activities such as using relevant tools
Familiar with applicable guidelines /codes / standards / legislations relevant to field of research
Show more "
Python Developer,Infosys,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-13,https://in.linkedin.com/jobs/view/python-developer-at-infosys-4284183811?position=40&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=1eVa%2BGkmxpBDH09fJ6MUiw%3D%3D,"Primary skills:Technology->Functional Testing->Mainframe testing->Proterm,Technology->Machine Learning->Python,Technology->OpenSystem->Python - OpenSystem Python


A day in the life of an Infoscion


As part of the Infosys consulting team, your primary role would be to lead the engagement effort of providing high-quality and value-adding consulting solutions to customers at different stages- from problem definition to diagnosis to solution design, development and deployment.
You will review the proposals prepared by consultants, provide guidance, and analyze the solutions defined for the client business problems to identify any potential risks and issues.
You will identify change Management requirements and propose a structured approach to client for managing the change using multiple communication mechanisms.
You will also coach and create a vision for the team, provide subject matter training for your focus areas, motivate and inspire team members through effective and timely feedback and recognition for high performance.
You would be a key contributor in unit-level and organizational initiatives with an objective of providing high-quality, value-adding consulting solutions to customers adhering to the guidelines and processes of the organization. If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!
Good knowledge on software configuration management systems
Strong business acumen, strategy and cross-industry thought leadership
Awareness of latest technologies and Industry trends
Logical thinking and problem solving skills along with an ability to collaborate
Two or three industry domain knowledge
Understanding of the financial processes for various types of projects and the various pricing models available
Client Interfacing skills
Knowledge of SDLC and agile methodologies
Project and Team management
Show more "
Python Developer,Persistent Systems,"Pune, Maharashtra, India",Pune,2025-08-12,https://in.linkedin.com/jobs/view/python-developer-at-persistent-systems-4281287692?position=41&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Ntn%2FYR%2FcF7mCGqd2p9TIfg%3D%3D,"About Position:




We are looking for a skilled and experienced Python Developer to join our team in Pune. The ideal candidate will have a strong background in backend development, cloud deployment, and automation tools, with a passion for building scalable and efficient systems.




Role: Python Developer
Location: Pune
Experience: 4 to 9 Years
Job Type: Full-Time Employment




What You'll Do




As a Python Developer, you will be responsible for designing, developing, and maintaining backend systems and APIs that power our applications.
Develop and maintain backend systems and APIs using Python and Django
Design, build, and optimize scalable and reliable services
Collaborate with frontend developers, designers, and other team members
Work with GitHub for version control and Jenkins for CI/CD pipelines
Deploy and monitor applications in AWS environments
Write clean, well-documented, and testable code
Troubleshoot, debug, and upgrade existing systems
Operate in Linux-based environments for development and deployment




Expertise You'll Bring




We’re looking for a proactive developer who thrives in a collaborative environment and is passionate about clean code and scalable architecture.
Minimum 3 years of professional experience in Python development
Strong knowledge of the Django framework
Familiarity with Jenkins and GitHub
Basic understanding of AWS services (EC2, S3, etc.)
Comfortable working in a Linux/Unix terminal
Knowledge of RESTful APIs and database design (PostgreSQL/MySQL)
Strong problem-solving skills and attention to detail
Good communication and teamwork skills




Benefits:




Competitive salary and benefits package
Culture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications
Opportunity to work with cutting-edge technologies
Employee engagement initiatives such as project parties, flexible work hours, and Long Service awards
Annual health check-ups
Insurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parents




Inclusive Environment:




Persistent Ltd. is dedicated to fostering diversity and inclusion in the workplace. We invite applications from all qualified individuals, including those with disabilities, and regardless of gender or gender preference. We welcome diverse candidates from all backgrounds.




We offer hybrid work options and flexible working hours to accommodate various needs and preferences.
Our office is equipped with accessible facilities, including adjustable workstations, ergonomic chairs, and assistive technologies to support employees with physical disabilities.
If you are a person with disabilities and have specific requirements, please inform us during the application process or at any time during your employment. We are committed to creating an inclusive environment where all employees can thrive.




Our company fosters a values-driven and people-centric work environment that enables our employees to:




Accelerate growth, both professionally and personally
Impact the world in powerful, positive ways, using the latest technologies
Enjoy collaborative innovation, with diversity and work-life wellbeing at the core
Unlock global opportunities to work and learn with the industry’s best




Let’s unleash your full potential at Persistent




“Persistent is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind.”

Show more "
Python Developer,Capgemini,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/python-developer-at-capgemini-4283416622?position=42&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=Ty5M6nrlrnyUZra4Xh%2BtIQ%3D%3D,"Job Description

This role involves the development and application of engineering practice and knowledge in defining, configuring and deploying industrial digital technologies (including but not limited to PLM and MES) for managing continuity of information across the engineering enterprise, including design, industrialization, manufacturing and supply chain, and for managing the manufacturing data.

Job Description - Grade Specific

Focus on Digital Continuity and Manufacturing. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers.
Show more "
Data Scientist,Straive,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-14,https://in.linkedin.com/jobs/view/data-scientist-at-straive-4285612817?position=43&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=hxtv8PVVdF2m83UTF4uNaw%3D%3D,"About the Role

Straive is looking for a talented and driven Consultant / Data Scientist / GenAI Engineer to join our Analytics & GenAI delivery team. In this role, you will work under the guidance of the Senior Project Manager / Engagement Manager to design, develop, and deploy advanced AI/ML and Generative AI solutions for global enterprise clients. You will be part of a high-performing team, collaborating with both onshore and offshore members to build scalable, production-grade AI systems.




This role is ideal for candidates from premier engineering institutes with 2–3 years of relevant experience in Python development, LLM integration, and RAG workflows, along with a passion for solving complex problems in real-world business contexts.




Key Responsibilities

Develop and maintain Python-based applications, AI/ML models, and data processing pipelines for GenAI projects.
Implement Large Language Model (LLM) integrations, including Retrieval-Augmented Generation (RAG) pipelines and embedding-based search solutions.
Build data ingestion and transformation workflows, working with structured and unstructured datasets.
Optimize AI model performance through prompt engineering, fine-tuning, and evaluation techniques.
Collaborate closely with senior team members to translate business requirements into technical solutions.
Integrate AI solutions with vector databases (e.g., Cosmos DB, Pinecone, ChromaDB) and API-driven applications.
(Optional) Contribute to cloud-native deployments and Azure architecture–based solutions, including containerization, CI/CD, and basic MLOps workflows.
Document workflows, maintain code repositories, and follow Agile development practices.




Required Qualifications

2–3 years of relevant experience in AI/ML development, preferably in enterprise projects.
Bachelor’s or Master’s degree in Computer Science, Data Science, AI/ML, or related field from a premier engineering institute.
Proficiency in Python programming and familiarity with relevant libraries (e.g., LangChain, Hugging Face, Pandas, NumPy).
Hands-on experience implementing RAG pipelines, embeddings, and vector search solutions.
Understanding of LLM architectures and integration patterns.
Working knowledge of SQL and data processing best practices.
Basic knowledge of cloud DevOps concepts, preferably with Azure (AWS/GCP experience is also acceptable).

Preferred Skills

Exposure to agentic AI frameworks such as LangGraph, Semantic Kernel, or similar.
Familiarity with ML model lifecycle management and deployment workflows.
Prior experience working with cross-border teams and Agile environments.

Show more "
Data Scientist,Tiger Analytics,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/data-scientist-at-tiger-analytics-4280061745?position=44&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=5b4y1dl8uGDnu11BcgOXDg%3D%3D,"Job Title: Data Scientist

Locations: Chennai | Bangalore | Hyderabad

NP : Immediate Joiner - 15 Days

Skills : Python , Data Science , ML Model building, Regression, Classification




Who we are

Tiger Analytics is a global leader in AI and analytics, helping Fortune 1000 companies solve their toughest challenges. We offer full-stack AI and analytics services & solutions to empower businesses to achieve real outcomes and value at scale. We are on a mission to push the boundaries of what AI and analytics can do to help enterprises navigate uncertainty and move forward decisively. Our purpose is to provide certainty to shape a better tomorrow.

Our team of 4000+ technologists and consultants are based in the US, Canada, the UK, India, Singapore and Australia, working closely with clients across CPG, Retail, Insurance, BFS, Manufacturing, Life Sciences, and Healthcare. Many of our team leaders rank in Top 10 and 40 Under 40 lists, exemplifying our dedication to innovation and excellence.

We are a Great Place to Work-Certified™ (2022-24), recognized by analyst firms such as Forrester, Gartner, HFS, Everest, ISG and others. We have been ranked among the ‘Best’ and ‘Fastest Growing’ analytics firms lists by Inc., Financial Times, Economic Times and Analytics India Magazine




Curious about the role? What your typical day would look like?

As a Data Scientist, your work is a combination of hands-on contribution to Loreum Ipsum, Loreum Ipsum, etc. More specifically, this will involve:

Analytical Translation: Translate complex business problems into sophisticated analytical structures, conceptualising solutions anchored in statistical and machine learning methodologies.
Problem Solving: While technical proficiency in data manipulation, statistical modelling, and machine learning is crucial, the ability to apply these skills to solve real-world business problems is equally vital.
Client Engagement: Establish a deep understanding of clients' business contexts, working closely to unravel intricate challenges and opportunities.
Algorithmic Expertise: Develop and refine algorithms and models, sculpting them into powerful tools to surmount intricate business challenges.
Quantitative Mastery: Conduct in-depth quantitative analyses, navigating vast datasets to extract meaningful insights that drive informed decision-making.
Cross-Functional Collaboration:Collaborate seamlessly with multiple teams, including Consulting and Engineering, fostering relationships with diverse stakeholders to meet deadlines and bring Analytical Solutions to life

What do we expect?

4 -7 years of Relevant Data Science Experience, with demonstrated proficiency and hands-on experience navigating data science complexities.
Good communication skills, both verbal and written.
Exhibit a fervour for crafting modular, scalable, and bug-free Python code.
Comfortable in SQL with additional proficiency in office tools like Excel & PowerPoint.
Experience in production engineering best practices (e.g. Git versioning, Docker).
Familiarity or experience with working on large data sets and distributed computing (e.g. Hive, Hadoop, Spark)
Working knowledge of Cloud platforms (e.g. AWS, Azure, GCP).
Excitement to collaborate with diverse stakeholders across the organisation.
In-depth understanding of various data science approaches, machine learning algorithms, and statistical methods.
Hunger to learn new technologies and embrace the change.
Proficiency in foundational concepts and algorithms in machine learning, encompassing regression and classification techniques, and a keen awareness of their assumptions, strengths, and limitations.
Must-Have Skills: Regression/Classification/Optimization/ Python Proficiency in these key skills is crucial to thriving in this role.




You are important to us, let’s stay connected!

Every individual comes with a different set of skills and qualities so even if you don’t tick all the boxes for the role today, we urge you to apply as there might be a suitable/unique role for you tomorrow. We are an equal opportunity employer. Our diverse and inclusive culture and values guide us to listen, trust, respect, and encourage people to grow the way they desire.




Note: The designation will be commensurate with expertise and experience. Compensation packages are among the best in the industry.

Additional Benefits: Health insurance (self & family), virtual wellness platform, and knowledge communities External Skills And Expertise

Show more "
AI/ML Engineer,IQVIA,"Kochi, Kerala, India",Kochi,2025-08-08,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-iqvia-4281802553?position=45&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=7bZ3EJRdVNEDi9FfT93z4Q%3D%3D,"Job Role: AI/ML Engineer

Experience: 4-7 years

Job Location: Kochi/Bangalore

Work Mode: Hybrid

Must Have Skills: Machine Learning, NLP, Deep Learning, Generative AI, Python




Job Overview:

Develop and implement fit for purpose AIML models, algorithms, foundation models to address pharma/healthcare applications. Transition innovative prototypes into production-grade solutions, including automation engines and client-ready deliverables. Evaluate model viability and scalability to ensure successful deployment. Rapidly translate research concepts into real-world applications at scale. Lead the design, testing, and delivery of solutions from post-prototype stages through to final client implementation.




Essential Functions:




Assists with the ongoing development and implementation of an enterprise architecture, including presenting business cases and strategic release plans to senior leadership.
Collaborates with product development to align IT strategy with business goals, ensuring long-term capability and process improvements within the enterprise framework.
Engages in cross-functional teams, offering technical and system expertise, and may act as a consultant on system design and implementation.
Stays up to date with emerging technologies, identifies opportunities for innovation, and leads or participates in R&D projects using standard project management practices.
Provides guidance and mentorship to junior architects and business analysts, fostering growth and knowledge sharing within the team.




Key Technical Skills:




Strong experience in Natural Language Processing, Machine Learning, and Deep Learning, including transforming natural language into features and applying the right algorithms and tools.
Deep knowledge of Generative AI and Large Language Models, including fine-tuning, deployment strategies, and extending ML frameworks for NLP tasks.
Proven ability to write scalable, maintainable code with experience in unit testing (e.g., Pytest) and understanding of Python’s multi-process architecture and threading limitations.
Skilled in working with REST APIs and frameworks like Flask, FastAPI, and optionally Django or Pyramid.
Familiarity with advanced NLP concepts such as Named Entity Recognition (NER) and Knowledge Graphs.




Educational Qualification: BTech/BE/MTech/ME

Show more "
Software Engineer AI/ML,Arista Networks,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/software-engineer-ai-ml-at-arista-networks-4283056188?position=46&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=ZYMwHlxZQgKeA1FQjqIp7w%3D%3D,"Company Description

Arista Networks is an industry leader in data-driven, client-to-cloud networking for large data center, campus and routing environments. Arista is a well-established and profitable company with over $8 billion in revenue. Arista’s award-winning platforms, ranging in Ethernet speeds up to 800G bits per second, redefine scalability, agility, and resilience. Arista is a founding member of the Ultra Ethernet consortium. We have shipped over 20 million cloud networking ports worldwide with CloudVision and EOS, an advanced network operating system. Arista is committed to open standards, and its products are available worldwide directly and through partners.

At Arista, we value the diversity of thought and perspectives each employee brings. We believe fostering an inclusive environment where individuals from various backgrounds and experiences feel welcome is essential for driving creativity and innovation.

Our commitment to excellence has earned us several prestigious awards, such as the Great Place to Work Survey for Best Engineering Team and Best Company for Diversity, Compensation, and Work-Life Balance. At Arista, we take pride in our track record of success and strive to maintain the highest quality and performance standards in everything we do.

Job Description

Who You’ll Work With

In this role, you’ll collaborate closely with a diverse group of talented professionals, including AI researchers and data scientists who develop and fine-tune machine learning models, software engineers building scalable backend and frontend systems, and product managers who help translate business needs into impactful AI solutions. You’ll also work alongside DevOps and cloud engineers to deploy and maintain services on Google Cloud Platform (particularly Vertex AI), as well as cross-functional teams such as network engineers, IT, and documentation specialists to identify key opportunities for automation and efficiency improvements across Arista.

We're building internal tools to help other Arista teams work more efficiently.

What You’ll Do


Develop and maintain internal conversational AI/chatbot agents for configuration, automation, and information retrieval
Build scalable Retrieval-Augmented Generation (RAG) applications to organize and surface organizational knowledge
Create LLM-integrated solutions to reduce manual effort and enhance decision-making across teams
Design and implement robust, reliable data pipelines from diverse sources including web content, Confluence, Box, GitLab, and more
Collaborate with engineering, IT, product, and documentation teams to identify high-value automation opportunities
Continuously improve internal developer and operational experiences using AI-powered tooling


Qualifications

Must-Have Skills:


Strong programming skills in Python; solid understanding of core computer science concepts and algorithms
Experience with API integrations and building/maintaining production-grade data pipelines
Proficiency with software development best practices: Git, code reviews, testing, CI/CD
Hands-on experience extracting and processing structured/unstructured data from various sources
Excellent problem-solving skills and the ability to independently navigate ambiguous technical challenges.


Nice-to-Haves


Familiarity with machine learning and data science fundamentals
Experience working with LLMs and frameworks like LangChain, LlamaIndex, or similar
Exposure to cloud platforms—especially Google Cloud Platform (GCP) and Vertex AI
Understanding of RAG architectures or vector search (e.g., FAISS, Pinecone)


Additional Information

Arista stands out as an engineering-centric company. Our leadership, including founders and engineering managers, are all engineers who understand sound software engineering principles and the importance of doing things right.

We hire globally into our diverse team. At Arista, engineers have complete ownership of their projects. Our management structure is flat and streamlined, and software engineering is led by those who understand it best. We prioritize the development and utilization of test automation tools.

Our engineers have access to every part of the company, providing opportunities to work across various domains. Arista is headquartered in Santa Clara, California, with development offices in Australia, Canada, India, Ireland, and the US. We consider all our R&D centers equal in stature.

Join us to shape the future of networking and be part of a culture that values invention, quality, respect, and fun.
Show more "
Data Scientist,Recro,"Bengaluru, Karnataka, India",Bengaluru,2025-08-14,https://in.linkedin.com/jobs/view/data-scientist-at-recro-4285474064?position=47&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=NxNoLV6NFDRWfk90jsV1vg%3D%3D,"Job Title: Data Scientist (3-5 Years).

Reporting to: Lead Data Scientist.

Location: Bangalore (India)

Job Role:

 Investigate the feasibility of applying scientific principles and concepts to business

problems.

 Develop new algorithms independently to solve well defined retail problems and

improve existing algorithms.

 Work with product team to implement new modules, maintain and release production

pipelines in timely and responsible manner.

 Develop POCs based on new ideas or technology, popularize new innovations in retail

and analytics with internal/external stakeholders.

 Collaborate with Data Engineering, Advisory and Product team to find scope of

improvement and drive right processes.

Mandatory Skills:

 Retail Experience Business Acumen

 Classic ML Experience – One model built in sole capacity end to end

 Good SQL / Python Hands on experience (PySpark is a plus)

Show more "
Data Scientist,World Wide Technology,India,India,2025-08-12,https://in.linkedin.com/jobs/view/data-scientist-at-world-wide-technology-4252364364?position=48&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=vJQp9MFPcPYR64uX83wh3w%3D%3D,"As a Data Scientist, you will collaborate with a multi-disciplinary team of solution architects and data engineers on a wide range of business problems. You will be an integral part of IT Advanced Analytics group who are a team responsible for building out capabilities across business strategy, analytics, and Cloud.

Data Scientist must be able to:


Execute on all phases of the Data Science project lifecycle with minimal supervision
Interact with business stakeholders to gather requirements and convey project outcomes


Job Responsibilities:


Be equal member of a cohesive and selfless team.
Take complete ownership of your work with the goal of exceeding customer expectations.
Work closely with analysts, developers, and data architects to ensure development meets requirements and delivers optimal performance.
Work closely with internal WWT business, engineering and technology teams
Contribute on all the stages of data science projects: from performing raw data mining to translating complex technical topics into business solutions.
Maintains and enhance a set of critical data models supporting our business use cases.
Maintains complex data pipeline supporting our team’s mission in democratizing data and enabling a data driven
organization, partnering with our data engineering teams.
Effectively communicate actionable insights at all levels of the organization.
Collaborate closely with stakeholders to improve our view of modeling and decision engines.
Solve complex problems using advanced mathematical modeling and optimization techniques, including but not limited to, big data pre-processing, problem formulation, features engineering, algorithmic selection and evaluation, hyperparameter tuning for machine learning, and deployment.
Build and Maintain models for internal customers and business teams, build knowledge and metrics for the product life cycle.
Flexibility to work as a member of a matrix based diverse and geographically distributed project teams.
Enhance the subject matter expertise while working with the various business domains.


,

Required Skills:


2-5 years of experience in data engineering, analytics and data sciences.
Experience in LLM and Gen AI.
Proficiency in Python, R, SQL and experience with ML libraries and frameworks like Scikit-learn, NumPy, etc.
Familiarity with ML Ops tools/platforms
Familiarity with Docker and Kubernetes
Proficiency in one or more visualization tools like Tableau etc.
Experience engineering information out of massive, complex and, in some cases, unstructured datasets.
Ability to apply a strong business sense with technical skills to effectively balance decisions around the complexity and speed of the project delivery.
Strong written, verbal, and interpersonal communication skills. Ability to effectively communicate at all levels in the organization.
Ability to self-start and self-direct work in an unstructured environment, comfortable dealing with ambiguity.
Excellent problem-framing, problem solving and project management skills and ability to change direction quickly.
Ability to balance and prioritize multiple projects.
Experience working within a Cloud based environment, SaaS.
Experience with git and version control workflows.
Proficient in performance tuning and debugging
Show more "
Data Scientist,InCred Financial Services,Mumbai Metropolitan Region,Mumbai Metropolitan Region,2025-08-07,https://in.linkedin.com/jobs/view/data-scientist-at-incred-financial-services-4279468592?position=49&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=u%2BqbB23UW0%2FDuBTi0otDew%3D%3D,"Job Title: Chief Manager/ AVP - Analytics - Personal Loan (Self-Employed Segment)

Department: Analytics

About the Role:

We are looking for a Chief Manager/ AVP - Analytics to join our Personal Loan – Self-Employed segment team. This role involves developing acquisition scorecards and credit risk models using diverse data sources such as credit bureau, banking, GST, and alternate data. The ideal candidate will also be responsible for shaping credit policy, optimizing the customer journey, and ensuring effective risk management through model validation and portfolio monitoring.

Key Responsibilities:

Develop acquisition scorecards - Full-Stack development of ML/Regression Models for Score Cards catering to Personal Loans (PL) for self-employed customers or Unsecured Business Loans (UBL) for MSMEs using multiple data sources.
Analyze and interpret GST data, banking transactions, credit bureau reports, and alternate data to enhance risk assessment.
Design and implement credit policies and customer journeys tailored to the self-employed segment.
Conduct post-implementation validation, monitoring, and performance tracking of risk models.
Perform portfolio analytics to identify trends, mitigate risks, and optimize underwriting strategies.
Collaborate with cross-functional teams including data science, product, and risk management to drive credit decisioning strategies.
Utilize big data tools and advanced analytics techniques to improve credit risk assessment models.

Experience Required:

Overall 5 to 8 years of experience in business / risk analytics in a lending company
Minimum 2 years of experience in developing acquisition scorecards for PL (self-employed customers) or UBL (MSMEs).
Strong understanding of GST data and its application in credit risk analytics.
Experience in portfolio management, risk model validation, and credit decisioning strategies.

Skills & Competencies:

Technical Skills:
Credit Risk Modeling, Data Modeling, and Portfolio Analytics
Python, SQL, Advanced Excel, and Data Visualization
Data Science / Big Data Analytics and exposure to machine learning techniques
Analytical Thinking & Problem-Solving Ability
Strong Oral and Written Communication Skills
Ability to work with large datasets and extract meaningful insights

Qualification:

B.Tech/M.Tech/B.E. in a quantitative field such as Computer Science, Mathematics, Statistics, or Engineering.
Certifications in Data Analytics, Credit Risk, or Machine Learning will be an added advantage.

Why Join Us?

Opportunity to work in a fast-growing credit risk team with a focus on innovation and data-driven decision-making.
Exposure to cutting-edge risk modeling techniques and big data applications.
A collaborative work environment with opportunities for career growth and skill development.

Show more "
Data Scientist,Perfios,Greater Bengaluru Area,Greater Bengaluru Area,2025-08-05,https://in.linkedin.com/jobs/view/data-scientist-at-perfios-4261891638?position=50&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=83BWvL9hedg22d4JbDXgIw%3D%3D,"Primary Function

As a Senior Data Scientist, you will:

Work collaboratively with the engineering and product teams.
Communicate and articulate complex issues & technologies easily to stakeholders at different levels.
Think through problems and drive solutions from inception to shipment.
Keeping abreast of research trends in the field of Deep Learning/vision/NLP.
Looking for someone with hands-on experience in Computer Vision—it's a must have experience for this role.




Qualification & Competency:

Bachelors or above in Data Science, Mathematics, Statistics, Econometrics, Computer Science or a related field.
4-6 years of experience in building complete ML products; from the problem analysis and data selection to their production deployment and monitoring for progressive enhancements and drifts from business impact.
Ability to lead, motivate, and drive team performance effectively.
Theoretical knowledge and hands-on experience in deep learning/computer vision/NLP
Ability to rapidly prototype and evaluate algorithms.
Experience on working with text only and multimodel SLMs will be a big plus. This involves finetuning and building robust eval pipelines specific to use cases.
Experience with deep learning frameworks such as Keras, PyTorch and TensorFlow.
Good programming skills is a must, especially skills relevant to building robust ML models.
Domain experience in Fintech is preferred, but not mandatory.
Experience of publishing in top-tier conferences and journals will be considered a plus.

Show more "
Senior Data Scientist,Nykaa,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-12,https://in.linkedin.com/jobs/view/senior-data-scientist-at-nykaa-4283335386?position=51&pageNum=0&refId=YX4L6jyE0TXXH9PGW686Yw%3D%3D&trackingId=BJmxszoDwYjC9unfG0fuQA%3D%3D,"Company Description

Nykaa is a digitally native, consumer-tech company that offers a wide range of beauty, personal care and fashion products. Since its inception in 2012, Nykaa has disrupted the beauty retail market in India and captured the hearts of millions of customers. Besides offering engaging and educational content, we have diversified our offerings through other online platforms like Nykaa Fashion, Nykaa Man, and Superstore.




Role:

This is a full-time on-site role for a Machine Learning Engineer/Scientist in Bengaluru. As a Machine Learning Engineer/Scientist, you will design and deploy machine learning models to solve complex business problems. You will be responsible for developing and implementing statistical and machine learning algorithms, managing large datasets, and working collaboratively with cross-functional teams. You will be working on the interesting problem areas such as Personalization, Customer Growth, Demand Forecasting & Inventory Management and other DS problems.




Key Skills

Minimum 3 years experience
Strong background in statistics, machine learning and deep learning
Expertise in pattern recognition, neural networks, and ML algorithms
Proficiency in statistical tools, Python programming language along with ML libraries (Scikit-Learning, XGBoost and LightGBM etc)
Exposure to DL frameworks such as Keras, Tensorflow and Pytorch
Have a sound understanding of modeling pipelines, ML architecture and MLOps
Excellent problem-solving skills and attention to detail
Ability to work collaboratively in a fast-paced environment
Experience with Causal Inference and Experimentation would be an advantage
Experience in Consumer tech experience would be a plus
Experience on Search, Ranking, Relevance, Recommendations is highly preferred

Show more "
Junior Software Developer - AI/ML,Siemens,"Bengaluru, Karnataka, India",Bengaluru,2025-08-12,https://in.linkedin.com/jobs/view/junior-software-developer-ai-ml-at-siemens-4283517939?position=1&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=%2BTXWTBmMG2mKfPTpyTGLGQ%3D%3D,"Dear Aspirant!

We empower our people to stay resilient and relevant in a constantly changing world. We’re looking for people who are always searching for creative ways to grow and learn. People who want to make a real impact, now and in the future. Does that sound like you? Then it seems like you’d make a great addition to our vibrant international team.

We are looking for: Graduate Trainee Engineer

You’ll make an impact by:


Design, develop, and optimize NLP-driven AI solutions using state-of-the-art models and
techniques (NER, embeddings, summarization, etc.).
Build and productionize RAG pipelines and agentic workflows to support intelligent, context aware applications.
Fine-tune, prompt-engineer, and deploy LLMs (OpenAI, Anthropic, Falcon, LLaMA, etc.) for domain-specific use cases.
Collaborate with data scientists, backend developers, and cloud architects to build scalable AI first systems.
Evaluate and integrate third-party models/APIs and open-source libraries for generative use cases.
Continuously monitor and improve model performance, latency, and accuracy in production settings.
Implement observability, performance monitoring, and explainability features in deployed models.
Ensure solutions meet enterprise-level requirements for reliability, traceability, and maintainability.


Use your skills to move the world forward!


Master’s or Bachelor’s degree in Computer Science, Machine Learning, AI, or a related field.
Exposure in AI/ML, with knowlegde in NLP and Generative AI.
Strong understanding of LLM architectures, fine-tuning methods (LoRA, PEFT), embeddings, and vector search.
Experience in designing and deploying RAG pipelines and working with multi-step agent
architectures.
Proficiency in Python and frameworks like Lang Chain, Transformers (Hugging Face), Llama Index, Smol Agents, etc.
Familiarity with ML observability and explainability tools (e.g., Tru Era, Arize, Why Labs).
Knowledge of cloud-based ML services like AWS Sagemaker, AWS Bedrock, Azure OpenAI Service, Azure ML Studio, and Azure AI Foundry.
Experience in integrating LLM-based agents in production environments.
Understanding of real-time NLP challenges (streaming, latency optimization, multi-turn dialogues).
Familiarity with Lang Graph, function calling, and tools for orchestration in agent-based systems.
Exposure to infrastructure-as-code (Terraform/CDK) and DevOps for AI pipelines.
Domain knowledge in Electrification, Energy, or Industrial AI is a strong plus..


Create a better #TomorrowWithUs!

This role is based in Bangalore, where you’ll get the chance to work with teams impacting entire cities, countries - and the shape of things to come.

We’re Siemens. A collection of over 312,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we encourage applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination and help us shape tomorrow.

Find out more about Siemens careers at: www.siemens.com/careers

Find out more about the Digital world of Siemens here: www.siemens.com/careers/digitalminds
Show more "
"ML Engineer ( Full Time, Remote)",Hike,India,India,2025-07-07,https://in.linkedin.com/jobs/view/ml-engineer-full-time-remote-at-hike-4262189289?position=2&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=L1pER1DbVuMIb7BKNQieKg%3D%3D,"To know more, check out work.hike.in.

At Hike, we're building the Hike Gaming Nation 🎮 📲 💰

In the fast-paced world of gaming, AI is our edge. As a ML Engineer, you're not just building models — you're powering the intelligence behind the Hike Gaming Nation. Your work turns cutting-edge research into real-time, scalable systems that make gameplay smarter, faster, and more immersive. You don't just build AI—you use it every day. You're an AI-first thinker, leveraging state-of-the-art tools and intelligent systems to move faster, build smarter, and continuously push boundaries.

Introduction 📖



At Hike, we're revolutionizing gaming and tech by blending innovation and immersive experiences. With our foray into Web3 gaming, we're exploring uncharted territories to create products that redefine fun and ownership. Join us as we make waves in this exciting new frontier.

Hike Code 📝( Our core cultural values )

The Hike Code is our value system. We aim to live and breathe by these every single day. They inspire us to be the best we can be and they are weaved into every part of our decision making, how we review performance and much more. We have 9 core values{​{:}

}
Top Talent in Every Role → Both a quest for greatness & shared values are important to us 🦸‍♂
️
Owner not a Renter → Proactive & radically responsible. Everyone is an owner ?
?
Pro-Sports Team → Strength-based, results driven with a ""team-first"" attitude ⚽
️
Customer Obsession → We exist to delight our customers ?
?
Think Deeply & Exercise Good Judgement → Clear mind, obsession to simplify & data-informed 🙇‍♀
️
Build & Make Magic → Courage to walk into the unknown and pioneer new fronts ?
?
Be Insatiably curious & keep Improving → Curiosity to acquire new perspectives, quickly 👨‍?
?
Move Fast & Be Dynamic → Ruthless prioritization & move fast 🙋‍♂
️
Dream Big, Be Bold & Think Long Term → Courage to climb big mountains ?
?

Skills & experience we're looking for 👨‍?

?
1-3  years of relevant industry experience | Top Talent in Every Rol
e
B.tech/MS from a top Tier institute | Top Talent in Every Rol
e
Strong programming abilities, especially Python Scientific & Deep Learning Stack (Numpy, Pandas, Pytorch/Tensorflow, Transformers, Diffusers etc.) | Top Talent in Every Rol
e
Solid foundations in Data-Structures, Algorithms, Design & Architecture | Top Talent in Every Rol
e
Exposure to Deep Learning, preferably building Generative AI applications | Top Talent in Every Rol
e
Experience working with LLMs such as Open AI GPTs, LLaMA & Claude with use cases taken to production. Preferably, experience working with SLMs and Mobile Language Models. | Top Talent in Every Rol
e
Strong AI-first mindset — you actively use AI tools (e.g., GitHub Copilot, GPT, LangChain) to enhance daily workflows, improve velocity, and automate repetitive dev tasks.  | Be Insatiably curious & keep Improvin
g
Ability to work in a fast-paced environment without compromising on quality I Move Fast & Be Dynami
c
Ability to be self-directed and learn quickly, coupled with a strong desire to stay on top of latest developments in the field of AI | Be Insatiably curious & keep Improvin
g
Teamplayer with excellent organizational, communication and interpersonal skills I Pro Sports Tea
m
Excited about building cutting edge AI products in the fields of Computer Vision, Graphics, Audio, AR/VR etc., preferably with experience, in at least one of the areas | Be Insatiably curious & keep Improvin
g

You will ?

?
Strategy → Build deep learning models in the areas of computer-vision, graphics & audi
o
Strategy → Own end to end Quality & Performance Metrics for AI deployment pipelines{​{:}} from learning to inference to renderi
n
g Operations → Create deployment pipelines for server-side as well as on-device real-time inferen
c
e Operations → Optimize ML inference pipelines to render high quality 3D graphics across multiple clients ranging from Android Native to game-engines like Uni
t
y Collaboration → Collaborate in a cross-functional setup including Artists, Engineers & Scientists to translate cutting-edge research (AI, Art & Graphics/Multimedia) into high quality user-experienc
e
s Operation → Leverage AI not just in product development but in your own workflow — from rapid prototyping with LLMs to automating test generation, documentation, and internal tooli
n

g 💰 Benefits → We have tremendous benefits & perks. Check out work.hike.in to know mo



re
Show more "
Machine Learning Engineer,Adobe,"Bengaluru East, Karnataka, India",Bengaluru East,2025-07-30,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-adobe-4272843897?position=3&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=VjxWHDWzFNakUTsKg0zV%2Bw%3D%3D,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

The Opportunity

Join our Experience Intelligence team as a Generative AI and LLM Specialist, where you'll contribute to building a brand new ad intelligence platform. In this role, you will develop innovative AI models focused on ad creative intelligence, using your expertise in LLMs and VLMs, including fine-tuning and Retrieval-Augmented Generation (RAG). This position is ideal for professionals passionate about working on the full lifecycle of generative AI-enabled platform capabilities, from conceptualization and experimentation to implementation and execution, ensuring a robust and scalable system.

What you'll Do


Build and Innovate: Design, fine-tune and deploy generative AI models with an eye on generalisation for customer use cases in a multi-tenant environment. Have an Ability to deeply understand product requirements and gaps and design solutions that meet those needs.
Quality Assurance: Conduct detailed testing of AI-generated content to ensure alignment with quality standards and suitability for the intended audience. Identify patterns of errors or biases and work to mitigate these issues.
Standout Colleague: Work effectively with all collaborators to understand product and engineering needs thoroughly.
Eager Learner: Keep abreast of the latest AI/ML trends, tools, and standard methodologies to apply new knowledge for improving project outcomes.
Ethics First: Champion ethical AI development, from bias mitigation to privacy protection.


What you need to succeed

Relevant Degree or equivalent experience: Bachelor’s or advanced degree in Computer Science, AI, ML, or related fields

Practical Experience: 2-4 yrs total experience in ML /Deep Learning with at least 2 years experience in Generative AI (Fine-tuning LLM, RAG, Agentic AI etc.)

Programming Proficiency: Proven Python skills and AI/ML tools (e.g., TensorFlow, PyTorch).

Tech-Savvy Foundations: Exposure to software engineering practices.

Problem Solver: Demonstrated ability to tackle challenges with innovative solutions.

Communicator: Strong skills in articulating ideas and collaborating with various teams.

Research Attitude: A curiosity driven approach to exploring new applications of generative AI is valued.

Emerging Leader: Show potential for technical leadership and project guidance.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Show more "
Machine Learning Engineer,Tata Technologies,"Pune, Maharashtra, India",Pune,2025-08-05,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-tata-technologies-4280134590?position=4&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=gS0OUvSLpN1CqMatiJrsog%3D%3D,"Location -Pune

Experience - 3 to 6 Years

Qualification - Graduate (B.E/B Tech)




JD .

Lead the architecture, design, and development of components and services to enable Machine Learning at scale
Build data sets from multiple data sources and write data flows using Python and R, SQL/Spark
Exposure to Streaming/Event based architecture
Implementing analytic models on Big data infrastructure
Stay up-to-date on ML, Big Data technologies sharing learnings with the teams
Build reusable code and libraries for future use and optimize application for maximum speed and scalability
Integration of user-facing elements developed by front-end developers with server-side logic
Implementation of security and data protection measures
Exposure in at least one cloud platform on related data services (AWS / Azure / GCP)

Skills – (highlighted are mandatory skill)

Python, R,
SQL,
Spark,
Hadoop, Big data tool,
NodeJS,
Javascript




Job Responsibility:

Apache Spark experience a major plus (Spark RDDs, Spark DataFrames, Spark SQL)
Leverage Spark ecosystem knowledge to design, and develop capabilities to deliver solutions using Scala, Python, Kafka and other things in the Spark ecosystem
Expert in Python, R, NodeJS framework
Good understanding in front-end technologies, such as angular, JavaScript, HTML5, and CSS3
Should design the solution Approach and Come out with optimized effort estimates.
Defining the technical specifications for the implementation of the frontend and backend solution
Should be able to create extensible APIs and scalable python modules

Show more "
Machine Learning Engineer,Infosys,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-09,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-infosys-4281898086?position=5&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=mt3%2F%2B4VG1Aaigejc0Sekrg%3D%3D,"Preferred Qualifications:


Experienced in Agile way of working, manage team effort and track through JIRA
High Impact client communication
Domain experience in Retail, CPG and Logistics
Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face. Roles & Responsibilities:
Understand the requirements from the business and translate it into an appropriate technical requirement.
Responsible for successful delivery of MLOps solutions and services in client consulting environments;
Define key business problems to be solved; formulate high level solution approaches and identify data to solve those problems, develop, analyze/draw conclusions and present to client.
Assist clients with operationalization metrics to track performance of ML Models
Help team with ML Pipelines from creation to execution
Guide team to debug on issues with pipeline failures
Understand and take requirements on Operationalization of ML Models from Data Scientist
Engage with Business / Stakeholders with status update on progress of development and issue fix
Setup Standards related to Coding, Pipelines and Documentation
Research on new topics, services and enhancements in Cloud Technologies EEO/About Us : About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.
Show more "
Machine Learning Engineer,Adobe,"Noida, Uttar Pradesh, India",Noida,2025-07-30,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-adobe-4272845837?position=6&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=Nn54SQ7hXCcVCJ5gHk1y0g%3D%3D,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Excited by AI/ML? Interested in crafting new innovative solutions using Machine Learning?

The Document Cloud team, in Noida, is crafting PDF solutions spanning all surfaces - Web, Mobile, Desktop and Platform APIs, that processes billions of PDFs every month using ML, Deep-Learning and Generative AI at its core.

As a part of this, we need expert individuals focusing on research and development of methods for processing huge amount of content, and can build mashups of Vision, Image Processing, NLP, generative models to solve sophisticated problems.

What you get to do in this role:


Develop algorithms that apply deep learning and innovative methods in NLP & computer vision, combined with traditional large sophisticated solutions/codebases!
Developing innovative solutions using Generative AI, Python, Machine Learning and Data Science!
Build experiments, algorithms and ship solution that not only yield high accuracy but are also crafted and engineered to scale.
Collaborate across multiple research and engineering teams, making the tradeoffs required to rapidly deliver AI/ML software solutions.


In order to be successful, we need someone who has:


B.Tech in Computer Science. MS/PhD preferred.
3+ years hands-on experience in either deep-learning models, Image processing, Vision and/or NLP.
Ability to write efficient, clean, and reusable code in Python. Knowledge of C++.
Broad Machine Learning experience – Data, Modelling, Metric, Analysis of Results.
Experience in prompt-engineering and working with advanced-RAG systems.
Exposure to Deep Learning - CNNs, LSTMs, Transformers, network architecture, network tuning, transfer learning, multi-task learning. Hands-on coding in pyTorch or Tensorflow.
Exposure in building solutions from scratch and writing maintainable code inside large existing codebases.
Strong software development skills that encourage code reuse among engineers and researchers.


Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Show more "
Python AI/ML Developer,Coforge,"Noida, Uttar Pradesh, India",Noida,2025-07-18,https://in.linkedin.com/jobs/view/python-ai-ml-developer-at-coforge-4267494470?position=7&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=RWs6%2FpidRE3taHFRAW8bHw%3D%3D,"Skills: Python, AI/ML

Experience- 3-5 Years

Location- Greater Noida




Job Description




Around 3 years experience working as an NLP Engineer or similar role.
Understanding of NLP techniques for text representation, semantic extraction techniques, data structures and modelling.
Ability to effectively design software architecture.
Deep understanding of text representation techniques (such as n-grams, bag of words, sentiment analysis etc), statistics and classification algorithms.
Expertise in Python.
Expertise in data structures/algorithms.
Experience with Machine Learning Libraries (like scikit-learn, pytorch and tensorflow).
An analytical mind with problem-solving abilities.

Show more "
Python Backend Engineer – ML,CloudSEK,"Bengaluru, Karnataka, India",Bengaluru,2025-07-11,https://in.linkedin.com/jobs/view/python-backend-engineer-%E2%80%93-ml-at-cloudsek-4265142270?position=8&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=6Xn%2FGFBaCMBV8lHdv7CR3w%3D%3D,"WHO ARE WE?

We are a bunch of super enthusiastic, passionate, and highly driven people, working to achieve a common goal! We believe that work and the workplace should be joyful and always buzzing with energy!

CloudSEK, one of India’s most trusted Cyber security product companies, is on a mission to build the world’s fastest and most reliable AI technology that identifies and resolves digital threats in real-time. The central proposition is leveraging Artificial Intelligence and Machine Learning to create a quick and reliable analysis and alert system that provides rapid detection across multiple internet sources, precise threat analysis, and prompt resolution with minimal human intervention.

Founded in 2015, headquartered at Singapore, we are proud to say that we’ve grown at a frenetic pace and have been able to achieve some accolades along the way, including:

CloudSEK’s Product Suite:


CloudSEK XVigil constantly maps a customer’s digital assets, identifies threats and enriches them with cyber intelligence, and then provides workflows to manage and remediate all identified threats including takedown support.
A powerful Attack Surface Monitoring tool that gives visibility and intelligence on customers’ attack surfaces. CloudSEK's BeVigil uses a combination of Mobile, Web, Network and Encryption Scanners to map and protect known and unknown assets.
CloudSEK’s Contextual AI SVigil identifies software supply chain risks by monitoring Software, Cloud Services, and third-party dependencies.


Key Milestones:


2016: Launched our first product.
2018: Secured Pre-series A funding.
2019: Expanded operations to India, Southeast Asia, and the Americas.
2020: Won the NASSCOM-DSCI Excellence Award for Security Product Company of the Year.
2021: Raised $7M in Series A funding led by MassMutual Ventures.
Awards & Recognition: Won NetApp Excellerator's ""Best Growth Strategy Award,"" CloudSEK XVigil joined NVIDIA Inception Program, and won the NASSCOM Emerge 50 Cybersecurity Award.
2025: Secured $19 million in funding led by Tenacity Ventures, Commvault.


Roles and Responsibilities:


Writing clean, efficient, and well-documented Python code
Develop back-end components to improve overall performance and system robustness.
Maintaining and updating existing systems
Collaborating with team members to identify, design, and implement new features
Participating in code reviews to ensure code quality and consistency


Required Skills:


Great programming skills with expertise in Python
Skills to build highly scalable and efficient backend services
Good knowledge of SQL and experience in working with relational databases.
Experience in working with NoSQL database programs such as MongoDB.
Hands-on experience in at least one Python web framework such as FastAPI or Flask.
Working knowledge of a message queuing system like RabbitMQ/ SQS? Kafka
Experience with Docker


Good to Have:


Experience working with kubernetes
Experience with AWS cloud services.
Hands on skills in Applied-ML


Benefits of Joining CloudSEK

We provide an environment where you can develop and enhance your skills while delivering meaningful work that matters. You’ll be rewarded a competitive salary as well as a full spectrum of generous perks and incentives which include:


Flexible working hours.
Food, unlimited snacks and drinks are all available while at office.


And, the finest part is yet to come! Every now and then we ensure to unwind and have a good time together, which involves games, fun, and soulful music. Feel free to show off your artistic side here!
Show more "
Data scientist- Python- AI/ML GEN AI- Across india,Capgemini Engineering,"Mumbai, Maharashtra, India",Mumbai,2025-08-04,https://in.linkedin.com/jobs/view/data-scientist-python-ai-ml-gen-ai-across-india-at-capgemini-engineering-4277353126?position=9&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=f4c0cPxt7UYJqMu4DjNY6Q%3D%3D,"• Develop strategies/solutions to solve problems in logical yet creative ways, leveraging state-of-the-art machine learning, deep learning and GEN AI techniques.

• Technically lead a team of data scientists to produce project deliverables on time and with high quality.

• Identify and address client needs in different domains, by analyzing large and complex data sets, processing, cleansing, and verifying the integrity of data, and performing exploratory data analysis (EDA) using state-of-the-art methods.

• Select features, build and optimize classifiers/regressors, etc. using machine learning and deep learning techniques.

• Enhance data collection procedures to include information that is relevant for building analytical systems, and ensure data quality and accuracy.

• Perform ad-hoc analysis and present results in a clear manner to both technical and non-technical stakeholders.

• Create custom reports and presentations with strong data visualization and storytelling skills to effectively communicate analytical conclusions to senior officials in a company and other stakeholders.

• Expertise in data mining, EDA, feature selection, model building, and optimization using machine learning and deep learning techniques.

• Strong programming skills in Python.

• Excellent communication and interpersonal skills, with the ability to present complex analytical concepts to both technical and non-technical stakeholders.







Primary Skills :

- Excellent understanding and hand-on experience of data-science and machine learning techniques & algorithms for supervised & unsupervised problems, NLP and computer vision and GEN AI. Good applied statistics skills, such as distributions, statistical inference & testing, etc.

- Excellent understanding and hand-on experience on building Deep-learning models for text & image analytics (such as ANNs, CNNs, LSTM, Transfer Learning, Encoder and decoder, etc).

- Proficient in coding in common data science language & tools such as R, Python.

- Experience with common data science toolkits, such as NumPy, Pandas, Matplotlib, StatsModel, Scikitlearn, SciPy, NLTK, Spacy, OpenCV etc.

- Experience with common data science frameworks such as Tensorflow, Keras, PyTorch, XGBoost,etc.

- Exposure or knowledge in cloud (Azure/AWS).

- Experience on deployment of model in production.

Show more "
AI/ML Engineer,TaskUs,"Chennai, Tamil Nadu, India",Chennai,2025-08-14,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-taskus-4256963112?position=10&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=vPQBlsNqaQ1b6NSjw7mJyg%3D%3D,"Job Description

About TaskUs: TaskUs is a provider of outsourced digital services and next-generation customer experience to fast-growing technology companies, helping its clients represent, protect and grow their brands. Leveraging a cloud-based infrastructure, TaskUs serves clients in the fastest-growing sectors, including social media, e-commerce, gaming, streaming media, food delivery, ride-sharing, HiTech, FinTech, and HealthTech.

The People First culture at TaskUs has enabled the company to expand its workforce to approximately 45,000 employees globally. Presently, we have a presence in twenty-three locations across twelve countries, which include the Philippines, India, and the United States.

It started with one ridiculously good idea to create a different breed of Business Processing Outsourcing (BPO)! We at TaskUs understand that achieving growth for our partners requires a culture of constant motion, exploring new technologies, being ready to handle any challenge at a moment's notice, and mastering consistency in an ever-changing world.

What We Offer: At TaskUs, we prioritize our employees' well-being by offering competitive industry salaries and comprehensive benefits packages. Our commitment to a People First culture is reflected in the various departments we have established, including Total Rewards, Wellness, HR, and Diversity. We take pride in our inclusive environment and positive impact on the community. Moreover, we actively encourage internal mobility and professional growth at all stages of an employee's career within TaskUs. Join our team today and experience firsthand our dedication to supporting People First.

Developer, AI/ML Engineer

About TaskUs: TaskUs is a provider of outsourced digital services and next-generation customer experience to fast-growing technology companies, helping its clients represent, protect and grow their brands. Leveraging a cloud-based infrastructure, TaskUs serves clients in the fastest-growing sectors, including social media, e-commerce, gaming, streaming media, food delivery, ride-sharing, HiTech, FinTech, and HealthTech.

TaskUs People First culture has grown the company to have approximately 45K employees worldwide. We are currently in twenty-three locations across twelve countries, including the Philippines, India, and the United States.

It started with one ridiculously good idea to create a different breed of Business Processing Outsourcing (BPO)! We at TaskUs understand that achieving growth for our partners requires a culture of constant motion, exploring new technologies, being ready to handle any challenge at a moment's notice, and mastering consistency in an ever-changing world.

What We Offer: TaskUs provides world-class benefit packages with competitive industry salaries to all its employees. With well-developed departments, such as Total Rewards, Wellness, HR, and Diversity, we continuously thrive in supporting a People First culture. We are known for our inclusiveness and community impact. We also promote internal mobility and professional development at every step of an employee's career within TaskUs. Come be part of TaskUs that supports People First by applying today!

What can you expect in a Developer, AI/ML Engineer role with TaskUs:

We are looking for an Artificial Intelligence and Machine Learning Engineer with 2 to 3 years of experience with python technology, who will be responsible for leveraging AI, NLP, NLU, LLM, and Generative AI technologies to create innovative products. The ideal candidate should have a strong background in machine learning and artificial intelligence with hands-on experience in building scalable and reliable AI-based products .

Key Responsibilities


Design and develop machine learning models to solve complex business problems using AI,NLP, NLU, LLM, and Generative AI technologies
Develop and implement algorithms for data processing, feature extraction, and model training
Collaborate with cross-functional teams to identify business requirements and create solutions that meet those requirements
Identify and evaluate new AI technologies and tools that can improve the performance and efficiency of our products
Manage and mentor a team of AI and Machine Learning Engineers
Ensure that the products are delivered on time, meet quality standards, and are scalable
Communicate technical solutions and results to non-technical stakeholders


Required Qualifications


Bachelor's or Master's degree in Computer Science, Information Technology or related fields 2 to 4 years of experience in machine learning and artificial intelligence
Hands-on experience in building and deploying AI-based products using NLP, NLU, LLM, and Generative AI technologies
Strong hands on experience in Object Oriented Programming System, Python, FastAPI, Generative AI Prompting.
Experience in containerisation(docker), Jenkins.
Experience in leading and managing a team of AI and Machine Learning Engineers
Experience in AWS AI Services would be added advantage
Excellent problem-solving skills with the ability to think creatively and critically
Strong communication and presentation skills with the ability to communicate technical solutions to non-technical stakeholders
Experience in Agile development methodologies and project management
If you are passionate about leveraging AI technologies to create innovative products and have a strong background in machine learning and artificial intelligence, we encourage you to apply for this exciting opportunity.


How We Partner To Protect You: TaskUs will neither solicit money from you during your application process nor require any form of payment in order to proceed with your application. Kindly ensure that you are always in communication with only authorized recruiters of TaskUs.

DEI: In TaskUs we believe that innovation and higher performance are brought by people from all walks of life. We welcome applicants of different backgrounds, demographics, and circumstances. Inclusive and equitable practices are our responsibility as a business. TaskUs is committed to providing equal access to opportunities. If you need reasonable accommodations in any part of the hiring process, please let us know.

We invite you to explore all TaskUs career opportunities and apply through the provided URL https://www.taskus.com/careers/ .

TaskUs is proud to be an equal opportunity workplace and is an affirmative action employer. We celebrate and support diversity; we are committed to creating an inclusive environment for all employees. TaskUs people first culture thrives on it for the benefit of our employees, our clients, our services, and our community.

Req Id: R_2506_8227

Posted At: Wed Jun 25 2025 00:00:00 GMT+0000 (Coordinated Universal Time)
Show more "
AI Software Engineer,DHL,"Indore, Madhya Pradesh, India",Indore,2025-07-28,https://in.linkedin.com/jobs/view/ai-software-engineer-at-dhl-4273033936?position=11&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=ANpkrZxA6BFD62rUTcayvQ%3D%3D,"Your IT Future, Delivered.

AI Software Engineer (Python, GenAI)

With a global team of 5600+ IT professionals, DHL IT Services connects people and keeps the global economy running by continuously innovating and creating sustainable digital solutions. We work beyond global borders and push boundaries across all dimensions of logistics. You can leave your mark shaping the technology backbone of the biggest logistics company of the world. All our offices have earned #GreatPlaceToWork certification, reflecting our commitment to exceptional employee experiences.

Digitalization. Simply delivered.

At IT Services, we are passionate about technology. Our team is continuously expanding. No matter your level of Architecture proficiency, you can always grow within our diverse environment.

#DHL #DHLITServices #GreatPlace

Grow together.

The role of an AI Engineer is the pathfinder for the Engineering team. AI Engineers need to be able to understand the challenges on the ground and find solution to improve efficiency in delivering solutions for faster time to market. AI Engineer is proficient in leveraging available AI tools in applying real world use cases for better productivity.

Ready to embark on the journey? Here’s what we are looking for:

As an AI Engineer, having Python experience, Prompt Engineering and Generative AI models, and AI use cases application is required. Also, knowledge of AI workflow tools such as LangChain and n8n will be a huge plus to help our company improve our business and IT processes with better efficiency, breaking down tasks to use the right learning models, while grounding results via “context engineering” using RAG and MCP protocols to ensure only relevant and good quality results are produced.

Aside from that, you should be able to work independently prioritize and organize your tasks under time and workload pressure. Working in a multinational environment, you can expect cross-region collaboration with teams around the globe, thus being advanced in spoken and written English will be certainly useful.

An array of benefits for you:



Hybrid work arrangements to balance in-office collaboration and home flexibility.
Annual Leave: 42 days off apart from Public / National Holidays.
Medical Insurance: Self + Spouse + 2 children. An option to opt for Voluntary Parental Insurance (Parents / Parent -in-laws) at a nominal premium covering pre existing disease.
In House training programs: professional and technical training certifications.



The role of a Software Engineer is a combination of project delivery and support. Software Engineers are an important part of an agile team, they need to understand and implement the requirements by business. As part of a DevOps Team, they solve incidents based on tickets, take care of a proper monitoring of the system and implement CR’s after the Go Live of a product. On top of it they bring improvement ideas in the discussions to increase quality and develop the product further.

Ready to embark on the journey? Here’s what we are looking for:

As a Software Engineer, having Python experience, Prompt Engineering and Generative AI models, use cases knowledge is a huge plus. Very good knowledge of Software Development Methodologies and DevSecOps process and tools and Java & Node.js programming language will also be an integral part of this role.

You are a GenAI aficionado, therefore you have a good understanding of version control systems (e.g., Git) and project management tools, analytical and soft skills. You are able to work independently prioritize and organize your tasks under time and workload pressure. Working in a multinational environment, you can expect cross-region collaboration with teams around the globe, thus being advanced in spoken and written English will be certainly useful.

An array of benefits for you:



Hybrid work arrangements to balance in-office collaboration and home flexibility.
Annual Leave: 42 days off apart from Public / National Holidays.
Medical Insurance: Self + Spouse + 2 children. An option to opt for Voluntary Parental Insurance (Parents / Parent -in-laws) at a nominal premium covering pre existing disease.
In House training programs: professional and technical training certifications.
Show more "
ML Software Engineer,eBay,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/ml-software-engineer-at-ebay-4264435923?position=12&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=cBRTmYWVemP%2Br%2BPdV9%2FEjA%3D%3D,"At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

About The Team And Role

The Compliance Engineering team at eBay is focused on prohibited, restricted, and counterfeit compliance detection is dedicated to ensuring that eBay’s marketplace adheres to all relevant regulations and internal policies.

The team develops and maintain advanced, AI-driven tools and scalable backend systems that automatically identify and assess items listed on the platform. By applying sophisticated data models, machine learning algorithms, and rules-based engines, they detect products that may be illegal, harmful, non-compliant with trade regulations, or counterfeit.

Overall, this Compliance Engineering team plays a crucial role in maintaining trust in eBay’s platform, safeguarding customers, and upholding the company’s dedication to a fair, safe, and legally compliant marketplace.

What You Will Accomplish


Build large-scale applications, low-latency APIs, data pipelines, and foundational architectures to support eBay’s business operations and customer experiences.
Design and implement highly configurable, metadata-driven platforms to enable seamless ingestion of attributes, rules, models, policies, and derived aggregates.
Develop machine learning models and Gen AI tools to generate insights and improve customer experiences across eBay.
Partner with architects, business leaders, and industry experts to devise strategies and scalable solutions.
Be responsible for the entire software lifecycle, including design, development, testing, and experimentation.
Mentor and lead junior team members by setting examples and guiding them toward success.



What You Will Bring


Prefer Technical degree with 3-5+ years of relevant software development experience.
Strong hands on Machine Leaning experience, AI/ML/Gen AI, LLM's and proven experience in building and running AI/ML/GenAI models in production environments.
Outstanding programming skills in Java, Scala, and Python, with hands-on experience in frameworks like PyTorch and TensorFlow.
Proven experience with APIs and Distributed Systems, building and consuming horizontally scalable RESTful APIs, GraphQL, and distributed systems.
Hands-on experience with technologies like Spark, Flink, and Kafka with practical experience in their use.
Strong understanding of SQL, NoSQL, and sophisticated data modeling techniques.
Hands-on experience with the Hadoop ecosystem (HDFS, MapReduce, Hive, Spark) for building and optimizing large-scale data solutions.



Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.
Show more "
AI/ML Software Engineer,eBay,"Bengaluru, Karnataka, India",Bengaluru,2025-08-06,https://in.linkedin.com/jobs/view/ai-ml-software-engineer-at-ebay-4265461193?position=13&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=JBUgHyvo5R6%2F6%2BoM1RTYWQ%3D%3D,"At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

About The Team And Role

The Compliance Engineering team at eBay is focused on prohibited, restricted, and counterfeit compliance detection is dedicated to ensuring that eBay’s marketplace adheres to all relevant regulations and internal policies.

The team develops and maintain advanced, AI-driven tools and scalable backend systems that automatically identify and assess items listed on the platform. By applying sophisticated data models, machine learning algorithms, and rules-based engines, they detect products that may be illegal, harmful, non-compliant with trade regulations, or counterfeit.

Overall, this Compliance Engineering team plays a crucial role in maintaining trust in eBay’s platform, safeguarding customers, and upholding the company’s dedication to a fair, safe, and legally compliant marketplace.

What You Will Accomplish


Build large-scale applications, low-latency APIs, data pipelines, and foundational architectures to support eBay’s business operations and customer experiences.
Design and implement highly configurable, metadata-driven platforms to enable seamless ingestion of attributes, rules, models, policies, and derived aggregates.
Develop machine learning models and Gen AI tools to generate insights and improve customer experiences across eBay.
Partner with architects, business leaders, and industry experts to devise strategies and scalable solutions.
Be responsible for the entire software lifecycle, including design, development, testing, and experimentation.
Mentor and lead junior team members by setting examples and guiding them toward success.



What You Will Bring


Prefer Technical degree with 3-5+ years of relevant software development experience.
Strong hands on Machine Leaning experience, AI/ML/Gen AI, LLM's and proven experience in building and running AI/ML/GenAI models in production environments.
Outstanding programming skills in Java, Scala, and Python, with hands-on experience in frameworks like PyTorch and TensorFlow.
Proven experience with APIs and Distributed Systems, building and consuming horizontally scalable RESTful APIs, GraphQL, and distributed systems.
Hands-on experience with technologies like Spark, Flink, and Kafka with practical experience in their use.
Strong understanding of SQL, NoSQL, and sophisticated data modeling techniques.
Hands-on experience with the Hadoop ecosystem (HDFS, MapReduce, Hive, Spark) for building and optimizing large-scale data solutions.



Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.
Show more "
Data Scientist Engineer - IN,OPPO,"Gurugram, Haryana, India",Gurugram,2025-07-25,https://in.linkedin.com/jobs/view/data-scientist-engineer-in-at-oppo-4272010609?position=14&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=z6keE2sunElmkt6n6c%2FQaw%3D%3D,"Responsible：

1. Responsible for enterprise-level data warehouse construction and big data task performance optimisation, responsible for data asset quality optimisation, asset governance and other work；

2. Responsible for the development of big data technology components or platform tools, technical difficulties, responsible for deployment, management and maintenance work.




Requirements：

1. Bachelor‘s degree or above in computer science, mathematics or related fields, with solid basic knowledge of computer systems;

2. Have a solid programming foundation, proficiency in C/C++/JAVA/Python at least one mainstream programming language;

3. Familiar with Hadoop/Kafka/starrocks/Flink and other one or more big data technologies and components.

4. Good learning ability and communication skills, as well as teamwork spirit




More Information：

1.Relocate to China for one year, and later be based in India.

2.Chinese communication skills are preferred but not mandatory.

3.1–3 years of work experience, with skills in SQL development or Java development; strong initiative and fast learner.

Show more "
AI/ML Engineer – XR Software (All levels)),Qualcomm,"Bengaluru, Karnataka, India",Bengaluru,2025-07-31,https://in.linkedin.com/jobs/view/ai-ml-engineer-%E2%80%93-xr-software-all-levels-at-qualcomm-4273838318?position=15&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=9%2FywiWWGgiVjWUw1KvIosA%3D%3D,"Company

Qualcomm India Private Limited

Job Area

Engineering Group, Engineering Group > Systems Engineering

General Summary

We are seeking a passionate and skilled AI/ML Engineer to join our cutting-edge Extended Reality (XR) Software team. In this role, you will work on next-generation XR products that blend the physical and digital worlds, leveraging artificial intelligence and machine learning to create immersive, intelligent, and responsive experiences.

You will collaborate with cross-functional teams of researchers, engineers, and designers to build real-time AI/ML software optimized for XR platforms. A strong background in C++ or embedded firmware development is essential, as you will be working close to hardware and performance-critical systems.

Key Responsibilities


Design, develop, and optimize AI/ML models for XR applications such as computer vision, sensor fusion, gesture recognition, and spatial understanding.
Implement real-time inference pipelines on embedded or edge devices.
Collaborate with firmware and hardware teams to integrate ML models into XR systems.
Analyze system performance and optimize for latency, power, and memory.
Stay up to date with the latest research and trends in AI/ML and XR technologies.
Contribute to the full lifecycle of product development—from prototyping to production.



Required Qualifications


Bachelor’s or Master’s degree in Computer Science, Electrical Engineering, or a related field.
1–10 years of industry experience in AI/ML engineering or embedded systems.
Proficiency in C++ and/or embedded firmware development.
Solid understanding of machine learning fundamentals and experience with frameworks like TensorFlow, PyTorch, or ONNX.
Experience with deploying ML models on edge devices
Familiarity with XR technologies (AR/VR/MR), sensor data processing, or 3D spatial computing.



Minimum Qualifications


Bachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.



OR

Master's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.

OR

PhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.

Applicants: Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries).

Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.

To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.

If you would like more information about this role, please contact Qualcomm Careers.
Show more "
Machine Learning Engineer,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-ab-inbev-gcc-india-4279258468?position=16&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=zp3N32AYmtNhayYZT2xObQ%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Description

Job Title: Junior Data Scientist

Location: Bangalore

Reporting to: Senior Manager – Analytics




1. Purpose of the role

The Global GenAI Team at Anheuser-Busch InBev (AB InBev) is tasked with constructing competitive solutions utilizing GenAI techniques. These solutions aim to extract contextual insights and meaningful information from our enterprise data assets. The derived data-driven insights play a pivotal role in empowering our business users to make well-informed decisions regarding their respective products. In the role of a Machine Learning Engineer (MLE), you will operate at the intersection of:




LLM-based frameworks, tools, and technologies
Cloud-native technologies and solutions
Microservices-based software architecture and design patterns As an additional responsibility, you will be involved in the complete development cycle of new product features, encompassing tasks such as the development and deployment of new models integrated into production systems. Furthermore, you will have the opportunity to critically assess and influence the product engineering, design, architecture, and technology stack across multiple products, extending beyond your immediate focus.




2. Key tasks & accountabilities

Large Language Models (LLM):

Experience with LangChain, LangGraph
Proficiency in building agentic patterns like ReAct, ReWoo, LLMCompiler

Multi-modal Retrieval-Augmented Generation (RAG):

Expertise in multi-modal AI systems (text, images, audio, video)
Designing and optimizing chunking strategies and clustering for large data processing

Streaming & Real-time Processing:

Experience in audio/video streaming and real-time data pipelines
Low-latency inference and deployment architectures

NL2SQL:

Natural language-driven SQL generation for databases
Experience with natural language interfaces to databases and query optimization

API Development:

Building scalable APIs with FastAPI for AI model serving

Containerization & Orchestration:

Proficient with Docker for containerized AI services
Experience with orchestration tools for deploying and managing services

Data Processing & Pipelines:

Experience with chunking strategies for efficient document processing
Building data pipelines to handle large-scale data for AI model training and inference

AI Frameworks & Tools:

Experience with AI/ML frameworks like TensorFlow, PyTorch
Proficiency in LangChain, LangGraph, and other LLM-related technologies

Prompt Engineering:

Expertise in advanced prompting techniques like Chain of Thought (CoT) prompting, LLM Judge, and self-reflection prompting
Experience with prompt compression and optimization using tools like LLMLingua, AdaFlow, TextGrad, and DSPy
Strong understanding of context window management and optimizing prompts for performance and efficiency




3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

Bachelor's or masterʼs degree in Computer Science, Engineering, or a related field.

Previous work experience required

Proven experience of 3+ years in developing and deploying applications utilizing Azure OpenAI and Redis as a vector database.

Technical skills required

Solid understanding of language model technologies, including LangChain, OpenAI Python SDK, LammaIndex, OLamma, etc.
Proficiency in implementing and optimizing machine learning models for natural language processing.
Experience with observability tools such as mlflow, langsmith, langfuse, weight and bias, etc.
Strong programming skills in languages such as Python and proficiency in relevant frameworks.
Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes).




And above all of this, an undying love for beer!

We dream big to create future with more cheer

Show more "
Python AI/ML Developer,Emorphis Technologies,"Indore, Madhya Pradesh, India",Indore,2025-02-21,https://in.linkedin.com/jobs/view/python-ai-ml-developer-at-emorphis-technologies-4161560349?position=17&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=DnwDInKttCqZEfPvlLSbhQ%3D%3D,"Implement proof of concepts in Engineering Systems and other innovation field topics where ML / AI technologies can be applied. Realize ML / AI product features.
You will be involved in coding of features, POCs and/or bug-fixing and delivering solutions adhering to coding and quality guidelines.
You will be responsible for Implementation of features and/or bug-fixing and delivering solutions in accordance with coding guidelines and on-time with high quality.
You will be responsible for Identification and implementation of unit and integration tests to ensure solution addresses customer requirements, and quality, security requirements of product are met.
You will be responsible for Ensuring integration and submission of solution into software configuration management system, within committed delivery timelines.
Experience on Large Language Models (LLMs) such as BERT and LLAMA.
Language Model Development: Utilize off-the-shelf LLM services, like Azure OpenAI, for integrating LLM capabilities into applications, and develop new language models.
Model Training and Evaluation: Train and fine-tune language models using appropriate machine-learning frameworks and tools.


Education


B.E. / B. Tech / MCA/ M. Tech (Computer Science).


Experience


3 years of experience in the following
Strong programming ability in both scripting and object-oriented programming languages is required (Python)
Strong working knowledge in Deep learning and ML Algorithms.
Strong working knowledge in TensorFlow, Sci-kit Learn, KERAS, Caffe, Pandas, NumPy, PyTorch, Matplotlib
Knowledge in Natural Language Processing (NLP) & Deep Learning is required.
Software Design & Development - OOPS/OOAD methodologies.


Locations: Madhya Pradesh, Indore, India
Show more "
AI/ML Developer - Python,Jade Global,"Pune, Maharashtra, India",Pune,2024-08-05,https://in.linkedin.com/jobs/view/ai-ml-developer-python-at-jade-global-3993515723?position=18&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=7EgqiLJc34r8XzFiqDINzA%3D%3D,"AI/ML Developer - Python1

Position Title : AI/ML Developer - Python

No of position : 1

Location : Pune / Hyderabad

Job Description


Design machine learning systems
Research and implement machine learning algorithms and tools
Manage and direct research and development processes to meet the needs of our AI strategy
Develop machine learning applications in alignment with project requirements and business goals
Perform machine learning tests and statistical analysis in order to fine-tune the machine learning systems
Select appropriate datasets and data representation methods
Extend existing machine learning libraries and frameworks
Train systems and retrain as necessary
Work with the engineering and leadership teams on the functional design, process design, prototyping, testing, and training of AI/ML solutions
Advise leaders on technology, strategy, and policy issues related to AI/ML
Coordinating with development teams to determine application requirements.
Writing scalable code using Python programming language.
Testing and debugging applications.
Developing back-end components.
Integrating user-facing elements using server-side logic.
Assessing and prioritizing client feature requests.
Integrating data storage solutions.
Coordinating with front-end developers.
Reprogramming existing databases to improve functionality.
Developing digital tools to monitor online traffic.
Work with the Data Scientists and Data Engineers to create production quality.
Machine Learning pipelines and solutions with an emphasis on Performance, Scalability, Reliability, and Maintainability.
Build components and libraries that will improve existing solutions and improve the delivery of new ones


Required Skills And Experience


3+ years of experience applying AI to practical uses
Experience with deep learning, NLP, and TensorFlow
Experience writing robust code in Python, Java, and/or R
Experience in REST API development, NoSQL database design, and RDBMS design and optimizations
Knowledge of basic algorithms and object-oriented and functional design principles
Knowledge of data structures, data modeling, and software architecture
Knowledge of math, probability, statistics, and algorithms
Knowledge of machine learning frameworks
Knowledge of machine learning libraries such as scikit-learn
Excellent communication skills
Strong analytical and problem solving skills


Preferred Qualifications


Bachelor's degree in a relevant technology field
Experience with cloud environments
Show more "
Interesting Job Opportunity: Volody - Python Developer - Machine Learning/Artificial Intelligence,Volody,Mumbai Metropolitan Region,Mumbai Metropolitan Region,2024-11-20,https://in.linkedin.com/jobs/view/interesting-job-opportunity-volody-python-developer-machine-learning-artificial-intelligence-at-volody-4080607264?position=19&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=vBZrCYk210UnAlmwqsnKpw%3D%3D,"Volody is leading software product company catering to demand of US market providing them Contract Lifecycle Management Software. Our software help corporates to digitize and automate legal contract management process and significantly reduce cost and time.


We are looking for Computer Science graduate with special skills on Artificial Intelligence and Machine Learning as we are adding many new features to products to make it much smarter with new features, capabilities.
The whole objective to give best experience to customers and enable lot of manual jobs completed through AI and ML.
The candidate should be Computer Science graduate from a reputed university and has prior experience of working on global software products enabling Artificial Intelligence and Machine Learning features.
Prior experience of interacting with customers, business user group and marketing team is added advantage.
Candidate should be very focussed tech geek and eat, sleep and breath only technology and more specifically AI and ML.


Though as a company we have already built in couple of features, however, with ongoing need for integration of lot of intelligence to software we are looking for a good expert in the field.

Suitable Candidate should have advance knowledge of Python, R Programming, Tableau & Natural Language Processing

(ref:hirist.tech)
Show more "
AI Engineer [T500-19607],McDonald's,"Hyderabad, Telangana, India",Hyderabad,2025-08-07,https://in.linkedin.com/jobs/view/ai-engineer-t500-19607-at-mcdonald-s-4281607390?position=20&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=kEdon3ynoHKwJq4S5GTA2Q%3D%3D,"About McDonald’s:

One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.




Company Description:

McDonald’s is on a mission to build a data- and AI-powered organization that scales innovation and accelerates the Arches. The AI Hub, part of the Enterprise Data, Analytics, and AI (EDAA) team, is central to that mission—designing, deploying, and scaling AI-driven products that improve guest experiences, restaurant operations, and business decision-making. The Opportunity We’re seeking a Manager, AI/ML Engineering focused on the development, refinement, and deployment of AI models and algorithms that power enterprise AI initiatives. With an emphasis on aligning technical solutions with business strategy, this position plays a pivotal role in delivering scalable AI products across domains. The role collaborates with cross-functional teams to design machine learning models, optimize performance, and guide delivery from prototype to production. The role contributes directly to evolving AI architectures and drives innovation in enterprise AI solutions.




Key Responsibilities:

Design and build scalable end-to-end AI Systems, focusing on backend development Design, develop, and refine advanced AI models and algorithms, especially generative AI approaches. Includes writing code on AI product component modules, or prototypes, typically in python, but also leveraging database technologies including vector, relational, NOSQL, messaging queues, front end interfaces, etc. Will make heavy use of various GenAI platform API’s.
Lead the execution of AI model lifecycle activities from development to deployment, including training, validation, and tuning
Ensure alignment with enterprise AI architecture and evolving AI strategy
Collaborate with data scientists, LLMOps / MLOps engineers, product managers, and business stakeholders to translate use cases into deployable AI solutions
Contribute to the development of scalable AI pipelines and model deployment workflows across cloud or hybrid infrastructure
Monitor model performance in production and implement updates or retraining processes to ensure continued relevance and accuracy
Apply best practices for reproducibility, version control, documentation, and ethical AI considerations
Mentor junior AI engineers and foster continuous learning and knowledge sharing within AI teams
Stay current with advances in AI/ML research and tools, translating new capabilities into practical enterprise use
Coach and mentor junior AI engineers and support cross-functional teams in AI product delivery
Support enterprise AI governance and model risk management processes




Qualifications Required:

Bachelor’s degree in computer science, Data Science, or a related field; master’s or PhD preferred
5+ years of experience in AI/ML model development or AI System engineering (backend or full stack)
Strong expertise in some variety of programming languages, with an emphasis on Python. Advanced proficiency with some AI/ML frameworks (e.g., Lang Chain, TensorFlow, PyTorch)
Deep understanding of machine learning algorithms, statistical modeling, data structures and distributed systems
Experience working with cloud AI platforms and services (e.g., AWS SageMaker, Google AI Platform, Azure ML)
Familiarity with MLops including model versioning, reproducibility, and monitoring
Ability to clearly communicate technical concepts to both technical and non-technical stakeholders
Strong collaboration skills with cross-functional teams in fast-paced environments
Demonstrated ability to contribute to innovation and continuous improvement in AI practices




Our Commitment to Values:

Serve: Customers and people first.
Inclusion: Everyone is welcome.
Integrity: We do what’s right.
Community: We give back.
Family: We support each other




Work location: Hyderabad, India

Work pattern: Full time role.

Work mode: Hybrid.

Show more "
Associate Data Scientist,Circle K,"Gurugram, Haryana, India",Gurugram,2025-08-02,https://in.linkedin.com/jobs/view/associate-data-scientist-at-circle-k-4278114996?position=21&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=%2FzNfmUt%2F78j9wKPL2Zz9%2Fg%3D%3D,"Job Description

Alimentation Couche-Tard Inc., (ACT) is a global Fortune 200 company. A leader in the convenience store and fuel space, it has footprint across 31 countries and territories. The India Data & Analytics Global Capability Centre is an integral part of ACT’s Global Data & Analytics Team and the Associate Data Scientist will be a key player on this team that will help grow analytics globally at ACT.

About The Role

The hired candidate will partner with multiple departments, including Global Marketing, Merchandising, Global Technology, and Business Units. The incumbent will be responsible for delivering advanced analytics projects that drive business results including interpreting business, selecting the appropriate methodology, data cleaning, exploratory data analysis, model building, and creation of polished deliverables.

Responsibilities


Analyze large-scale structured and unstructured data; develop deep-dive analyses and machine learning models in retail, marketing, merchandising, and other areas of the business
Utilize data mining, statistical and machine learning techniques to derive business value from store, product, operations, financial, and customer transactional data
Apply multiple algorithms or architectures and recommend the best model with in-depth description to evangelize data-driven business decisions
Utilize cloud setup to extract processed data for statistical modelling and big data analysis, and visualization tools to represent large sets of time series/cross-sectional data
Structure hypothesis, build thoughtful analyses, develop underlying data models, and bring clarity to previously undefined problems
Partner with Data Engineering to build, design and maintain core data infrastructure, pipelines, and data workflows to automate dashboards and analyses
Articulate complex data science models to business teams and present the insights in easily understandable and innovative formats


Qualifications And Experience


Bachelor’s degree required, preferably with a quantitative focus (Statistics, Business Analytics, Data Science, Math, Economics, etc.)
Master’s degree preferred (MBA/MS Computer Science/M.Tech Computer Science, etc.)
1–2 years of relevant working experience in a data science/advanced analytics role
Knowledge of Functional Analytics (Supply chain analytics, Marketing Analytics, Customer Analytics)
Knowledge and ability to conduct statistical modelling using Analytical tools (R, Python, KNIME, etc.) and use big data technologies
Knowledge of business intelligence & reporting (Power BI, Tableau, Alteryx, etc.)
Knowledge of Enterprise reporting systems, relational (MySQL, Microsoft SQL Server etc.), non-relational database management systems and Data Engineering tools
Knowledge and ability to use Big data technologies (Hadoop, Spark, Kafka, Presto etc) and Cloud computing services in Azure/AWS/GCP for data engineering, ML Ops
Ability to delivery, strong disposition towards business and strong interpersonal communication
Individual must be organized, dependable, able to multi-task and manage priorities, display initiative, and must have the ability to work independently in a demanding, fast-paced environment.


Show more "
Data Scientist,Unilever,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/data-scientist-at-unilever-4282325097?position=22&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=QbwhITisMmcGfBSaXV3nBA%3D%3D,"JOB TITLE: Data Scientist

JOB FUNCTION: R&D

SCOPE: Global

WORK LOCATION: Unilever Research India – R&D Bangalore, Whitefield

About Unilever

With 3.4 billion people in over 190 countries using our products every day, Unilever is a business that makes a real impact on the world. Work on brands that are loved and improve the lives of our consumers and the communities around us. We are driven by our purpose: to make sustainable living commonplace, and it is our belief that doing business the right way drives superior performance. At the heart of what we do is our people – we believe that when our people work with purpose, we will create a better business and a better world.

At Unilever, your career will be a unique journey, grounded in our inclusive, collaborative, and flexible working environment. We don’t believe in the ‘one size fits all’ approach and instead we will equip you with the tools you need to shape your own future.

Category Or Function Introduction

HomeCare is a global business with leading household cleaning and laundry brands such as OMO, Sunlight and Comfort. Our aim is to offer products that are unmissably superior, sustainable and great value.

We are organised to deliver growth and margin across three core categories: Fabric Cleaning, Fabric Enhancer, and Home & Hygiene. We have a portfolio of strong global brands, and a global geographical footprint.

Our strength is in emerging markets where we lead the industry through market development.

Within R&D, our team of world-leading scientists, researchers and professionals creates innovations that drive growth for our business and deliver positive impacts for people, society and our planet.

For more than 100 years, we have been using our differentiated science and technology to create the superior products and experiences our consumers love.

Job Purpose

Unilever is the place where you can bring your purpose to life with the work that you do – creating a better business and a better world. If you are passionate about leveraging data analytics power to drive consumer insights and developing modelling capabilities to empower our scientists for innovating superior products, then this role is just for you!

What Will Your Main Responsibilities Be


Analyse complex data sets using a diverse set of machine learning techniques. Build UI solutions to deploy these solutions for the end users.
Develop data analysis and visualization solutions to generate faster insights, thereby helping business team to make informed decision.
Execute data modeling projects working together with project SMEs; manage stakeholder expectations.
Support and manage activities and expectation on data capture and data quality. Ensure data quality compliance with R&D Data Governance standards
Translate business needs into technical specifications, especially for R&D lab and experimental data.


What You Need To Succeed

Experiences & Qualifications


Bachelor’s or master’s degree in STEM subject (Science, Technology, Engineering, or Maths, Computer science, Data Science, Statistics.)
Minimum 2-4 years of working experience in the field of Data science. Experience in data processing / handling, insight building and digital solutions.
Should have working experience in the field of Power BI and/ Python dash.
Having knowledge of experimental data capture systems like LIMS will is plus.
Having python/dash/flask application development skills is plus.


Skills


Expert knowledge in Excel, Power BI. Experience in large data management.
Good to moderate knowledge of scripting and standard modeling practices of developing ML models using Python.
Good to moderate knowledge in interface designing with an ability to understand user’s requirements and develop a mock-up UI wireframe.
Working experience with modelling software such as JMP and DOE are an added advantage.


Leadership


Strong interpersonal and communication skills, both written and oral.
A good team player with ability to work successfully across multiple business units and formats, effectively collaborate with global teams across time-zone.
Energize by delivering fantastic results and be an example to others – with both results and resilience.
Responsible for own wellbeing and delivering high standards of work. Must focus on the Consumer and what they need.


Our commitment to Equality, Diversity & Inclusion

Unilever embraces diversity and encourages applicants from all walks of life! This means giving full and fair consideration to all applicants and continuing development of all employees regardless of age, disability, gender reassignment, race, religion or belief, sex, sexual orientation, marriage and civil partnership, and pregnancy and maternity.

""All official offers from Unilever are issued only via our Applicant Tracking System (ATS). Offers from individuals or unofficial sources may be fraudulent—please verify before proceeding.""
Show more "
Machine Learning Engineer,Impetus,"Pune, Maharashtra, India",Pune,2025-07-20,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-impetus-4241752294?position=23&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=afyicWxWJ1EN3V7JYp4a0Q%3D%3D,"Job Summary:

We are looking for highly motivated and analytical Machine Learning Engineers with 1–3 years of experience in building scalable, production-ready AI/ML models. This role involves working on complex business problems using advanced ML/DL techniques across domains such as Natural Language Processing (NLP), Computer Vision, Time Series Forecasting, and Generative AI.

You will be responsible for end-to-end model development, deployment, and performance tracking while collaborating with cross-functional teams including data engineering, DevOps, and product.




Location: Noida / Gurugram / Indore / Bengaluru / Pune / Hyderabad

Experience: 1–3 Years

Education: BE / B.Tech / M.Tech / MCA / M.Com




Key Responsibilities:

Model Development & Experimentation

Design and build machine learning models for NLP, computer vision, and time series prediction using supervised, unsupervised, and deep learning techniques.
Conduct experiments to improve model performance via architectural modifications, hyperparameter tuning, and feature selection.
Apply statistical analysis to validate and interpret model results.
Evaluate models using appropriate metrics (e.g., accuracy, precision, recall, F1-score, AUC-ROC).

Data Handling & Feature Engineering

Process large structured and unstructured datasets using Python, Pandas, and DataFrame APIs.
Perform feature extraction, transformation, and selection tailored to specific ML problems.
Implement data augmentation and enrichment techniques to enhance training quality.

Model Deployment & Productionization

Deploy trained models to production environments using cloud platforms such as AWS (especially SageMaker).
Containerize models using Docker and orchestrate deployments with Kubernetes.
Implement monitoring, logging, and automated retraining pipelines for model health tracking.

Collaboration & Innovation

Collaborate with data engineers and architects to ensure smooth data flow and infrastructure alignment.
Explore and adopt cutting-edge AI/ML methodologies and GenAI frameworks (e.g., LangChain, GPT-3).
Contribute to documentation, versioning, and knowledge-sharing across teams.
Drive innovation and continuous improvement in AI/ML delivery and engineering practices.

Mandatory Technical Skills:

Languages & Tools: Python (Pandas, NumPy, Scikit-learn, TensorFlow/PyTorch)
Model Development: Deep Learning, NLP, Time Series, Computer Vision
Cloud Platforms: AWS (especially SageMaker)
Model Deployment: Docker, Kubernetes, REST APIs
ML Ops: Model monitoring, performance logging, CI/CD
Frameworks: LangChain (for GenAI), Transformers, Hugging Face

Preferred / Good to Have:

Experience with Foundation Model tuning and prompt engineering
Hands-on with Generative AI (GPT-3/4, OpenAI APIs, LangChain integrations)
Certifications: AWS Certified Machine Learning – Specialty
Experience with version control (Git), and experiment tracking tools (MLflow, Weights & Biases)

Soft Skills:

Excellent communication and presentation abilities
Strong analytical and problem-solving mindset
Ability to work in collaborative, fast-paced environments
Curiosity to learn emerging technologies and apply them to real-world problems

Show more "
Machine Learning Engineer,eBay,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-ebay-4264478744?position=24&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=dLcySTdvwxAow5FbB8RWUg%3D%3D,"At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

Machine Learning Engineer

Level: T24

People Manager: No

Location: India

Team: BX Recs

Hiring Manager: rishaagarwal@ebay.com

Recruiter: TBD

Date: Jul 3, 2025

Job Description

Looking for a company that inspires passion, courage and creativity, where you can be on the team shaping the future of global commerce? Want to shape how millions of people buy, sell, connect, and share around the world? If you’re interested in joining a purpose driven community that is dedicated to crafting an ambitious and inclusive work environment, join eBay – a company you can be proud to be with.

Our Recommendations team works on delivering recommendations at scale and in near real time to our buyers on our website and native app platforms. Recommendations are a core part of how our buyers navigate eBay’s vast and varied inventory. Our team develops state-of-the-art recommendations systems, including deep learning based retrieval systems for personalized recommendations, machine learned ranking models, GenAI/LLM powered recommendations, as well as advanced MLOps in a high volume traffic industrial e-commerce setting.

We are building cutting edge recommender systems powered by the latest ML, NLP, LLM/GenAI/RAG and AI technologies. Additionally, we are building production integrations with Google GCP Vertex AI platforms to supercharge our item recommendation algorithms. Come join our innovative engineering and applied research team!

This Is An Opportunity To


Influence how people will interact with eBay’s recommender systems in the future, and how recommender systems technology will evolve
Work with unique and large data sets of unstructured multimodal data representing eBay's vast and varied inventory, including billions of items and millions of users
Develop and deploy state-of-the-art AI models to production which have direct measurable impact on eBay buyers
Deploy big data technology and large scale data pipelines
Drive marketplace GMB as well as advertising revenue via organic and sponsored recommendations



Qualifications


MS in Computer Science or related area with 1+ years of relevant work experience (or BS/BA with 3+ years) in Engineering / Machine Learning / AI
Experience building large scale distributed applications and expertise in an OO/functional language (Scala, Java, etc.)
Experience building with no sql databases and key value stores (MongoDB, Redis, etc)
Generalist with a can do attitude and willingness to learn/pick up new skill sets as needed
Experience with using cloud services is a plus (GCP is a double plus)
Experience with big data pipelines (Hadoop, Spark, Flink) is a plus
Experience in AI applied research and industrial recommendation systems is a plus
Experience with Large Language Models (LLMs) and prompt engineering is a plus



Links To Some Of Our Previous Work


Tech Blog 2025 (Multimodal GenAI)
Tech Blog 2025 (GenAI Agentic Platform)
RecSys 2024 Workshop paper
Google Cloud Blog 2024
eBay Tech Blog 2023
eBay Tech Blog 2022
RecSys 2021 paper



Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.
Show more "
Data Scientist,Danone,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/data-scientist-at-danone-4282126896?position=25&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=%2Bmwsa43UmZscoatAnT4low%3D%3D,"About Danone Group:




Mission: ‘Bringing Health through Food to as Many people as Possible’

Danone is a global leader in food and beverages, focusing on Essential Dairy and Plant-based products, Waters, and Specialized Nutrition. Our mission is to bring health through food to as many people as possible by creating nutritious products, promoting healthy eating habits, and operating sustainably.




With nearly 90,000 employees and products available in over 120 markets, Danone generated €27.6 billion in sales in 2023. Our Renew Danone strategy aims to foster long-term value through innovation and community support.




Danone is committed to making a positive impact economically, socially, and environmentally. In 2020, we became the first listed company to adopt the ‘Société à Mission’ status, reflecting our vision for a sustainable future.




More information can be found at www.danone.com.




About Danone India:

Danone operates in India as Nutricia International Pvt. Ltd, focusing on nutrition with a range of products catering to infants, toddlers, pregnant mothers, as well as adults. The company features well-known brands such as Aptamil, Dexolac, and Protinex. Danone employs over 1,000 individuals across India and generates a turnover exceeding €150 million. The company's head office is located in Mumbai, with a manufacturing facility situated in Lalru, Punjab.




Danone India is a Great Place To Work® certified organization, which reflects our commitment to creating a workplace where people are empowered to contribute meaningfully, grow professionally, and feel a true sense of belonging.




More information can be found at https://www.danone.in/




Job Summary:

Work on the project of transformation of Demand Planning at global level in the roadmap of the digitalization for the Supply Chain. Creating and developing the ML models for all Danone categories\




Roles & Responsibilities:




Be part of the design and development of the ML core models and the analytics behind them
Understand and capture cross country needs
Be able to build the common approach of ML scalable models for the demand planning teams of different countries
Support with all the analytics needs for the adoption of the ML models
Build outstanding best in class ML models for Demand Planning that are able to cope with more complex and less steady environments
Set up KPI's to track ML and Statistical models performance
Select and understand the best approach of automatization for the overall Demand process driven by Statistical and Machine Learning capabilities
Ensures collaboration of all teams in order to guarantee scalability of the models
Keeps a close control of the ML developments to ensure cost compliance
Responsible of the Continuous Improvement of the ML models and create the strategy of ML vs Statistical approach
Responsible for the region's continuous improvement of ML and Statistical models in order to improve business performance
Create standard ways of measure and manage strategies to find and fix root causes in forecast bias/accuracy
Develop capabilities and skills on Machine Learning understanding across the regions
Build, maintain, fine tune and audit Statistical & ML models to guarantee adaptability to new business context providing service for all regions
Assist regions in processes and tools to embrace Statistical and ML technology
Shield key processes and know-how on Statistical and ML
Ensures standardization between different countries
Guarantee highest ML utilization




Job Specifications:

Education: Mathematics/Physics/Engineering with a master’s in business/data analytics or proven track record on Data Science
Proven track record of minimum 5 years as a data scientist
Great analytical skills
Coding capabilities in R and/or Phyton
Relationship/ Network builder
Change management
Project management
Experience with Continuous Improvement




Main Interfaces

Cross country demand planning teams
IS/IT project managers and developers
Supply chain cross functions

Show more "
Data Scientist,Circle K,"Gurugram, Haryana, India",Gurugram,2025-08-02,https://in.linkedin.com/jobs/view/data-scientist-at-circle-k-4278120180?position=26&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=BsfuuTQH%2By4gxqvTPyN0nw%3D%3D,"Job Description

Circle K (Part of Alimentation Couche-Tard Inc., (ACT)) is a global Fortune 200 company. A leader in the convenience store and fuel space, it has a footprint across 31 countries and territories. Circle K India Data & Analytics team is an integral part of ACT’s Global Data & Analytics Team, and the Data Scientist will be a key player on this team that will help grow analytics globally at ACT. This is a unique opportunity to be a part of an experienced team of data scientists and analysts within a large organization.

The Data Scientist is responsible for delivering advanced analytics and insights that drive business results and operational excellence to our dynamic and forward-thinking Merchandise team in Europe. The ideal candidate should possess both technical capabilities as well as commercial savviness, should be able to drive independent analysis as well as work effectively in a group.

About The Role

We are looking for an individual who is a proven problem solver with exceptional critical thinking ability. The candidate should have a high sense of curiosity and be comfortable with ambiguity when faced with a difficult challenge. Additionally, the candidate should possess excellent communication skills, the ability to collaborate with others, and simply and effectively communicate complex concepts with a non-technical audience.

Roles & Responsibilities

Analytics (Data & Insights)


Evaluate performance of categories and activities, using proven and advanced analytical methods
Support stakeholders with actionable insights based on transactional, financial or customer data on an ongoing basis
Oversee the design and measurement of experiments and pilots
Initiate and conduct advanced analytics projects such as clustering, forecasting, causal impact
Build highly impactful and intuitive dashboards that bring the underlying data to life through insights


Operational Excellence


Improve data quality by using and improving tools to automatically detect issues
Develop analytical solutions or dashboards using user-centric design techniques in alignment with ACT’s protocol
Study industry/organization benchmarks and design/develop analytical solutions to monitor or improve business performance across retail, marketing, and other business areas


Stakeholder Management


Work with Peers, Functional Consultants, Data Engineers, and cross-functional teams to lead / support the complete lifecycle of analytical applications, from development of mock-ups and storyboards to complete production ready application
Provide regular updates to stakeholders to simplify and clarify complex concepts, and communicate the output of work to business
Create compelling documentation or artefacts that connects business to the solutions
Coordinate internally to share key learning with other teams and lead to accelerated business performance
Be an advocate for a data-driven culture among the stakeholders


Job Requirements

Education


A higher degree in an analytical discipline like Finance, Mathematics, Statistics, Engineering, or similar


Relevant Experience


Experience: 3-4 years for Data Scientist
Relevant working experience in a quantitative/ applied analytics role
Experience with programming, and the ability to quickly pick up handling large data volumes with modern data processing tools, e.g. by using Spark / SQL / Python
Excellent communication skills in English, both verbal and written


Behavioural Skills


Delivery Excellence
Business disposition
Social intelligence
Innovation and agility


Knowledge


Functional Analytics (Retail Analytics, Supply Chain Analytics, Marketing Analytics, Customer Analytics, etc.)
Working understanding of Statistical modelling & Time Series Analysis using Analytical tools (Python, PySpark, R, etc.)
Knowledge of statistics and experimental design (A/B testing, hypothesis testing, causal inference)
Practical experience building scalable ML models, feature engineering, model evaluation metrics, and statistical inference
Enterprise reporting systems, relational (MySQL, Microsoft SQL Server etc.), database management systems
Business intelligence & reporting (Power BI)
Cloud computing services in Azure/ AWS/ GCP for analytics


Show more "
Data Scientist,KPMG,"Bengaluru, Karnataka, India",Bengaluru,2025-07-17,https://in.linkedin.com/jobs/view/data-scientist-at-kpmg-4268200771?position=27&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=HIpnwZsxsJFtj3BBt5qXmg%3D%3D,"DATA SCIENCE + GEN AI

Major Duties & Responsibilities

• Work with business stakeholders and cross-functional SMEs to deeply understand business context and key business

questions

• Create Proof of concepts (POCs) / Minimum Viable Products (MVPs), then guide them through to production deployment

and operationalization of projects

• Influence machine learning strategy for Digital programs and projects

• Make solution recommendations that appropriately balance speed to market and analytical soundness

• Explore design options to assess efficiency and impact, develop approaches to improve robustness and rigor

• Develop analytical / modelling solutions using a variety of commercial and open-source tools (e.g., Python, R,

TensorFlow)

• Formulate model-based solutions by combining machine learning algorithms with other techniques such as simulations.

• Design, adapt, and visualize solutions based on evolving requirements and communicate them through presentations,

scenarios, and stories.

• Create algorithms to extract information from large, multiparametric data sets.

• Deploy algorithms to production to identify actionable insights from large databases.

• Compare results from various methodologies and recommend optimal techniques.

• Design, adapt, and visualize solutions based on evolving requirements and communicate them through presentations,

scenarios, and stories.

• Develop and embed automated processes for predictive model validation, deployment, and implementation

• Work on multiple pillars of AI including cognitive engineering, conversational bots, and data science

• Ensure that solutions exhibit high levels of performance, security, scalability, maintainability, repeatability, appropriate

reusability, and reliability upon deployment

• Lead discussions at peer review and use interpersonal skills to positively influence decision making

• Provide thought leadership and subject matter expertise in machine learning techniques, tools, and concepts; make

impactful contributions to internal discussions on emerging practices

• Facilitate cross-geography sharing of new ideas, learnings, and best-practices

Required Qualifications

• Bachelor of Science or Bachelor of Engineering at a minimum.

• 4+ years of work experience as a Data Scientist

• A combination of business focus, strong analytical and problem-solving skills, and programming knowledge to be able to

quickly cycle hypothesis through the discovery phase of a project

• Advanced skills with statistical/programming software (e.g., R, Python) and data querying languages (e.g., SQL,

Hadoop/Hive, Scala)

• Good hands-on skills in both feature engineering and hyperparameter optimization

• Experience producing high-quality code, tests, documentation

• Experience with Microsoft Azure or AWS data management tools such as Azure Data factory, data lake, Azure ML,

Synapse, Databricks

• Understanding of descriptive and exploratory statistics, predictive modelling, evaluation metrics, decision trees, machine

learning algorithms, optimization & forecasting techniques, and / or deep learning methodologies

• Proficiency in statistical concepts and ML algorithms

• Good knowledge of Agile principles and process

• Ability to lead, manage, build, and deliver customer business results through data scientists or professional services team

• Ability to share ideas in a compelling manner, to clearly summarize and communicate data analysis assumptions and

results

• Self-motivated and a proactive problem solver who can work independently and in teams




Must to Have : Agent Framework, RAG Framework, Chunking Strategies, LLMs, AI on cloud

Services, Open Source Frameworks like Langchain, Llama Index, Vector Database, Token

Management, Knowledge Graph, Vision APIs, Prompt Engineering




Good to have : AI Algorithms, Deep Learning,Computer Vision, Hallucination Control

Mechanism, Responsible AI frameworks




Tech : Python, SQL, Docker, Versioning tool, Azure/AWS/GCP

Show more "
AI Engineer,Fusemachines,"Pune, Maharashtra, India",Pune,2025-08-08,https://in.linkedin.com/jobs/view/ai-engineer-at-fusemachines-4282134885?position=28&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=yiK9JYrwf3sfkVzBnq0xew%3D%3D,"About Fusemachines

Fusemachines is a 10+ year old AI company, dedicated to delivering state-of-the-art AI products and solutions to a diverse range of industries. Founded by Sameer Maskey, Ph.D., an Adjunct Associate Professor at Columbia University, our company is on a steadfast mission to democratize AI and harness the power of global AI talent from underserved communities. With a robust presence in four countries and a dedicated team of over 400 full-time employees, we are committed to fostering AI transformation journeys for businesses worldwide. At Fusemachines, we not only bridge the gap between AI advancement and its global impact but also strive to deliver the most advanced technology solutions to the world.

Location: Remote (Full-time)

Role Overview:

We are seeking a highly skilled and motivated MLOps Engineer with a strong background in computer vision. In this role, you will be responsible for the full lifecycle of our machine learning models, from development and optimization to deployment and scaling. You will build and maintain the infrastructure that allows our cutting-edge computer vision algorithms to run reliably and efficiently in production. The ideal candidate will have a deep understanding of both MLOps principles and 3D computer vision, with hands-on experience in containerization, model optimization, and scalable systems.

Key Responsibilities:


Design, build, and maintain robust, scalable, and automated MLOps pipelines for model training, evaluation, and deployment (CI/CD for ML)
Containerize machine learning applications using Docker for scalable and reproducible deployments
Deploy and manage ML models at scale
Optimize deep learning models for inference performance, including techniques like quantization, pruning, and distillation
Work with and extend state-of-the-art AI models for tasks such as:
Depth estimation and 6D object pose estimation
Image and video segmentation
Dense point tracking and feature matching
Develop and maintain monitoring systems to track model performance, detect data drift, and ensure the reliability of production systems
Collaborate with AI researchers and software engineers to transition models from research to production
Manage and optimize pipelines for processing large-scale 3D data, including point clouds, LiDAR, and stereoscopic imagery
Apply a strong mathematical understanding of spatial transformations, rigid body rotations, and coordinate frame alignment to ensure algorithmic integrity in production


Required Qualifications:


Bachelor's in Computer Science, Engineering, or a related field
Proven experience in an MLOps, DevOps, or similar role with a focus on machine learning
Strong programming skills in Python and/or C++
A portfolio of projects or publications in the field of computer vision or MLOps
Hands-on experience with model optimization techniques (quantization, etc.) and frameworks (e.g., TensorRT, ONNX Runtime)
Hands-on experience with containerization technologies
Experience with CI/CD tools (e.g., Jenkins, GitLab CI, CircleCI) and version control (Git)
Solid understanding of general computer vision and 3D computer vision principles
Experience with deep learning frameworks such as PyTorch or TensorFlow
A strong mathematical foundation in spatial transformations, rigid body rotations, coordinate frame alignment, and triangulation


Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by applicable federal, state, or local laws.

Powered by JazzHR

CKEyAqRgGj
Show more "
Software Engineer (AI/ML),HID,Greater Chennai Area,Greater Chennai Area,2025-07-21,https://in.linkedin.com/jobs/view/software-engineer-ai-ml-at-hid-4270619737?position=29&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=zQ5tf276SixA5uykdzBnyw%3D%3D,"Job ID: 39582




Position Summary

A rewarding career at HID Global beckons you! We are looking for an AI/ML Engineer , who is responsible for designing, developing, and deploying advanced AI/ML solutions to solve complex business challenges. This role requires expertise in machine learning, deep learning, MLOps, and AI model optimization, with a focus on building scalable, high-performance AI systems. As an AI/ML Engineer, you will work closely with data engineers, software developers, and business stakeholders to integrate AI-driven insights into real-world applications. You will be responsible for model development, system architecture, cloud deployment, and ensuring responsible AI adoption. We are a leading company in the trusted source for innovative HID Global Human Resources products, solutions and services that help millions of customers around the globe create, manage and use secure identities.







Roles & Responsibilities:

Design, develop, and deploy robust & scalable AI/ML models in Production environments.
Collaborate with business stakeholders to identify AI/ML opportunities and define measurable success metrics.
Design and build Retrieval-Augmented Generation (RAG) pipelines integrating vector stores, semantic search, and document parsing for domain-specific knowledge retrieval.
Integrate Multimodal Conversational AI platforms (MCP) including voice, vision, and text to deliver rich user interactions.
Drive innovation through PoCs, benchmarking, and experiments with emerging models and architectures.
Optimize models for performance, latency and scalability.
Build data pipelines and workflows to support model training and evaluation.
Conduct research & experimentation on the state-of-the-art techniques (DL, NLP, Time series, CV)
Partner with MLOps and DevOps teams to implement best practices in model monitoring, version and re-training.
Lead code reviews, architecture discussions and mentor junior & peer engineers.
Architect and implement end-to-end AI/ML pipelines, ensuring scalability and efficiency.
Deploy models in cloud-based (AWS, Azure, GCP) or on-premises environments using tools like Docker, Kubernetes, TensorFlow Serving, or ONNX
Ensure data integrity, quality, and preprocessing best practices for AI/ML model development.
Ensure compliance with AI ethics guidelines, data privacy laws (GDPR, CCPA), and corporate AI governance.
Work closely with data engineers, software developers, and domain experts to integrate AI into existing systems.
Conduct AI/ML training sessions for internal teams to improve AI literacy within the organization.
Strong analytical and problem solving mindset.




Technical Requirements:

Strong expertise in AI/ML engineering and software development.
Strong experience with RAG architecture, vector databases
Proficiency in Python and hands-on experience in using ML frameworks (tensorflow, pytorch, scikit-learn, xgboost etc)
Familiarity with MCPs like Google Dialogflow, Rasa, Amazon Lex, or custom-built agents using LLM orchestration.
Cloud-based AI/ML experience (AWS Sagemaker, Azure ML, GCP Vertex AI, etc.).
Solid understanding of AI/ML life cycle – Data preprocessing, feature engineering, model selection, training, validation and deployment.
Experience in production grade ML systems (Model serving, APIs, Pipelines)
Familiarity with Data engineering tools (SPARK, Kafka, Airflow etc)
Strong knowledge of statistical modeling, NLP, CV, Recommendation systems, Anomaly detection and time series forecasting.
Hands-on in Software engineering with knowledge of version control, testing & CI/CD
Hands-on experience in deploying ML models in production using Docker, Kubernetes, TensorFlow Serving, ONNX, and MLflow.
Experience in MLOps & CI/CD for ML pipelines, including monitoring, retraining, and model drift detection.
Proficiency in scaling AI solutions in cloud environments (AWS, Azure & GCP).
Experience in data preprocessing, feature engineering, and dimensionality reduction.
Exposure to Data privacy, Compliance and Secure ML practices




Education and/or Experience:

Graduation or master’s in computer science or information technology or AI/ML/Data science
3+ years of hands-on experience in AI/ML development/deployment and optimization
Experience in leading AI/ML teams and mentoring junior engineers.

Show more "
AI/ML Engineer,Impetus,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-impetus-4279596200?position=30&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=JgszSA2ezfKwodxoeqX2GQ%3D%3D,"Job Description:




Hands-on experience working with SAS to Python conversions.
Strong mathematics and statistics skills.
Skilled in AI-specific utilities like ChatGPT, Hugging Face Transformers, etc.
Ability to understand business requirements.
Use case derivation and solution creation from structured/unstructured data
Storytelling, Business Communication, and Documentation
Programming Skills – SAS, Python, Scikit-Learn, TensorFlow, PyTorch, Keras
Exploratory Data Analysis
Machine Learning and Deep Learning Algorithms
Model building, Hyperparameter tuning, and Model performance metrics
MLOps, Data Pipeline, Data Engineering
Statistics Knowledge (Probability Distributions, Hypothesis Testing)
Time series modeling, Forecasting, Image/Video Analytics, and Natural Language Processing (NLP).
ML services from Clouds such as AWS, GCP, Azure, and Databricks
Optional - Databricks, Big Data -Basic knowledge of Spark, Hive




Roles & Responsibilities:




Responsible for SAS to python code conversion.
Acquire skills required for building Machine learning models and deploy them for production.
Feature Engineering, EDA, Pipeline creation, Model training, and hyperparameter tuning with structured and unstructured data sets. skills
Develop and deploy cloud-based applications, including LLM/GenAI, into production.

Show more "
Junior Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/junior-data-scientist-at-ab-inbev-gcc-india-4279260172?position=31&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=rudFKbBzDiOczgj%2FWsjplw%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Description

Job Title: Junior Data Scientist

Location: Bangalore

Reporting to: Senior Manager – Analytics




1. Purpose of the role

The Global GenAI Team at Anheuser-Busch InBev (AB InBev) is tasked with constructing competitive solutions utilizing GenAI techniques. These solutions aim to extract contextual insights and meaningful information from our enterprise data assets. The derived data-driven insights play a pivotal role in empowering our business users to make well-informed decisions regarding their respective products. In the role of a Machine Learning Engineer (MLE), you will operate at the intersection of:




LLM-based frameworks, tools, and technologies
Cloud-native technologies and solutions
Microservices-based software architecture and design patterns As an additional responsibility, you will be involved in the complete development cycle of new product features, encompassing tasks such as the development and deployment of new models integrated into production systems. Furthermore, you will have the opportunity to critically assess and influence the product engineering, design, architecture, and technology stack across multiple products, extending beyond your immediate focus.




2. Key tasks & accountabilities

Large Language Models (LLM):

Experience with LangChain, LangGraph
Proficiency in building agentic patterns like ReAct, ReWoo, LLMCompiler

Multi-modal Retrieval-Augmented Generation (RAG):

Expertise in multi-modal AI systems (text, images, audio, video)
Designing and optimizing chunking strategies and clustering for large data processing

Streaming & Real-time Processing:

Experience in audio/video streaming and real-time data pipelines
Low-latency inference and deployment architectures

NL2SQL:

Natural language-driven SQL generation for databases
Experience with natural language interfaces to databases and query optimization

API Development:

Building scalable APIs with FastAPI for AI model serving

Containerization & Orchestration:

Proficient with Docker for containerized AI services
Experience with orchestration tools for deploying and managing services

Data Processing & Pipelines:

Experience with chunking strategies for efficient document processing
Building data pipelines to handle large-scale data for AI model training and inference

AI Frameworks & Tools:

Experience with AI/ML frameworks like TensorFlow, PyTorch
Proficiency in LangChain, LangGraph, and other LLM-related technologies

Prompt Engineering:

Expertise in advanced prompting techniques like Chain of Thought (CoT) prompting, LLM Judge, and self-reflection prompting
Experience with prompt compression and optimization using tools like LLMLingua, AdaFlow, TextGrad, and DSPy
Strong understanding of context window management and optimizing prompts for performance and efficiency




3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

Bachelor's or masterʼs degree in Computer Science, Engineering, or a related field.

Previous work experience required

Proven experience of 1+ years in developing and deploying applications utilizing Azure OpenAI and Redis as a vector database.

Technical skills required

Solid understanding of language model technologies, including LangChain, OpenAI Python SDK, LammaIndex, OLamma, etc.
Proficiency in implementing and optimizing machine learning models for natural language processing.
Experience with observability tools such as mlflow, langsmith, langfuse, weight and bias, etc.
Strong programming skills in languages such as Python and proficiency in relevant frameworks.
Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes).




And above all of this, an undying love for beer!

We dream big to create future with more cheer

Show more "
AI/ML Engineer,CodeCraft Technologies Pvt Ltd,"Bengaluru, Karnataka, India",Bengaluru,2025-08-01,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-codecraft-technologies-pvt-ltd-4278976918?position=32&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=H%2BADJzlRMsoK4IDNE5UM8w%3D%3D,"Job Category: AIML

Job Type: Full Time

Job Location: Bengaluru Mangalore

Experience: 4-8 Years

Skills: AI AWS/AZURE/GCP Azure ML C computer vision data analytics Data Modeling Data Visualization deep learning Descriptive Analytics GenAI Image processing Java LLM models ML ONNX Predictive Analytics Python R Regression/Classification Models SageMaker SQL TensorFlow

Position Overview

We are looking for an experienced AI/ML Engineer to join our team. The ideal candidate will bring a deep understanding of machine learning, artificial intelligence, and big data technologies, with proven expertise in developing scalable AI/ML solutions. This role shall lead technical efforts, mentor team members, and collaborate with cross-functional teams to design, develop, and deploy cutting edge AI/ML applications.

Job Details


Job Category: AI/ML Engineer.
Job Type: Full-Time
Job Location: Bangalore/Mangalore
Experience Required: 4-8 Years


Key Responsibilities


Design, develop, and deploy deep learning models for object classification, detection, and segmentation using CNNs and Transfer Learning.
Implement image preprocessing and advanced computer vision pipelines.
Optimize deep learning models using pruning, quantization, and ONNX for deployment on edge devices.
Work with PyTorch, TensorFlow, and ONNX frameworks to develop and convert models.
Accelerate model inference using GPU programming with CUDA and cuDNN.
Port and test models on embedded and edge hardware platforms. (Orin, Jetson, Hailo)
Conduct research and experiments to evaluate and integrate GenAI technologies in computer vision tasks.
Explore and implement cloud-based AI workflows, particularly using AWS/Azure AI/ML services.
Collaborate with cross-functional teams for data analytics, data processing, and large-scale model training.


Desired Profile


Strong programming experience in Python.
Solid background in deep learning, CNNs, and transfer learning and Machine learning basics.
Expertise in object detection, classification, segmentation.
Proficiency with PyTorch, TensorFlow, and ONNX.
Experience with GPU acceleration (CUDA, cuDNN).
Hands-on knowledge of model optimization (pruning, quantization).
Experience deploying models to edge devices (e.g., Jetson, mobile, Orin, Hailo )
Understanding of image processing techniques.
Familiarity with data pipelines, data preprocessing, and data analytics.
Willingness to explore and contribute to Generative AI and cloud-based AI solutions.
Good problem-solving and communication skills.


Good to have


Experience with C/C++.
Familiarity with AWS Cloud AI/ML tools (e.g., SageMaker, Rekognition).
Exposure to GenAI frameworks like OpenAI, Stable Diffusion, etc.
Knowledge of real-time deployment systems and streaming analytics.


Qualifications

Graduation/Post-graduation in Computers, Engineering, or Statistics from a reputed institute

If you are passionate to work in a collaborative and challenging environment, apply now!
Show more "
AI Python Engineer,OpenText,"Bengaluru, Karnataka, India",Bengaluru,2025-08-03,https://in.linkedin.com/jobs/view/ai-python-engineer-at-opentext-4253818817?position=33&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=8bqaYyWnReslhOxBYXMzfQ%3D%3D,"Opentext - The Information Company

OpenText is a global leader in information management, where innovation, creativity, and collaboration are the key components of our corporate culture. As a member of our team, you will have the opportunity to partner with the most highly regarded companies in the world, tackle complex issues, and contribute to projects that shape the future of digital transformation.

AI-First. Future-Driven. Human-Centered.

At OpenText, AI is at the heart of everything we do—powering innovation, transforming work, and empowering digital knowledge workers. We're hiring talent that AI can't replace to help us shape the future of information management. Join us.

Your Impact

As a Python Developer in the Debricked data science team, you will work on enhancing data intake processes and optimizing data pipelines. You will apply many different approaches, depending on the needs of the product and the challenges you encounter. In some cases, we use AI/LLM techniques, and we expect the number of such cases to increase. Your contributions will directly impact Debricked’s scope and quality and will help ensure future commercial growth of the product.

What The Role Offers

As a Python Developer, you will:


Innovative Data Solutions: Develop and optimize data pipelines that improve the


efficiency, accuracy, and automation of the Debricked SCA tool’s data intake processes.


Collaborative Environment: Work closely with engineers and product managers from Sweden and India to create impactful, data-driven solutions.
Continuous Improvement: Play an essential role in maintaining and improving the data quality that powers Debricked’s analysis, improving the product’s competitiveness.
Skill Development: Collaborate across teams and leverage OpenText’s resources (including an educational budget) to develop your expertise in software engineering,data science and AI, expanding your skill set in both traditional and cutting-edge technologies.


What You Need To Succeed


2-4 years of experience in Python development, with a focus on optimizing data processes and improving data quality. Proficiency in Python and related tools and libraries like Jupyter, Pandas and Numpy.
A degree in Computer Science or a related discipline.
An interest in application security.
Asset to have skills in Go, Java, LLMs (specifically Gemini), GCP, Kubernetes, MySQL, Elastic, Neo4J.
A strong understanding of how to manage and improve data quality in automated systems and pipelines.
Ability to address complex data challenges and develop solutions to optimize systems.
Comfortable working in a distributed team, collaborating across different time zones.


One Last Thing

OpenText is more than just a corporation, it's a global community where trust is foundational, the bar is raised, and outcomes are owned.Join us on our mission to drive positive change through privacy, technology, and collaboration. At OpenText, we don't just have a culture; we have character. Choose us because you want to be part of a company that embraces innovation and empowers its employees to make a difference.

OpenText's efforts to build an inclusive work environment go beyond simply complying with applicable laws. Our Employment Equity and Diversity Policy provides direction on maintaining a working environment that is inclusive of everyone, regardless of culture, national origin, race, color, gender, gender identification, sexual orientation, family status, age, veteran status, disability, religion, or other basis protected by applicable laws.

If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please contact us at hr@opentext.com. Our proactive approach fosters collaboration, innovation, and personal growth, enriching OpenText's vibrant workplace.
Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4282057513?position=34&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=YXFwMMKcD1S10J9%2FP9ozYA%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Title: Data Scientist

Location: Bangalore

Reporting to: Manager- Analytics/ Senior Manager-Analytics

1. Purpose of the role

Drive AB InBev's pricing strategy by developing and refining data science models, specifically elasticity models, to provide actionable insights that guide business in making optimal pricing decisions.

2. KEY TASKS AND ACCOUNTABILITIES




Understand the business problem and translate that to an analytical problem; participate in the solution design process.
Manage the full AI/ML lifecycle, including data preprocessing, feature engineering, model training, validation, deployment, and monitoring.
Develop reusable and modular Python code adhering to OOP (Object-Oriented Programming) principles.
Design, develop, and deploy machine learning models into production environments on Azure.
Collaborate with data scientists, software engineers, and other stakeholders to meet business needs.
Ability to communicate findings clearly to both technical and business stakeholders.

3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

B. Tech /BE/ Masters in CS/IS/AI/ML/ Statistics

Previous work experience required




Minimum 3 years of relevant experience

Technical skills required

Must Have

Strong expertise in Python, including advanced knowledge of OOP concepts.
Exposure to AI/ML methodologies with a previous hands-on experience in ML concepts like forecasting, clustering, regression, classification, optimization using Python
Azure Tech Stack, Databricks, ML Flow in any cloud platform Airflow for orchestrating and automating workflows
MLOPS concepts and containerization tools like Docker
Experience with version control tools such as Git.
Consistently display an intent for problem solving
Strong communication skills (vocal and written)
Ability to effectively communicate and present information at various levels of an organization.

Good To Have

Preferred industry exposure in Pricing and Revenue management Domain
Product building experience

Other Skills required

Passion for solving problems using data
Detail oriented, analytical and inquisitive
Ability to learn on the go
Ability to work independently and with others

We dream big to create future with more cheers

Show more "
AI/ML Developer - Python,Jade Global,"Hyderabad, Telangana, India",Hyderabad,2024-08-05,https://in.linkedin.com/jobs/view/ai-ml-developer-python-at-jade-global-3993516788?position=35&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=eM3clsnzLZ4YfWJsCgkZGw%3D%3D,"AI/ML Developer - Python1

Position Title : AI/ML Developer - Python

No of position : 1

Location : Pune / Hyderabad

Job Description


Design machine learning systems
Research and implement machine learning algorithms and tools
Manage and direct research and development processes to meet the needs of our AI strategy
Develop machine learning applications in alignment with project requirements and business goals
Perform machine learning tests and statistical analysis in order to fine-tune the machine learning systems
Select appropriate datasets and data representation methods
Extend existing machine learning libraries and frameworks
Train systems and retrain as necessary
Work with the engineering and leadership teams on the functional design, process design, prototyping, testing, and training of AI/ML solutions
Advise leaders on technology, strategy, and policy issues related to AI/ML
Coordinating with development teams to determine application requirements.
Writing scalable code using Python programming language.
Testing and debugging applications.
Developing back-end components.
Integrating user-facing elements using server-side logic.
Assessing and prioritizing client feature requests.
Integrating data storage solutions.
Coordinating with front-end developers.
Reprogramming existing databases to improve functionality.
Developing digital tools to monitor online traffic.
Work with the Data Scientists and Data Engineers to create production quality.
Machine Learning pipelines and solutions with an emphasis on Performance, Scalability, Reliability, and Maintainability.
Build components and libraries that will improve existing solutions and improve the delivery of new ones


Required Skills And Experience


3+ years of experience applying AI to practical uses
Experience with deep learning, NLP, and TensorFlow
Experience writing robust code in Python, Java, and/or R
Experience in REST API development, NoSQL database design, and RDBMS design and optimizations
Knowledge of basic algorithms and object-oriented and functional design principles
Knowledge of data structures, data modeling, and software architecture
Knowledge of math, probability, statistics, and algorithms
Knowledge of machine learning frameworks
Knowledge of machine learning libraries such as scikit-learn
Excellent communication skills
Strong analytical and problem solving skills


Preferred Qualifications


Bachelor's degree in a relevant technology field
Experience with cloud environments
Show more "
AI/ML Engineer,Deccan AI,"Hyderabad, Telangana, India",Hyderabad,2025-07-24,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-deccan-ai-4275340084?position=36&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=kjcwWei4zvlpY1ZSOb9Q8A%3D%3D,"About Soul AI Pods

Deccan AI is a pioneering company founded by IIT Bombay and IIM Ahmedabad alumni, with a strong founding team from top tier institutes like IITs, NITs, and BITS.





We’re hiring for our client servicing arm Soul AI. Soul AI has a talent network, known as Soul AI Pods, under which highly skilled & vetted tech talent gets the opportunity to work with top-tier global tech companies. Our client list includes tech giants like Google & Snowflake

.Read more about her

eResponsibilitie

sBuilding agentic systems, LLM pipelines, or RLHF framework
sPackage and deploy models via containerized APIs and manage CI/CD pipeline
sOwn the end-to-end ML lifecycle, from data prep to serving to monitorin
gCollaborate with product and engineering teams on scalable AI solution




sSkill Require




d
Strong foundation in machine learning, deep learning, and model evaluati
onProficient in Python, with experience in PyTorch, TensorFlow, and scikit-lea
rnSkilled in data preprocessing, feature engineering, and SQL-based data handli
ngFamiliar with deploying APIs using Docker, FastAPI, and managing version control with G
itExperience with cloud platforms (AWS/GCP/Azure) and ML model deployment at sca
leUnderstanding of MLOps tools (MLflow, Kubeflow) and CI/CD workflows for ML syste




ms
Application & Other Deta

ilsTo apply, fill the Soul AI Pods Interest F
ormYou will be invited for selection process → R1: Test, R2: AI Interview, R3: 1:1 Interv
iewWe are hiring for full-time or long Contract (40 hrs/week) hybrid ro
lesWe are hiring across different seniority lev
elsYou will work on a key client project (Top-tier tech consulting fi




rm)
Show more "
Interesting Job Opportunity: Volody - Python Developer - Machine Learning,Volody,Mumbai Metropolitan Region,Mumbai Metropolitan Region,2025-06-27,https://in.linkedin.com/jobs/view/interesting-job-opportunity-volody-python-developer-machine-learning-at-volody-4258247069?position=37&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=T7D8X%2B5%2BgPT2VVcz6ii%2BTw%3D%3D,"Objectives Of This Role


Develop, test and maintain high-quality software using Python programming language.
Participate in the entire software development lifecycle, building, testing and delivering high-quality solutions.
Collaborate with cross-functional teams to identify and solve complex problems.
Write clean and reusable code that can be easily maintained and scaled.


Your Tasks


Create large-scale data processing pipelines to help developers build and train novel machine learning algorithms.
Participate in code reviews, ensure code quality and identify areas for improvement to implement practical solutions.
Debugging codes when required and troubleshooting any Python-related queries.
Keep up to date with emerging trends and technologies in Python development.


Required Skills And Qualifications


2+ years of experience as a Python Developer with a strong portfolio of projects.
Bachelor's degree in Computer Science, Software Engineering or a related field.
In-depth understanding of the Python software development stacks, ecosystems, frameworks and tools such as Numpy, Scipy, Pandas, Dask, spaCy, NLTK, sci-kit-learn and PyTorch.
Experience with front-end development using HTML, CSS, and JavaScript.
Familiarity with database technologies such as SQL and NoSQL.
Excellent problem-solving ability with solid communication and collaboration skills.


(ref:hirist.tech)
Show more "
Data Scientist 1,Uber,"Bengaluru, Karnataka, India",Bengaluru,2025-08-06,https://in.linkedin.com/jobs/view/data-scientist-1-at-uber-4281428228?position=38&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=lDoGA5lSYPXqmdM6CsrzOw%3D%3D,"About The Role

Communication Platform enables all the messages (SMS OTP, Whatsapp, Notifications, Voice Call, Chat) among our users. This role will help improve our communications products in improving the Deliverability, reliability and reach of the messages by optimising the cost at the same time. Improving effieciency of communications among our users will helop improve trip conversion and in turn revenue for the organization.

What The Candidate Will Need / Bonus Points

---- What the Candidate Will Do ----


Build scalable analytical frameworks to support product analytics for Uber's Communications Platform
Own new product experimentation including plan creation, roll-out, and monitoring
Be an invaluable partner to cross-functional teams such as engineering, product management, various data teams to deploy data quality across critical pipelines and to set up processes to triage data issues
Develop and track metrics and reporting functions to measure and monitor products performance on our platform
Effectively and proactively communicate insights and drive projects to drive towards team goals
Proactively seek out opportunities to build new solutions to tackle challenges
Create and drive data quality standards and frameworks to ensure inclusion into pipeline engineering efforts


Basic Qualifications


2+ years of experience (Bachelor) OR 1+ years of experience (Masters) in a data-focused role such as product analytics, business analytics, business operations, or data science
Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience
Experience in programming and/or query languages
Past experience with a Product / Tech company serving millions of customers on multiple platforms and countries


Preferred Qualifications


SQL mastery. Write efficient and complex code in SQL
Experience in Python/R and experimentation, A/B testing, and statistical modelling
Experience in Payments or Compliance with a Product / Tech company
Proven ability to handle and visualise large datasets, explore and utilize raw data feeds
Love of data - you just go get the data you need and turn it into an insightful story.
A well-organized, structured approach to problem-solving
Strong sense of ownership, accountability, and entrepreneurial spirit
Great communicator, problem-solver & confident in decision making
Independent & autonomous, while still a strong teammate
Enthusiastic, self-starting and thrives in changing, agile environments
Show more "
AI/ML Engineers,Jade Global,"Pune, Maharashtra, India",Pune,2024-08-05,https://in.linkedin.com/jobs/view/ai-ml-engineers-at-jade-global-3993516795?position=39&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=1lDH%2BC4Fdw7gcqBP9FUL%2FA%3D%3D,"AI/ML Engineers1


AI/ML (Artificial Intelligence/Machine Learning) engineers with 3+ years of experience and having knowledge of Python, Microsoft OpenAI, and GitHub Copilot, along with AWS (Amazon Web Services) cloud experience.
Design, implement, and optimize machine learning algorithms using Python to solve complex business problems.
Build Prototypes, demos and Gen AI and AI/ML Solutions.
Leverage Microsoft OpenAI and GitHub Copilot for enhanced code suggestions and collaboration.
Train, evaluate, and fine-tune machine learning models on large datasets using frameworks like TensorFlow or PyTorch.
Utilize OpenAI's models for natural language processing tasks and generate code snippets with Copilot to expedite development.
Perform data preprocessing tasks, including cleaning, normalization, and feature engineering, to prepare datasets for machine learning models.
Use Python libraries and tools to extract meaningful features from raw data.
Deploy and manage machine learning models on AWS cloud infrastructure.
Utilize AWS services like SageMaker for model training, deployment, and monitoring.
Collaborate with cross-functional teams, including data scientists, software engineers, and business stakeholders.
Document code, models, and processes to ensure transparency and facilitate knowledge transfer.
Implement CI/CD pipelines to automate the testing, deployment, and monitoring of machine learning models.
Use GitHub Copilot to enhance code quality and efficiency in the development lifecycle.
Monitor the performance of deployed models and optimize them for scalability, speed, and accuracy.
Implement best practices for model versioning and management.
Ensure that machine learning solutions adhere to security standards and compliance requirements.
Implement secure coding practices and data protection measures.
Stay updated on the latest advancements in AI/ML, Python, OpenAI, and cloud technologies.
Experiment with new models, techniques, and tools to drive innovation within the team.
Troubleshoot and debug issues related to machine learning models, Python code, and cloud infrastructure.
Collaborate with support teams to address production issues promptly.
Provide guidance and training to team members on AI/ML best practices, Python coding standards, and effective use of OpenAI and Copilot.
Conduct workshops or knowledge-sharing sessions within the organization.
Optimize cloud resources to ensure cost-effectiveness in model training and deployment on AWS.
Requirements
Proficiency in python, Gen AI, Microsoft OpenAI, and GitHub Copilot, along with AWS
Strong knowledge of Python, TensorFlow and PyTorch
Strong knowledge of NLPs like Microsoft OpenAI and Copilot
Knowledge of cloud platforms like Amazon Web Services.
Solid understanding of SQL and data manipulation techniques for data extraction, transformation, and loading.
Ability to understand business requirements and translate them into meaningful solutions.
Strong analytical and problem-solving skills.
Excellent communication and collaboration skills to work effectively with business users, data analysts, and other stakeholders.


Educational Qualifications


Bachelor's degree in computer science, software engineering, mathematics, or a related field is often the minimum requirement
Knowledge of Data science will be added advantage.
Show more "
Data Scientist – Fraud & Scams Detection,Deloitte,"Gurugram, Haryana, India",Gurugram,2025-06-06,https://in.linkedin.com/jobs/view/data-scientist-%E2%80%93-fraud-scams-detection-at-deloitte-4234129872?position=40&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=VxuJoOs3dgPDGuPjG%2BnTwg%3D%3D,"What impact will you make?







Every day, your work will make an impact that matters, while you thrive in a dynamic culture of inclusion, collaboration and high performance. As the undisputed leader in professional services, Deloitte is where you will find unrivaled opportunities to succeed and realize your full potential




Deloitte is where you will find unrivaled opportunities to succeed and realize your full potential.







The Team

Deloitte’s practice can help you uncover and unlock the value buried deep inside vast amounts of data. Our global network provides strategic guidance and implementation services to help companies manage data from disparate sources and convert it into accurate, actionable information that can support fact-driven decision-making and generate an insight-driven advantage. Our practice addresses the continuum of opportunities in business intelligence & visualization, data management, performance management and next-generation analytics and technologies, including big data, cloud, cognitive and machine learning. Learn more about Analytics and Information Management Practice




Position Title: Data Scientist – Fraud & Scams Detection

Role Type: Data Scientist / Model Developer

Division: Division or Business Unit, e.g., Financial Crime Analytics / Technology & Operations




Role Purpose: - The Data Scientist – Fraud & Scams Detection will be responsible for designing, developing, and deploying advanced machine learning models to detect and mitigate fraud in digital and card transactions. This role supports the transition from a third-party solution to an internally developed and managed fraud detection system. The successful candidate will play a key role across the full model lifecycle—from early-stage analysis and feature engineering through to deployment and post-production monitoring working closely within an agile squad environment.




Key Responsibilities

Design and develop fraud and scams detection models tailored to digital and card transaction data.
Replace existing third-party fraud detection solutions with internally developed models.
Define and test different ML approaches suitable for the fraud domain.
Lead feature engineering, feature selection, and hyperparameter tuning for model optimization.
Collaborate with business stakeholders, engineers, and squad members from initial discovery to deployment.
Articulate design choices, modeling approaches, and monitoring strategies clearly and effectively.
Deploy models into production using modern MLOps practices.
Maintain model accuracy, relevance, and compliance through ongoing monitoring and evaluation.




Key Performance Indicators (KPIs)

Successful deployment of fraud detection models with measurable accuracy and performance.
Reduction in false positives/negatives relative to the third-party benchmark.
Timely delivery of model milestones aligned to project timelines.
Evidence of collaboration and active contribution in agile squad setup.
Quality and robustness of documentation and monitoring processes.




Essential Experience

Proven experience in developing and deploying fraud detection or risk models in production environments.
Experience with end-to-end model development, including:
Algorithm selection
Feature engineering and selection
Model training and tuning
Deployment and post-deployment monitoring
Strong understanding of fraud patterns and digital transaction behaviors.
Hands-on experience working within agile teams or squads on data science delivery.




Technical & Functional Competencies

Required:
High proficiency in SQL, Python, PySpark
Strong understanding of version control using Git
Preferred:
Experience with Databricks
Familiarity with MLOps frameworks and production workflows




Soft Skills & Attributes

Analytical mindset with a strong problem-solving approach.
Ability to articulate complex data science concepts and decisions to non-technical stakeholders.
Proactive, self-driven, and accountable for delivering high-quality outcomes.
Strong communication and collaboration skills.
Comfortable working in fast-paced, evolving environments.




Qualification Requirements

Bachelor's or postgraduate degree in Computer Science, Statistics, Mathematics, Engineering, or a related quantitative field.







Our purpose Deloitte is led by a purpose: To make an impact that matters.

Every day, Deloitte people are making a real impact in the places they live and work. We pride ourselves on doing not only what is good for clients, but also what is good for our people and the

Communities in which we live and work—always striving to be an organization that is held up as a role model of quality, integrity, and positive change. Learn more about Deloitte's impact on the world

Show more "
AI/ML Engineer - Python,iAI Solution,"Bengaluru, Karnataka, India",Bengaluru,2025-06-17,https://in.linkedin.com/jobs/view/ai-ml-engineer-python-at-iai-solution-4252091093?position=41&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=B0WmuEtSWh5hJ52XUAujMw%3D%3D,"Job Title : AI/ML Engineer

Location : Bengaluru, India

Experience : 6 months - 2 years

Company Overview

IAI Solutions operates at the edge of applied AI where foundational research meets real-world deployment. We craft intelligent systems that think in teams, adapt with context, and deliver actionable insight across domains.

Position Summary

We are looking for an AI/ML Engineer with a strong background in Python, Flask/FastAPI and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, open source model fine-tuning, and using the HuggingFace libraries.

Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.

Key Responsibilities


Develop, fine-tune, and deploy AI models using Python and Flask/FastAPI frameworks.
Apply prompt engineering techniques to optimize model outputs and improve accuracy.
Utilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.
Work on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.
Collaborate with research teams to translate cutting-edge AI research into scalable solutions.
Implement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.
Stay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.
Document and share findings, best practices, and solutions across the engineering team.


An Ideal Candidate Will Have


Strong proficiency in Python and Flask/FastAPI.
Experience in prompt engineering and fine-tuning AI models.
Extensive experience with HuggingFace libraries and similar AI/ML tools.
Strong experience in AI Agentic Architecture
Hands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.
Proficiency in Databases like MongoDB or PostgreSQL, as well as vector databases such as FAISS, Qdrant, or Elasticsearch
Hands-on experience with Docker and Git for version control.
Background in AI/ML research, with a preference for candidates from research institutes.
Demonstrated experience in training and deploying machine learning models in real-world applications.
Solid understanding of object-oriented programming and problem-solving skills.
Strong analytical skills and the ability to work independently or in a team environment.
Excellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.


Must Have Skills


Python
Object-Oriented Programming (OOP)
Prompt engineering
HuggingFace libraries and similar AI/ML tools
Open Source Model fine-tuning
AI Agentic Architecture such as LangGraph and CrewA
Docker and Git for version control.
Databases like MongoDB or PostgreSQL, as well as vector databases such as FAISS, Qdrant, or Elasticsearch


Good To Have


Deep Learning and Machine Learning
AWS SageMaker or similar services for training AI models
Previous experience in academic or industrial research, with published work in AI/ML.
Proven track record of successful AI model deployments and optimizations.
Experience with databases like MongoDB or PostgreSQL, as well as vector databases such as FAISS, Qdrant, or Elasticsearch.


Perks & Benefits


Work on groundbreaking AI/ML projects in a collaborative and innovative environment.
Access to state-of-the-art tools and cloud platforms.
Opportunities for professional development and continuous learning.
Competitive salary.
Join IAI Solutions and help build the future of AI-powered software!


(ref:hirist.tech)
Show more "
ML Engineer,AbleCredit,"Pune, Maharashtra, India",Pune,2024-10-19,https://in.linkedin.com/jobs/view/ml-engineer-at-ablecredit-4052680289?position=42&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=E84Nett7aCqR7nR3mRaE3w%3D%3D,"Salary: INR 15 to INR 30 lakhs per annum

Performance Bonus: Up to 10% of the base salary can be added

Location: Bangalore or Pune

Experience: 2-5 years

About AbleCredit

AbleCredit is on a mission to solve the Credit Gap of emerging economies. In India alone, the Credit Gap is over USD 5T (Trillion!). This is the single largest contributor to poverty, poor genie index and lack of opportunities. Our Vision is to deploy AI reliably, and safely to solve some of the greatest problems of humanity.

Job Description

This role is ideal for someone with a strong foundation in deep learning and hands-on experience with AI technologies.


You will be tasked with solving complex, real-world problems using advanced machine learning models in a privacy-sensitive domain, where your contributions will have a direct impact on business-critical processes.
As a Machine Learning Engineer at AbleCredit, you will collaborate closely with the founding team, who bring decades of industry expertise to the table.
You’ll work on deploying cutting-edge Generative AI solutions at scale, ensuring they align with strict privacy requirements and optimize business outcomes.


This is an opportunity for experienced engineers to bring creative AI solutions to one of the most challenging and evolving sectors, while making a significant difference to the company’s growth and success.

Requirements


Experience: 2-4 years of hands-on experience in applying machine learning and deep learning techniques to solve complex business problems.
Technical Skills: Proficiency in standard ML tools and languages, including:
Python: Strong coding ability for building, training, and deploying machine learning models.
PyTorch (or MLX or Jax): Solid experience in one or more deep learning frameworks for developing and fine-tuning models.
Shell scripting: Familiarity with Unix/Linux shell scripting for automation and system-level tasks.
Mathematical Foundation: Good understanding of the mathematical principles behind machine learning and deep learning (linear algebra, calculus, probability, optimization).
Problem Solving: A passion for solving tough, ambiguous problems using AI, especially in data-sensitive, large-scale environments.
Privacy & Security: Awareness and understanding of working in privacy-sensitive domains, adhering to best practices in data security and compliance.
Collaboration: Ability to work closely with cross-functional teams, including engineers, product managers, and business stakeholders, and communicate technical ideas effectively.
Work Experience: This position is for experienced candidates only.


Additional Information


Location: Pune or Bangalore
Work Environment: Collaborative and entrepreneurial, with close interactions with the founders.
Growth Opportunities: Exposure to large-scale AI systems, GenAI, and working in a data-driven privacy-sensitive domain.
Compensation: Competitive salary and ESOPs, based on experience and performance
Industry Impact: You’ll be at the forefront of applying Generative AI to solve high-impact problems in the finance/credit space, helping shape the future of AI in the business world.


Skills:- Python, PyTorch and Shell Scripting
Show more "
Data Scientist,Visa,Greater Bengaluru Area,Greater Bengaluru Area,2025-08-05,https://in.linkedin.com/jobs/view/data-scientist-at-visa-4280080738?position=43&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=Ow4tlt9ycp6c1VigAXxOPQ%3D%3D,"Data Scientist - Credit Card Analytics (3-5yrs)

Bangalore, India
Full-time
Job Family Group: Product Development

Company Description

Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid.

Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.

Job Description

Visa Consulting and Analytics (VCA) is Visa's consulting division, serving Visa's clients (including card issuers, acquirers, and merchants) and solving their strategic problems focused on improving performance and profitability. Drawing on our expertise in strategy consulting, payments, data analytics, marketing, operational and macroeconomics, VCA drives high impact and tangible financial results.

The individual will be part of VCA Data Science team, under Managed Services vertical and will be responsible for delivering data analytics projects with Visa client. The team is involved in a comprehensive range of analytics services for our client, that address unique challenges in areas such as strategic growth, cards profitability, product acquisitions, customer engagement and portfolio management.

What a Data Scientist, Visa Consulting & Analytics does at Visa:

The Data Scientist will be a member of VCA Data Science team in Asia Pacific and will report to the squad lead. This position will be embedded at client office and based in Bangalore.

The individual will be accountable for delivery and implementation of analytics strategies as well as high-impact solutions for the client. He/she will bring in deep expertise from credit cards and retail banking with a strong background in data analysis to solve complex problems and unlock business value.

Key responsibilities include:

Execute and deliver data analytics projects for the Visa client
Drive credit card portfolio strategies with the use of client data and/or other sources of data e.g. Visa data, third party etc.
Act as analytics advocate within our partners, advising teams and sharing best practices and case studies.
Continually look at the environment to challenge our assumptions around new sources of data, potential analytics partners, tools, talent, and infrastructure.
Explore leading methodologies, best practices and import successful methodologies from other international markets
Effectively interact with clients and manage internal/external stakeholder communication

Why this is important to Visa

As payments consulting arm of Visa, VCA is growing a team of highly specialized experts who can provide best-in-class payment expertise and data-driven strategies to clients. We’re building a high-performing team of data scientists, data analysts and statisticians helping major organizations adapt and evolve to meet the changes taking place in technology, finance, and commerce with cutting-edge, creative, and advanced analytic solutions. The purpose of the team is to help Visa’s clients grow their business and solve problems by providing consulting services using data.

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

We are looking for a motivated, analytical minded individual with a track record of using data and analytics to unlock business value. A successful candidate should have accumulated a variety of industry experience, be curious about banking and cards industry, should be results-driven and client-centric.




• Degree in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent

• Minimum 3+ years of analytics experience in applying statistical solutions to business problems

• Experience in card payments and/or retail banking domain

• Hands on experience with one or more data analytics/programming tools such as SAS/Hadoop/R/SQL/Python/Hive

• Outstanding problem-solving skills, with demonstrated ability to think creatively and strategically

• Presentation and data storytelling skills including strong hold on MS Excel and PowerPoint

• Self-motivated, results oriented individual with ability to handle multiple projects concurrently

• Experience in working closely with data science community

Additional Information

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Show more "
Data Scientist,LTIMindtree,"Bengaluru, Karnataka, India",Bengaluru,2025-08-10,https://in.linkedin.com/jobs/view/data-scientist-at-ltimindtree-4282455821?position=44&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=wURvNkzt6%2BLHvHaUsnnITw%3D%3D,"Job Description

We are seeking a talented AI Engineer with a strong background in signal processing vibration analysis and acousticnoise control The ideal candidate will have experience in deploying AI solutions on edge and IoT devices This role will involve designing developing and implementing AI algorithms to process and analyze various signal types and control noise in realtime applications Experience with Generative AI and Predictive Analytics particularly within the Oil Gas OG and Manufacturing sectors is a plus




Key Responsibilities




Develop and implement AI algorithms for signal processing vibration analysis and acousticnoise control

Design and deploy AI models on edge and IoT devices

Collaborate with crossfunctional teams to integrate AI solutions into existing systems and products

Perform data analysis and interpretation to improve and optimize AI models

Work on realtime data processing and ensure efficient deployment on resourceconstrained devices

Conduct research and stay updated on the latest advancements in AI signal processing noise control Generative AI and Predictive Analytics

Troubleshoot and resolve issues related to AI models and deployment on edge devices




Qualifications

Bachelors or Masters degree in Electrical Engineering Computer Science Mechanical Engineering or a related field

Proven experience in signal processing vibration analysis and acousticnoise control

Strong programming skills in Python MATLAB or similar languages

Experience with AI frameworks and libraries such as TensorFlow PyTorch or similar

Knowledge of deploying AI models on edge and IoT devices

Familiarity with microcontroller programming and embedded systems

Strong analytical and problem solving skills

Excellent communication and teamwork abilities

Experience with Generative AI and Predictive Analytics

Knowledge of the Oil Gas OG and Manufacturing sectors is a plus

Show more "
AI/ML Engineer,Citi,"Chennai, Tamil Nadu, India",Chennai,2025-07-28,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-citi-4273277108?position=45&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=aYFc8kpcPuZPouZkeXqDng%3D%3D,"The Applications Development Programmer Analyst is an intermediate level position responsible for participation in the establishment and implementation of new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to contribute to applications systems analysis and programming activities.

Responsibilities:


Responsibilities:
Designing, implementing, and maintaining secure and stable AI/ML solutions using leading AI technology frameworks, including conversational AI solutions
Aligning AI/ML use cases with business strategies and key performance indicators and other metrics
Working closely and lead software engineers to build new applications to run on AI/ML platforms
Perform data analysis, feature engineering, and NLP training to optimize model performance
Monitoring current and future trends and advancements in AI, machine learning, and other emerging technologies
Provide vision for relevant technology systems, including those that support enterprise risk management and independent compliance applications, ensuring that engineers use blueprints, architecture, patterns, and design.
Explore and prototype novel techniques in generative AI/ML including fine-tuning, reinforcement learning with various of reward strategies, transfer learning, and multimodal alignment.
Build and maintain chatbot solutions using bot builder platforms
Interfaces with vendors to assess their technology and to guide their product roadmap based on Citi requirements.
Requires sophisticated analytical thought to resolve issues in a variety of complex situations.
Develop and maintain applications using Node.js and JavaScript, along with relevant frameworks.
Contribute to the development of Generative AI use cases and proof-of-concept projects.
Uses developed communication skills to negotiate and often at higher levels.
Collaborate with cross-functional teams to integrate AI/ML and NLP solutions into existing products and systems.
Perform batch testing and quality assurance of chatbot performance and other NLP applications.
Develop and maintain NLP pipelines for text processing and analysis.
Implement API and system integrations.
Manage databases for storing and retrieving user data using MongoDB, SQL, or other NoSQL databases.
Conduct A/BT testing for conversation flows.


Good to Have:


Experience with cloud computing platforms (e.g., AWS, Azure, GCP).
Experience with MLOps practices.
Contributions to open-source AI/ML or NLP projects.
Experience with Generative AI models and applications.
Deeper expertise with Kore.ai platform, including NLP training and batch testing (preferred for one position).
Experience with Java and Spring Boot.
Knowledge of Unix/Linux operating systems.


Education:


Bachelor’s degree/University degree or equivalent experience


This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.

------------------------------------------------------

Job Family Group:

Technology

------------------------------------------------------

Job Family:

Applications Development

------------------------------------------------------

Time Type:

Full time

------------------------------------------------------

Most Relevant Skills

Please see the requirements listed above.

------------------------------------------------------

Other Relevant Skills

For complementary skills, please see above and/or contact the recruiter.

------------------------------------------------------

Citi is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.

If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View Citi’s EEO Policy Statement and the Know Your Rights poster.
Show more "
AI Core Developer,Tata Electronics,"Bengaluru, Karnataka, India",Bengaluru,2025-07-23,https://in.linkedin.com/jobs/view/ai-core-developer-at-tata-electronics-4268930805?position=46&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=FbLxH0NMJLAFAc6phEK%2B6A%3D%3D,"Company Overview

Tata Electronics Pvt. Ltd. is a prominent global player in the electronics manufacturing industry, with fast-emerging capabilities in Electronics Manufacturing Services, Semiconductor Assembly & Test, Semiconductor Foundry, and Design Services. Established in 2020 as a greenfield venture of the Tata Group, the company aims to serve global customers through integrated offerings across a trusted electronics and semiconductor value chain.




We are seeking a talented AI Core Developer to join our research and development team in Bangalore. This role focuses on fundamental AI research, algorithm development, and model pre-training rather than application engineering.




Position Summary

The AI Core Developer will work on cutting-edge AI research, developing novel algorithms, and building foundation models from the ground up. This is an excellent opportunity for someone with solid experience in pre-training methodologies and algorithm development who wants to contribute to core AI innovations.




Key Responsibilities

Algorithm Development & Research

Design and implement novel machine learning algorithms for computer vision, natural language processing, and multimodal AI systems
Develop optimization techniques for training large-scale models efficiently
Research and implement state-of-the-art techniques in deep learning architectures
Contribute to open-source AI frameworks and model repositories

Model Pre-training & Foundation Models

Design and execute pre-training pipelines for large language models and vision models
Implement data curation and preprocessing pipelines for large-scale datasets
Optimize training procedures, including distributed training and mixed-precision techniques
Develop domain-specific foundation models and evaluate their performance

Technical Innovation

Prototype and validate new AI architectures and training methodologies
Implement knowledge distillation, transfer learning, and few-shot learning techniques
Design synthetic data generation methods for model training
Develop evaluation frameworks and benchmarks for AI model performance

Collaboration & Documentation

Work closely with research scientists and senior engineers on technical projects
Document research findings and contribute to technical publications
Participate in code reviews and maintain high-quality codebase standards
Present research results to internal teams and external stakeholders




Required Qualifications

Education & Experience

Bachelor's or Master's degree in Computer Science, Machine Learning, or related field
2-4 years of hands-on experience in AI/ML development
Demonstrated experience with model pre-training on large datasets
Strong background in algorithm development and implementation

Technical Skills

Programming: Proficiency in Python, C/C++; experience with CUDA programming is a plus
Deep Learning Frameworks: Hands-on experience with PyTorch, TensorFlow, and distributed training
Model Training: Experience with pre-training large models, hyperparameter tuning, and optimization
Infrastructure: Knowledge of Slurm, Docker, and cloud computing platforms (GCP, AWS)
Libraries: Familiarity with HuggingFace, vLLM, TRL, and other ML libraries

Core Competencies

Strong mathematical foundation in linear algebra, statistics, and optimization
Experience with transformer architectures, attention mechanisms, and modern NLP techniques
Knowledge of computer vision fundamentals and multimodal learning
Understanding of distributed computing and parallel processing
Familiarity with MLOps practices and model deployment pipelines




Preferred Qualifications

Advanced Experience

Experience with multimodal AI systems (vision-language models)
Background in scene text recognition, object detection, or video understanding
Knowledge of knowledge distillation and model compression techniques
Experience with synthetic data generation and data augmentation

Research & Publications

Published research in top-tier AI conferences (CVPR, ICCV, NeurIPS, ICML, AAAI)
Contributions to open-source AI projects or frameworks
Experience as a reviewer for academic conferences or journals

Domain Expertise

Understanding of domain-specific AI applications (healthcare, finance, manufacturing)
Experience with RAG systems, agent frameworks, or knowledge graphs
Background in reinforcement learning or self-supervised learning




Location & Work Arrangement

Location: Bangalore, India
Work Mode: Hybrid (3-4 days in office)
Travel: Occasional travel for conferences and collaborations

Show more "
AI/ML Engineer,Impetus,"Gurugram, Haryana, India",Gurugram,2025-08-10,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-impetus-4262914875?position=47&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=Jbbfg9o%2Fa698ONxfNgHv3g%3D%3D,"Job Description-

ML Engineer:

Strong experience of at-least 2-3 years in Python.
2 + years’ experience of working on feature/data pipelines and feature stores using Py-Spark.
Exposure to AWS cloud services such as Sagemaker, Bedrock, Kendra etc.
Experience with machine learning model lifecycle management tools, and an understanding of MLOps principles and best practice.
Knowledge on Docker and Kubernetes.
Experience with orchestration/scheduling tools like Argo.
Experience building and consuming data from REST APIs.
Demonstrable ability to think outside of the box and not be dependent on readily available tools.
Excellent communication, presentation and interpersonal skills are a must.

Py-Spark AWS Engineer:

Good hands-on experience of python and Bash Scripts.
4+ years of good hands-on exposure with Big Data technologies – Pyspark (Data frame and Spark SQL), Hadoop, and Hive
Hands-on experience with using Cloud Platform provided Big Data technologies (i.e. Glue, EMR, RedShift, S3, Kinesis)
Ability to write Glue jobs and utilise the different core functionalities of Glue.
Good understanding of SQL and data warehouse tools like (Redshift).
Experience with orchestration/scheduling tools like Airflow.
Strong analytical, problem-solving, data analysis and research skills.
Demonstrable ability to think outside of the box and not be dependent on readily available tools.
Excellent communication, presentation and interpersonal skills are a must.




Roles & Responsibilities-

Collaborate with data engineers & architects to implement and deploy scalable solutions.
Provide technical guidance and code review of the deliverables.
Play active role in estimation and planning.
Communicate results to diverse technical and non-technical audiences.
Generate actionable insights for business improvements.
Ability to understand business requirements.
Use case derivation and solution creation from structured/unstructured data.
Actively drive a culture of knowledge-building and sharing within the team
Encourage continuous innovation and out-of-the-box thinking.

Good To Have:

ML Engineer:

Experience researching and applying large language and Generative AI models.
Experience with Langchain, LLAMA Index, and Performance Evaluation frameworks.
Experience working with model registry, model deployment & monitoring tools.
ML-Flow / App. Monitoring tools.

Py-Spark AWS Engineer:

Experience in migrating workload from on-premises to cloud and cloud to cloud migrations.
Experience with Data quality frameworks.

Show more "
Data Scientist,PepsiCo,"Hyderabad, Telangana, India",Hyderabad,2025-07-21,https://in.linkedin.com/jobs/view/data-scientist-at-pepsico-4270656480?position=48&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=Xr026Ba3bWJOPTunPl0W2w%3D%3D,"We are PepsiCo

PepsiCo is one of the world's leading food and beverage companies with more than $79 Billion in Net Revenue and a global portfolio of diverse and beloved brands. We have a complementary food and beverage portfolio that includes 22 brands that each generate more than $1 Billion in annual retail sales. PepsiCo's products are sold in more than 200 countries and territories around the world. PepsiCo's strength is its people. We are over 250,000 game changers, mountain movers and history makers, located around the world, and united by a shared set of values and goals.




We believe that acting ethically and responsibly is not only the right thing to do, but also the right thing to do for our business. At PepsiCo, we aim to deliver top-tier financial performance over the long term by integrating sustainability into our business strategy, leaving a positive imprint on society and the environment. We call this Winning with Pep+ Positive. For more information on PepsiCo and the opportunities it holds, visit www.pepsico.com.

PepsiCo Data Analytics & AI Overview:

With data deeply embedded in our DNA, PepsiCo Data, Analytics and AI (DA&AI) transforms data into consumer delight. We build and organize business-ready data that allows PepsiCo’s leaders to solve their problems with the highest degree of confidence. Our platform of data products and services ensures data is activated at scale. This enables new revenue streams, deeper partner relationships, new consumer experiences, and innovation across the enterprise.

The Data Science Pillar in DA&AI will be the organization where Data Scientist and ML Engineers report to in the broader D+A Organization. Also DS will lead, facilitate and collaborate on the larger DS community in PepsiCo. DS will provide the talent for the development and support of DS component and its life cycle within DA&AI Products. And will support “pre-engagement” activities as requested and validated by the prioritization framework of DA&AI.




Data Scientist-Gurugram and Hyderabad




The role will work in developing Machine Learning (ML) and Artificial Intelligence (AI) projects. Specific scope of this role is to develop ML solution in support of ML/AI projects using big analytics toolsets in a CI/CD environment. Analytics toolsets may include DS tools/Spark/Databricks, and other technologies offered by Microsoft Azure or open-source toolsets. This role will also help automate the end-to-end cycle with Machine Learning Services and Pipelines.

Responsibilities

Delivery of key Advanced Analytics/Data Science projects within time and budget, particularly around DevOps/MLOps and Machine Learning models in scope
Collaborate with data engineers and ML engineers to understand data and models and leverage various advanced analytics capabilities
Ensure on time and on budget delivery which satisfies project requirements, while adhering to enterprise architecture standards
Use big data technologies to help process data and build scaled data pipelines (batch to real time)
Automate the end-to-end ML lifecycle with Azure Machine Learning and Azure/AWS/GCP Pipelines.
Setup cloud alerts, monitors, dashboards, and logging and troubleshoot machine learning infrastructure
Automate ML models deployments




Qualifications




Minimum 3years of hands-on work experience in data science / Machine learning
Minimum 3year of SQL experience
Experience in DevOps and Machine Learning (ML) with hands-on experience with one or more cloud service providers
BE/BS in Computer Science, Math, Physics, or other technical fields.
Data Science – Hands on experience and strong knowledge of building machine learning models – supervised and unsupervised models
Programming Skills – Hands-on experience in statistical programming languages like Python and database query languages like SQL
Statistics – Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators
Any Cloud – Experience in Databricks and ADF is desirable
Familiarity with Spark, Hive, Pig is an added advantage
Model deployment experience will be a plus
Experience with version control systems like GitHub and CI/CD tools
Experience in Exploratory data Analysis
Knowledge of ML Ops / DevOps and deploying ML models is required
Experience using MLFlow, Kubeflow etc. will be preferred
Experience executing and contributing to ML OPS automation infrastructure is good to have
Exceptional analytical and problem-solving skills
Show more "
Machine Learning Engineer,Tower Research Capital,"Gurgaon, Haryana, India",Gurgaon,2025-07-23,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-tower-research-capital-3940345912?position=49&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=GE8YXSKjmLFUVZQDxc6nXw%3D%3D,"Tower Research Capital is a leading quantitative trading firm founded in 1998. Tower has built its business on a high-performance platform and independent trading teams. We have a 25+ year track record of innovation and a reputation for discovering unique market opportunities.

Tower is home to some of the world’s best systematic trading and engineering talent. We empower portfolio managers to build their teams and strategies independently while providing the economies of scale that come from a large, global organization.

Engineers thrive at Tower while developing electronic trading infrastructure at a world class level. Our engineers solve challenging problems in the realms of low-latency programming, FPGA technology, hardware acceleration and machine learning. Our ongoing investment in top engineering talent and technology ensures our platform remains unmatched in terms of functionality, scalability and performance.

At Tower, every employee plays a role in our success. Our Business Support teams are essential to building and maintaining the platform that powers everything we do — combining market access, data, compute, and research infrastructure with risk management, compliance, and a full suite of business services. Our Business Support teams enable our trading and engineering teams to perform at their best.

At Tower, employees will find a stimulating, results-oriented environment where highly intelligent and motivated colleagues inspire each other to reach their greatest potential.

Responsibilities:


Developing data pipelines for collecting, processing, and analyzing diverse datasets.
Designing and implement deep learning architectures for large volumes of data.
Conducting experiments and tests to evaluate model performance.
Contributing to optimizing and fine-tuning existing machine learning models.
Building pipelines for monitoring, managing and constantly improving production ML/DL models.


Qualifications:


A bachelor’s, master's, or PhD (complete) degree or equivalent from a top university, with 2-6 years of experience.
Prior experience with training, building, and deploying large scale deep learning models is mandatory.
Prior experience designing and implementing sequence and time series models is required.
Experience with Git, CI/CD pipelines and MLOps for automating model deployments.
Skilled in using Linux, SQL, Git, and BASH scripting.
Strong knowledge of Python and hands-on (Pytorch/Tensorflow).


Benefits:

Tower’s headquarters are in the historic Equitable Building, right in the heart of NYC’s Financial District and our impact is global, with over a dozen offices around the world.

At Tower, we believe work should be both challenging and enjoyable. That is why we foster a culture where smart, driven people thrive – without the egos. Our open concept workplace, casual dress code, and well-stocked kitchens reflect the value we place on a friendly, collaborative environment where everyone is respected, and great ideas win.

Our benefits include:


Generous paid time off policies
Savings plans and other financial wellness tools available in each region
Hybrid working opportunities
Free breakfast, lunch and snacks daily
In-office wellness experiences and reimbursement for select wellness expenses (e.g., gym, personal training and more)
Volunteer opportunities and charitable giving
Social events, happy hours, treats and celebrations throughout the year
Workshops and continuous learning opportunities


At Tower, you’ll find a collaborative and welcoming culture, a diverse team and a workplace that values both performance and enjoyment. No unnecessary hierarchy. No ego. Just great people doing great work – together.

Tower Research Capital is an equal opportunity employer.
Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-07-31,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4275952439?position=50&pageNum=0&refId=NfcrCrJz48mn5aXH06cy7A%3D%3D&trackingId=QuWTdDMMEuOjHM5vhfuHAA%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?




We Need You.




Job Title: Data Scientist




Location: Bangalore




Reporting to: Senior Manager Analytics




1.Purpose of the role




The Data Scientist will play a key role in designing and delivering data-driven solutions that enable better decision-making across the organization. This role requires strong hands-on coding skills in Python, experience with core data science libraries, and the ability to statistically validate features and models. The analyst will collaborate across teams, work efficiently with existing codebases, and apply version control and development best practices to build scalable, production-ready analytics solutions. With intermediate SQL expertise and a solid grasp of model development workflows, the role ensures robust, interpretable, and actionable outcomes from complex data.




2.Key Tasks AND Accountabilities




Develop and maintain data science models using Python, applying intermediate to advanced knowledge of syntax, data structures, and key libraries such as pandas and numpy.
Perform feature engineering and statistical validation of features and models to ensure robustness, accuracy, and business relevance.
Write clean, modular, and well-documented code following best development practices; optionally adopt Test-Driven Development (TDD) to enable faster iteration and feedback cycles.
Collaborate with cross-functional teams to understand data requirements, align on analytical solutions, and translate business problems into data science problems.
Read, understand, and extend existing codebases, adapting quickly to different coding styles and project structures.
Leverage version control tools like Git for collaborative development, code management, and maintaining reproducibility of models.
Write and optimize intermediate-level SQL queries to extract, transform, and analyze data from structured databases.
Contribute to the deployment readiness of models, ensuring outputs are interpretable, reusable, and aligned with production or decision-support use cases.
Document processes, assumptions, and outputs clearly for stakeholder transparency, reproducibility, and future reference.
Stay up to date with industry trends, new tools, and emerging best practices in data science, analytics, and development methodologies.




3.Qualifications, Experience, Skills




Bachelor’s or master’s degree in computer science, Information Systems, Artificial Intelligence, Machine Learning, or a related field (B. Tech / BE / Masters in CS/IS/AI/ML).




Work experience




Minimum of 3 years of hands-on experience in a data science or analytics role, with a proven track record of building and deploying data-driven solutions in real-world scenarios.




Technical Skills Required,




Python Programming (Intermediate to Advanced):
Strong grasp of syntax, data structures, and experience with libraries like pandas and NumPy.
Data Science Fundamentals:
Ability to statistically validate features and models, ensuring sound analytical rigor.
SQL (Intermediate):
Proficiency in writing queries to extract, manipulate, and analyze data from relational databases.
Version Control (GIT):
Familiarity with collaborative development using Git for code versioning and management.
Code Adaptability:
Comfortable working with and modifying existing codebases written by others.




Good to have skills:




Object-Oriented Programming (OOPs) in Python: Understanding and applying OOP concepts where appropriate.
Test-Driven Development (TDD): Awareness of TDD practices for faster iteration and improved code quality.
Model Deployment Lifecycle Knowledge: Familiarity with reproducibility, tracking, and maintaining deployed models (though not explicitly required, it’s a plus if known).




And above all of this, an undying love for beer!




We dream big to create future with more cheers.

Show more "
Data scientist- Python- AI/ML GEN AI- Across india,Capgemini Engineering,"Mumbai, Maharashtra, India",Mumbai,2025-08-04,https://in.linkedin.com/jobs/view/data-scientist-python-ai-ml-gen-ai-across-india-at-capgemini-engineering-4277353126?position=1&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=HpxlqcsH%2FaET5M1t9ESQeA%3D%3D,"• Develop strategies/solutions to solve problems in logical yet creative ways, leveraging state-of-the-art machine learning, deep learning and GEN AI techniques.

• Technically lead a team of data scientists to produce project deliverables on time and with high quality.

• Identify and address client needs in different domains, by analyzing large and complex data sets, processing, cleansing, and verifying the integrity of data, and performing exploratory data analysis (EDA) using state-of-the-art methods.

• Select features, build and optimize classifiers/regressors, etc. using machine learning and deep learning techniques.

• Enhance data collection procedures to include information that is relevant for building analytical systems, and ensure data quality and accuracy.

• Perform ad-hoc analysis and present results in a clear manner to both technical and non-technical stakeholders.

• Create custom reports and presentations with strong data visualization and storytelling skills to effectively communicate analytical conclusions to senior officials in a company and other stakeholders.

• Expertise in data mining, EDA, feature selection, model building, and optimization using machine learning and deep learning techniques.

• Strong programming skills in Python.

• Excellent communication and interpersonal skills, with the ability to present complex analytical concepts to both technical and non-technical stakeholders.







Primary Skills :

- Excellent understanding and hand-on experience of data-science and machine learning techniques & algorithms for supervised & unsupervised problems, NLP and computer vision and GEN AI. Good applied statistics skills, such as distributions, statistical inference & testing, etc.

- Excellent understanding and hand-on experience on building Deep-learning models for text & image analytics (such as ANNs, CNNs, LSTM, Transfer Learning, Encoder and decoder, etc).

- Proficient in coding in common data science language & tools such as R, Python.

- Experience with common data science toolkits, such as NumPy, Pandas, Matplotlib, StatsModel, Scikitlearn, SciPy, NLTK, Spacy, OpenCV etc.

- Experience with common data science frameworks such as Tensorflow, Keras, PyTorch, XGBoost,etc.

- Exposure or knowledge in cloud (Azure/AWS).

- Experience on deployment of model in production.

Show more "
Machine Learning Engineer,Tata Technologies,"Pune, Maharashtra, India",Pune,2025-08-05,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-tata-technologies-4280134590?position=2&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=CoBPfQ5mGdXw7XMKyM22kA%3D%3D,"Location -Pune

Experience - 3 to 6 Years

Qualification - Graduate (B.E/B Tech)




JD .

Lead the architecture, design, and development of components and services to enable Machine Learning at scale
Build data sets from multiple data sources and write data flows using Python and R, SQL/Spark
Exposure to Streaming/Event based architecture
Implementing analytic models on Big data infrastructure
Stay up-to-date on ML, Big Data technologies sharing learnings with the teams
Build reusable code and libraries for future use and optimize application for maximum speed and scalability
Integration of user-facing elements developed by front-end developers with server-side logic
Implementation of security and data protection measures
Exposure in at least one cloud platform on related data services (AWS / Azure / GCP)

Skills – (highlighted are mandatory skill)

Python, R,
SQL,
Spark,
Hadoop, Big data tool,
NodeJS,
Javascript




Job Responsibility:

Apache Spark experience a major plus (Spark RDDs, Spark DataFrames, Spark SQL)
Leverage Spark ecosystem knowledge to design, and develop capabilities to deliver solutions using Scala, Python, Kafka and other things in the Spark ecosystem
Expert in Python, R, NodeJS framework
Good understanding in front-end technologies, such as angular, JavaScript, HTML5, and CSS3
Should design the solution Approach and Come out with optimized effort estimates.
Defining the technical specifications for the implementation of the frontend and backend solution
Should be able to create extensible APIs and scalable python modules

Show more "
Data Scientist,Danone,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/data-scientist-at-danone-4282126896?position=3&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=ReOi7qJNsv9AJ%2BkpfbJDgQ%3D%3D,"About Danone Group:




Mission: ‘Bringing Health through Food to as Many people as Possible’

Danone is a global leader in food and beverages, focusing on Essential Dairy and Plant-based products, Waters, and Specialized Nutrition. Our mission is to bring health through food to as many people as possible by creating nutritious products, promoting healthy eating habits, and operating sustainably.




With nearly 90,000 employees and products available in over 120 markets, Danone generated €27.6 billion in sales in 2023. Our Renew Danone strategy aims to foster long-term value through innovation and community support.




Danone is committed to making a positive impact economically, socially, and environmentally. In 2020, we became the first listed company to adopt the ‘Société à Mission’ status, reflecting our vision for a sustainable future.




More information can be found at www.danone.com.




About Danone India:

Danone operates in India as Nutricia International Pvt. Ltd, focusing on nutrition with a range of products catering to infants, toddlers, pregnant mothers, as well as adults. The company features well-known brands such as Aptamil, Dexolac, and Protinex. Danone employs over 1,000 individuals across India and generates a turnover exceeding €150 million. The company's head office is located in Mumbai, with a manufacturing facility situated in Lalru, Punjab.




Danone India is a Great Place To Work® certified organization, which reflects our commitment to creating a workplace where people are empowered to contribute meaningfully, grow professionally, and feel a true sense of belonging.




More information can be found at https://www.danone.in/




Job Summary:

Work on the project of transformation of Demand Planning at global level in the roadmap of the digitalization for the Supply Chain. Creating and developing the ML models for all Danone categories\




Roles & Responsibilities:




Be part of the design and development of the ML core models and the analytics behind them
Understand and capture cross country needs
Be able to build the common approach of ML scalable models for the demand planning teams of different countries
Support with all the analytics needs for the adoption of the ML models
Build outstanding best in class ML models for Demand Planning that are able to cope with more complex and less steady environments
Set up KPI's to track ML and Statistical models performance
Select and understand the best approach of automatization for the overall Demand process driven by Statistical and Machine Learning capabilities
Ensures collaboration of all teams in order to guarantee scalability of the models
Keeps a close control of the ML developments to ensure cost compliance
Responsible of the Continuous Improvement of the ML models and create the strategy of ML vs Statistical approach
Responsible for the region's continuous improvement of ML and Statistical models in order to improve business performance
Create standard ways of measure and manage strategies to find and fix root causes in forecast bias/accuracy
Develop capabilities and skills on Machine Learning understanding across the regions
Build, maintain, fine tune and audit Statistical & ML models to guarantee adaptability to new business context providing service for all regions
Assist regions in processes and tools to embrace Statistical and ML technology
Shield key processes and know-how on Statistical and ML
Ensures standardization between different countries
Guarantee highest ML utilization




Job Specifications:

Education: Mathematics/Physics/Engineering with a master’s in business/data analytics or proven track record on Data Science
Proven track record of minimum 5 years as a data scientist
Great analytical skills
Coding capabilities in R and/or Phyton
Relationship/ Network builder
Change management
Project management
Experience with Continuous Improvement




Main Interfaces

Cross country demand planning teams
IS/IT project managers and developers
Supply chain cross functions

Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4282057513?position=4&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=K1dRhjMpzCrNAR1EdVFdiA%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Title: Data Scientist

Location: Bangalore

Reporting to: Manager- Analytics/ Senior Manager-Analytics

1. Purpose of the role

Drive AB InBev's pricing strategy by developing and refining data science models, specifically elasticity models, to provide actionable insights that guide business in making optimal pricing decisions.

2. KEY TASKS AND ACCOUNTABILITIES




Understand the business problem and translate that to an analytical problem; participate in the solution design process.
Manage the full AI/ML lifecycle, including data preprocessing, feature engineering, model training, validation, deployment, and monitoring.
Develop reusable and modular Python code adhering to OOP (Object-Oriented Programming) principles.
Design, develop, and deploy machine learning models into production environments on Azure.
Collaborate with data scientists, software engineers, and other stakeholders to meet business needs.
Ability to communicate findings clearly to both technical and business stakeholders.

3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

B. Tech /BE/ Masters in CS/IS/AI/ML/ Statistics

Previous work experience required




Minimum 3 years of relevant experience

Technical skills required

Must Have

Strong expertise in Python, including advanced knowledge of OOP concepts.
Exposure to AI/ML methodologies with a previous hands-on experience in ML concepts like forecasting, clustering, regression, classification, optimization using Python
Azure Tech Stack, Databricks, ML Flow in any cloud platform Airflow for orchestrating and automating workflows
MLOPS concepts and containerization tools like Docker
Experience with version control tools such as Git.
Consistently display an intent for problem solving
Strong communication skills (vocal and written)
Ability to effectively communicate and present information at various levels of an organization.

Good To Have

Preferred industry exposure in Pricing and Revenue management Domain
Product building experience

Other Skills required

Passion for solving problems using data
Detail oriented, analytical and inquisitive
Ability to learn on the go
Ability to work independently and with others

We dream big to create future with more cheers

Show more "
Data Scientist,Unilever,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/data-scientist-at-unilever-4282325097?position=5&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=iH%2BfOKTGEcvOQtJcW7LGtw%3D%3D,"JOB TITLE: Data Scientist

JOB FUNCTION: R&D

SCOPE: Global

WORK LOCATION: Unilever Research India – R&D Bangalore, Whitefield

About Unilever

With 3.4 billion people in over 190 countries using our products every day, Unilever is a business that makes a real impact on the world. Work on brands that are loved and improve the lives of our consumers and the communities around us. We are driven by our purpose: to make sustainable living commonplace, and it is our belief that doing business the right way drives superior performance. At the heart of what we do is our people – we believe that when our people work with purpose, we will create a better business and a better world.

At Unilever, your career will be a unique journey, grounded in our inclusive, collaborative, and flexible working environment. We don’t believe in the ‘one size fits all’ approach and instead we will equip you with the tools you need to shape your own future.

Category Or Function Introduction

HomeCare is a global business with leading household cleaning and laundry brands such as OMO, Sunlight and Comfort. Our aim is to offer products that are unmissably superior, sustainable and great value.

We are organised to deliver growth and margin across three core categories: Fabric Cleaning, Fabric Enhancer, and Home & Hygiene. We have a portfolio of strong global brands, and a global geographical footprint.

Our strength is in emerging markets where we lead the industry through market development.

Within R&D, our team of world-leading scientists, researchers and professionals creates innovations that drive growth for our business and deliver positive impacts for people, society and our planet.

For more than 100 years, we have been using our differentiated science and technology to create the superior products and experiences our consumers love.

Job Purpose

Unilever is the place where you can bring your purpose to life with the work that you do – creating a better business and a better world. If you are passionate about leveraging data analytics power to drive consumer insights and developing modelling capabilities to empower our scientists for innovating superior products, then this role is just for you!

What Will Your Main Responsibilities Be


Analyse complex data sets using a diverse set of machine learning techniques. Build UI solutions to deploy these solutions for the end users.
Develop data analysis and visualization solutions to generate faster insights, thereby helping business team to make informed decision.
Execute data modeling projects working together with project SMEs; manage stakeholder expectations.
Support and manage activities and expectation on data capture and data quality. Ensure data quality compliance with R&D Data Governance standards
Translate business needs into technical specifications, especially for R&D lab and experimental data.


What You Need To Succeed

Experiences & Qualifications


Bachelor’s or master’s degree in STEM subject (Science, Technology, Engineering, or Maths, Computer science, Data Science, Statistics.)
Minimum 2-4 years of working experience in the field of Data science. Experience in data processing / handling, insight building and digital solutions.
Should have working experience in the field of Power BI and/ Python dash.
Having knowledge of experimental data capture systems like LIMS will is plus.
Having python/dash/flask application development skills is plus.


Skills


Expert knowledge in Excel, Power BI. Experience in large data management.
Good to moderate knowledge of scripting and standard modeling practices of developing ML models using Python.
Good to moderate knowledge in interface designing with an ability to understand user’s requirements and develop a mock-up UI wireframe.
Working experience with modelling software such as JMP and DOE are an added advantage.


Leadership


Strong interpersonal and communication skills, both written and oral.
A good team player with ability to work successfully across multiple business units and formats, effectively collaborate with global teams across time-zone.
Energize by delivering fantastic results and be an example to others – with both results and resilience.
Responsible for own wellbeing and delivering high standards of work. Must focus on the Consumer and what they need.


Our commitment to Equality, Diversity & Inclusion

Unilever embraces diversity and encourages applicants from all walks of life! This means giving full and fair consideration to all applicants and continuing development of all employees regardless of age, disability, gender reassignment, race, religion or belief, sex, sexual orientation, marriage and civil partnership, and pregnancy and maternity.

""All official offers from Unilever are issued only via our Applicant Tracking System (ATS). Offers from individuals or unofficial sources may be fraudulent—please verify before proceeding.""
Show more "
Python AI/ML Developer,Coforge,"Noida, Uttar Pradesh, India",Noida,2025-07-18,https://in.linkedin.com/jobs/view/python-ai-ml-developer-at-coforge-4267494470?position=6&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=m7qrbnXzVV9J98tDFK8C3g%3D%3D,"Skills: Python, AI/ML

Experience- 3-5 Years

Location- Greater Noida




Job Description




Around 3 years experience working as an NLP Engineer or similar role.
Understanding of NLP techniques for text representation, semantic extraction techniques, data structures and modelling.
Ability to effectively design software architecture.
Deep understanding of text representation techniques (such as n-grams, bag of words, sentiment analysis etc), statistics and classification algorithms.
Expertise in Python.
Expertise in data structures/algorithms.
Experience with Machine Learning Libraries (like scikit-learn, pytorch and tensorflow).
An analytical mind with problem-solving abilities.

Show more "
Data Scientist,KPMG,"Bengaluru, Karnataka, India",Bengaluru,2025-07-17,https://in.linkedin.com/jobs/view/data-scientist-at-kpmg-4268200771?position=7&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=wK8eGfNZaXh8bStrjoYSFw%3D%3D,"DATA SCIENCE + GEN AI

Major Duties & Responsibilities

• Work with business stakeholders and cross-functional SMEs to deeply understand business context and key business

questions

• Create Proof of concepts (POCs) / Minimum Viable Products (MVPs), then guide them through to production deployment

and operationalization of projects

• Influence machine learning strategy for Digital programs and projects

• Make solution recommendations that appropriately balance speed to market and analytical soundness

• Explore design options to assess efficiency and impact, develop approaches to improve robustness and rigor

• Develop analytical / modelling solutions using a variety of commercial and open-source tools (e.g., Python, R,

TensorFlow)

• Formulate model-based solutions by combining machine learning algorithms with other techniques such as simulations.

• Design, adapt, and visualize solutions based on evolving requirements and communicate them through presentations,

scenarios, and stories.

• Create algorithms to extract information from large, multiparametric data sets.

• Deploy algorithms to production to identify actionable insights from large databases.

• Compare results from various methodologies and recommend optimal techniques.

• Design, adapt, and visualize solutions based on evolving requirements and communicate them through presentations,

scenarios, and stories.

• Develop and embed automated processes for predictive model validation, deployment, and implementation

• Work on multiple pillars of AI including cognitive engineering, conversational bots, and data science

• Ensure that solutions exhibit high levels of performance, security, scalability, maintainability, repeatability, appropriate

reusability, and reliability upon deployment

• Lead discussions at peer review and use interpersonal skills to positively influence decision making

• Provide thought leadership and subject matter expertise in machine learning techniques, tools, and concepts; make

impactful contributions to internal discussions on emerging practices

• Facilitate cross-geography sharing of new ideas, learnings, and best-practices

Required Qualifications

• Bachelor of Science or Bachelor of Engineering at a minimum.

• 4+ years of work experience as a Data Scientist

• A combination of business focus, strong analytical and problem-solving skills, and programming knowledge to be able to

quickly cycle hypothesis through the discovery phase of a project

• Advanced skills with statistical/programming software (e.g., R, Python) and data querying languages (e.g., SQL,

Hadoop/Hive, Scala)

• Good hands-on skills in both feature engineering and hyperparameter optimization

• Experience producing high-quality code, tests, documentation

• Experience with Microsoft Azure or AWS data management tools such as Azure Data factory, data lake, Azure ML,

Synapse, Databricks

• Understanding of descriptive and exploratory statistics, predictive modelling, evaluation metrics, decision trees, machine

learning algorithms, optimization & forecasting techniques, and / or deep learning methodologies

• Proficiency in statistical concepts and ML algorithms

• Good knowledge of Agile principles and process

• Ability to lead, manage, build, and deliver customer business results through data scientists or professional services team

• Ability to share ideas in a compelling manner, to clearly summarize and communicate data analysis assumptions and

results

• Self-motivated and a proactive problem solver who can work independently and in teams




Must to Have : Agent Framework, RAG Framework, Chunking Strategies, LLMs, AI on cloud

Services, Open Source Frameworks like Langchain, Llama Index, Vector Database, Token

Management, Knowledge Graph, Vision APIs, Prompt Engineering




Good to have : AI Algorithms, Deep Learning,Computer Vision, Hallucination Control

Mechanism, Responsible AI frameworks




Tech : Python, SQL, Docker, Versioning tool, Azure/AWS/GCP

Show more "
Junior Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/junior-data-scientist-at-ab-inbev-gcc-india-4279260172?position=8&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=zfTGkYJ7QHS6EOTHVSwOLQ%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Description

Job Title: Junior Data Scientist

Location: Bangalore

Reporting to: Senior Manager – Analytics




1. Purpose of the role

The Global GenAI Team at Anheuser-Busch InBev (AB InBev) is tasked with constructing competitive solutions utilizing GenAI techniques. These solutions aim to extract contextual insights and meaningful information from our enterprise data assets. The derived data-driven insights play a pivotal role in empowering our business users to make well-informed decisions regarding their respective products. In the role of a Machine Learning Engineer (MLE), you will operate at the intersection of:




LLM-based frameworks, tools, and technologies
Cloud-native technologies and solutions
Microservices-based software architecture and design patterns As an additional responsibility, you will be involved in the complete development cycle of new product features, encompassing tasks such as the development and deployment of new models integrated into production systems. Furthermore, you will have the opportunity to critically assess and influence the product engineering, design, architecture, and technology stack across multiple products, extending beyond your immediate focus.




2. Key tasks & accountabilities

Large Language Models (LLM):

Experience with LangChain, LangGraph
Proficiency in building agentic patterns like ReAct, ReWoo, LLMCompiler

Multi-modal Retrieval-Augmented Generation (RAG):

Expertise in multi-modal AI systems (text, images, audio, video)
Designing and optimizing chunking strategies and clustering for large data processing

Streaming & Real-time Processing:

Experience in audio/video streaming and real-time data pipelines
Low-latency inference and deployment architectures

NL2SQL:

Natural language-driven SQL generation for databases
Experience with natural language interfaces to databases and query optimization

API Development:

Building scalable APIs with FastAPI for AI model serving

Containerization & Orchestration:

Proficient with Docker for containerized AI services
Experience with orchestration tools for deploying and managing services

Data Processing & Pipelines:

Experience with chunking strategies for efficient document processing
Building data pipelines to handle large-scale data for AI model training and inference

AI Frameworks & Tools:

Experience with AI/ML frameworks like TensorFlow, PyTorch
Proficiency in LangChain, LangGraph, and other LLM-related technologies

Prompt Engineering:

Expertise in advanced prompting techniques like Chain of Thought (CoT) prompting, LLM Judge, and self-reflection prompting
Experience with prompt compression and optimization using tools like LLMLingua, AdaFlow, TextGrad, and DSPy
Strong understanding of context window management and optimizing prompts for performance and efficiency




3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

Bachelor's or masterʼs degree in Computer Science, Engineering, or a related field.

Previous work experience required

Proven experience of 1+ years in developing and deploying applications utilizing Azure OpenAI and Redis as a vector database.

Technical skills required

Solid understanding of language model technologies, including LangChain, OpenAI Python SDK, LammaIndex, OLamma, etc.
Proficiency in implementing and optimizing machine learning models for natural language processing.
Experience with observability tools such as mlflow, langsmith, langfuse, weight and bias, etc.
Strong programming skills in languages such as Python and proficiency in relevant frameworks.
Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes).




And above all of this, an undying love for beer!

We dream big to create future with more cheer

Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-07-31,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4275952439?position=10&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=OeGqkdlFM63QW7b3xXcyYQ%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?




We Need You.




Job Title: Data Scientist




Location: Bangalore




Reporting to: Senior Manager Analytics




1.Purpose of the role




The Data Scientist will play a key role in designing and delivering data-driven solutions that enable better decision-making across the organization. This role requires strong hands-on coding skills in Python, experience with core data science libraries, and the ability to statistically validate features and models. The analyst will collaborate across teams, work efficiently with existing codebases, and apply version control and development best practices to build scalable, production-ready analytics solutions. With intermediate SQL expertise and a solid grasp of model development workflows, the role ensures robust, interpretable, and actionable outcomes from complex data.




2.Key Tasks AND Accountabilities




Develop and maintain data science models using Python, applying intermediate to advanced knowledge of syntax, data structures, and key libraries such as pandas and numpy.
Perform feature engineering and statistical validation of features and models to ensure robustness, accuracy, and business relevance.
Write clean, modular, and well-documented code following best development practices; optionally adopt Test-Driven Development (TDD) to enable faster iteration and feedback cycles.
Collaborate with cross-functional teams to understand data requirements, align on analytical solutions, and translate business problems into data science problems.
Read, understand, and extend existing codebases, adapting quickly to different coding styles and project structures.
Leverage version control tools like Git for collaborative development, code management, and maintaining reproducibility of models.
Write and optimize intermediate-level SQL queries to extract, transform, and analyze data from structured databases.
Contribute to the deployment readiness of models, ensuring outputs are interpretable, reusable, and aligned with production or decision-support use cases.
Document processes, assumptions, and outputs clearly for stakeholder transparency, reproducibility, and future reference.
Stay up to date with industry trends, new tools, and emerging best practices in data science, analytics, and development methodologies.




3.Qualifications, Experience, Skills




Bachelor’s or master’s degree in computer science, Information Systems, Artificial Intelligence, Machine Learning, or a related field (B. Tech / BE / Masters in CS/IS/AI/ML).




Work experience




Minimum of 3 years of hands-on experience in a data science or analytics role, with a proven track record of building and deploying data-driven solutions in real-world scenarios.




Technical Skills Required,




Python Programming (Intermediate to Advanced):
Strong grasp of syntax, data structures, and experience with libraries like pandas and NumPy.
Data Science Fundamentals:
Ability to statistically validate features and models, ensuring sound analytical rigor.
SQL (Intermediate):
Proficiency in writing queries to extract, manipulate, and analyze data from relational databases.
Version Control (GIT):
Familiarity with collaborative development using Git for code versioning and management.
Code Adaptability:
Comfortable working with and modifying existing codebases written by others.




Good to have skills:




Object-Oriented Programming (OOPs) in Python: Understanding and applying OOP concepts where appropriate.
Test-Driven Development (TDD): Awareness of TDD practices for faster iteration and improved code quality.
Model Deployment Lifecycle Knowledge: Familiarity with reproducibility, tracking, and maintaining deployed models (though not explicitly required, it’s a plus if known).




And above all of this, an undying love for beer!




We dream big to create future with more cheers.

Show more "
Data Scientist – Fraud & Scams Detection,Deloitte,"Gurugram, Haryana, India",Gurugram,2025-06-06,https://in.linkedin.com/jobs/view/data-scientist-%E2%80%93-fraud-scams-detection-at-deloitte-4234129872?position=11&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=OItnOu7a8oy%2BdIDme8bXHw%3D%3D,"What impact will you make?







Every day, your work will make an impact that matters, while you thrive in a dynamic culture of inclusion, collaboration and high performance. As the undisputed leader in professional services, Deloitte is where you will find unrivaled opportunities to succeed and realize your full potential




Deloitte is where you will find unrivaled opportunities to succeed and realize your full potential.







The Team

Deloitte’s practice can help you uncover and unlock the value buried deep inside vast amounts of data. Our global network provides strategic guidance and implementation services to help companies manage data from disparate sources and convert it into accurate, actionable information that can support fact-driven decision-making and generate an insight-driven advantage. Our practice addresses the continuum of opportunities in business intelligence & visualization, data management, performance management and next-generation analytics and technologies, including big data, cloud, cognitive and machine learning. Learn more about Analytics and Information Management Practice




Position Title: Data Scientist – Fraud & Scams Detection

Role Type: Data Scientist / Model Developer

Division: Division or Business Unit, e.g., Financial Crime Analytics / Technology & Operations




Role Purpose: - The Data Scientist – Fraud & Scams Detection will be responsible for designing, developing, and deploying advanced machine learning models to detect and mitigate fraud in digital and card transactions. This role supports the transition from a third-party solution to an internally developed and managed fraud detection system. The successful candidate will play a key role across the full model lifecycle—from early-stage analysis and feature engineering through to deployment and post-production monitoring working closely within an agile squad environment.




Key Responsibilities

Design and develop fraud and scams detection models tailored to digital and card transaction data.
Replace existing third-party fraud detection solutions with internally developed models.
Define and test different ML approaches suitable for the fraud domain.
Lead feature engineering, feature selection, and hyperparameter tuning for model optimization.
Collaborate with business stakeholders, engineers, and squad members from initial discovery to deployment.
Articulate design choices, modeling approaches, and monitoring strategies clearly and effectively.
Deploy models into production using modern MLOps practices.
Maintain model accuracy, relevance, and compliance through ongoing monitoring and evaluation.




Key Performance Indicators (KPIs)

Successful deployment of fraud detection models with measurable accuracy and performance.
Reduction in false positives/negatives relative to the third-party benchmark.
Timely delivery of model milestones aligned to project timelines.
Evidence of collaboration and active contribution in agile squad setup.
Quality and robustness of documentation and monitoring processes.




Essential Experience

Proven experience in developing and deploying fraud detection or risk models in production environments.
Experience with end-to-end model development, including:
Algorithm selection
Feature engineering and selection
Model training and tuning
Deployment and post-deployment monitoring
Strong understanding of fraud patterns and digital transaction behaviors.
Hands-on experience working within agile teams or squads on data science delivery.




Technical & Functional Competencies

Required:
High proficiency in SQL, Python, PySpark
Strong understanding of version control using Git
Preferred:
Experience with Databricks
Familiarity with MLOps frameworks and production workflows




Soft Skills & Attributes

Analytical mindset with a strong problem-solving approach.
Ability to articulate complex data science concepts and decisions to non-technical stakeholders.
Proactive, self-driven, and accountable for delivering high-quality outcomes.
Strong communication and collaboration skills.
Comfortable working in fast-paced, evolving environments.




Qualification Requirements

Bachelor's or postgraduate degree in Computer Science, Statistics, Mathematics, Engineering, or a related quantitative field.







Our purpose Deloitte is led by a purpose: To make an impact that matters.

Every day, Deloitte people are making a real impact in the places they live and work. We pride ourselves on doing not only what is good for clients, but also what is good for our people and the

Communities in which we live and work—always striving to be an organization that is held up as a role model of quality, integrity, and positive change. Learn more about Deloitte's impact on the world

Show more "
Data Scientist,Visa,Greater Bengaluru Area,Greater Bengaluru Area,2025-08-05,https://in.linkedin.com/jobs/view/data-scientist-at-visa-4280080738?position=12&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=X8a6Tevh7ddHGGGZjpEHHw%3D%3D,"Data Scientist - Credit Card Analytics (3-5yrs)

Bangalore, India
Full-time
Job Family Group: Product Development

Company Description

Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid.

Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.

Job Description

Visa Consulting and Analytics (VCA) is Visa's consulting division, serving Visa's clients (including card issuers, acquirers, and merchants) and solving their strategic problems focused on improving performance and profitability. Drawing on our expertise in strategy consulting, payments, data analytics, marketing, operational and macroeconomics, VCA drives high impact and tangible financial results.

The individual will be part of VCA Data Science team, under Managed Services vertical and will be responsible for delivering data analytics projects with Visa client. The team is involved in a comprehensive range of analytics services for our client, that address unique challenges in areas such as strategic growth, cards profitability, product acquisitions, customer engagement and portfolio management.

What a Data Scientist, Visa Consulting & Analytics does at Visa:

The Data Scientist will be a member of VCA Data Science team in Asia Pacific and will report to the squad lead. This position will be embedded at client office and based in Bangalore.

The individual will be accountable for delivery and implementation of analytics strategies as well as high-impact solutions for the client. He/she will bring in deep expertise from credit cards and retail banking with a strong background in data analysis to solve complex problems and unlock business value.

Key responsibilities include:

Execute and deliver data analytics projects for the Visa client
Drive credit card portfolio strategies with the use of client data and/or other sources of data e.g. Visa data, third party etc.
Act as analytics advocate within our partners, advising teams and sharing best practices and case studies.
Continually look at the environment to challenge our assumptions around new sources of data, potential analytics partners, tools, talent, and infrastructure.
Explore leading methodologies, best practices and import successful methodologies from other international markets
Effectively interact with clients and manage internal/external stakeholder communication

Why this is important to Visa

As payments consulting arm of Visa, VCA is growing a team of highly specialized experts who can provide best-in-class payment expertise and data-driven strategies to clients. We’re building a high-performing team of data scientists, data analysts and statisticians helping major organizations adapt and evolve to meet the changes taking place in technology, finance, and commerce with cutting-edge, creative, and advanced analytic solutions. The purpose of the team is to help Visa’s clients grow their business and solve problems by providing consulting services using data.

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

We are looking for a motivated, analytical minded individual with a track record of using data and analytics to unlock business value. A successful candidate should have accumulated a variety of industry experience, be curious about banking and cards industry, should be results-driven and client-centric.




• Degree in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent

• Minimum 3+ years of analytics experience in applying statistical solutions to business problems

• Experience in card payments and/or retail banking domain

• Hands on experience with one or more data analytics/programming tools such as SAS/Hadoop/R/SQL/Python/Hive

• Outstanding problem-solving skills, with demonstrated ability to think creatively and strategically

• Presentation and data storytelling skills including strong hold on MS Excel and PowerPoint

• Self-motivated, results oriented individual with ability to handle multiple projects concurrently

• Experience in working closely with data science community

Additional Information

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Show more "
Machine Learning Engineer,Infosys,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-09,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-infosys-4281898086?position=13&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=S%2B3Kd2VFu%2BMGYW8BdRRL9A%3D%3D,"Preferred Qualifications:


Experienced in Agile way of working, manage team effort and track through JIRA
High Impact client communication
Domain experience in Retail, CPG and Logistics
Experience in Test Driven Development and experience in using Pytest frameworks, git version control, Rest APIs The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face. Roles & Responsibilities:
Understand the requirements from the business and translate it into an appropriate technical requirement.
Responsible for successful delivery of MLOps solutions and services in client consulting environments;
Define key business problems to be solved; formulate high level solution approaches and identify data to solve those problems, develop, analyze/draw conclusions and present to client.
Assist clients with operationalization metrics to track performance of ML Models
Help team with ML Pipelines from creation to execution
Guide team to debug on issues with pipeline failures
Understand and take requirements on Operationalization of ML Models from Data Scientist
Engage with Business / Stakeholders with status update on progress of development and issue fix
Setup Standards related to Coding, Pipelines and Documentation
Research on new topics, services and enhancements in Cloud Technologies EEO/About Us : About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.
Show more "
Data Scientist Engineer - IN,OPPO,"Gurugram, Haryana, India",Gurugram,2025-07-25,https://in.linkedin.com/jobs/view/data-scientist-engineer-in-at-oppo-4272010609?position=14&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=Z15e7JXnFtlfmx1LYsAC5A%3D%3D,"Responsible：

1. Responsible for enterprise-level data warehouse construction and big data task performance optimisation, responsible for data asset quality optimisation, asset governance and other work；

2. Responsible for the development of big data technology components or platform tools, technical difficulties, responsible for deployment, management and maintenance work.




Requirements：

1. Bachelor‘s degree or above in computer science, mathematics or related fields, with solid basic knowledge of computer systems;

2. Have a solid programming foundation, proficiency in C/C++/JAVA/Python at least one mainstream programming language;

3. Familiar with Hadoop/Kafka/starrocks/Flink and other one or more big data technologies and components.

4. Good learning ability and communication skills, as well as teamwork spirit




More Information：

1.Relocate to China for one year, and later be based in India.

2.Chinese communication skills are preferred but not mandatory.

3.1–3 years of work experience, with skills in SQL development or Java development; strong initiative and fast learner.

Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4282052980?position=15&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=Wugdp%2BYiOLu3Y1irSslssg%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Description

Job Title: Data Scientist – Predictive Forecasting

Location: Bangalore

Reporting to: Senior Manager Analytics

1) Purpose of the role

We are seeking a talented Data Scientist specializing in Statistical modelling, Predictive modelling, Time Series Forecasting to join our dynamic analytics team. The ideal candidate will have a strong background in statistical modeling and machine learning, with a focus on time series analysis. You will be responsible for developing predictive models for Business Cycles and Monthly Performance Monitoring, generating actionable insights from Forecasts, and driving business value through data-driven decision-making.




2) Key tasks & accountabilities




Develop and Implement Models:
Design and implement and Maintain time series forecasting models to predict key business metrics.
Utilize advanced statistical techniques and machine learning algorithms to improve model accuracy.
Data Analysis and Insight Generation:
Analyze large and complex datasets to identify trends, patterns, and anomalies.
Generate actionable insights that inform business strategies and operational improvements.
Collaborate with Cross-Functional Teams:
Work closely with deployment and development data scientists, and other stakeholders to understand business needs.
Communicate Findings:
Present analysis results and insights to stakeholders in a clear and concise manner.
Prepare reports, visualizations, and dashboards to communicate data findings.
Continuous Improvement:
Monitor model performance and implement enhancements as necessary.
Stay updated with the latest developments in data science, machine learning, and time series forecasting.




3) Qualifications, Experience, Skills




Level of educational attainment required.

Bachelor’s or master’s degree in data science, Statistics, Mathematics, Computer Science, or a related field.




Previous work experience

Minimum of 2 years of experience in data science or a related role.
Proven experience with time series analysis and forecasting techniques is a plus




Technical Skills required




Python (Data Structures, Control Flow, OOPs, Modules and Packages, Exception Handling, VENV)
MLOPs Fundamentals (Model Development, VCS, CI, CD, Serving, Monitoring & Logging, Registry, Data and Model Lineage)
Experience with machine learning frameworks (e.g., scikit-learn, TensorFlow is a plus).
Familiarity with data visualization tools (e.g., Power BI, matplotlib, plotly, streamlet).
Data Analysis Tools - Pandas, Excel (Pivot Tables, Charts, Macros, Conditional Formatting, Shortcuts)
Insights presentation - PowerPoint
Version Control System (Git) - Basic Commands, Branching and Merging, Pull Requests & Code Reviews




Other Skills required




Excellent problem-solving and analytical skills.
Strong communication and presentation abilities.
Ability to work collaboratively in a team environment.




And above all of this, an undying love for beer!




We dream big to create future with more cheers.

Show more "
"ML Engineer ( Full Time, Remote)",Hike,India,India,2025-07-07,https://in.linkedin.com/jobs/view/ml-engineer-full-time-remote-at-hike-4262189289?position=16&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=aBrlDM7E16qjhfERjRMgaA%3D%3D,"To know more, check out work.hike.in.

At Hike, we're building the Hike Gaming Nation 🎮 📲 💰

In the fast-paced world of gaming, AI is our edge. As a ML Engineer, you're not just building models — you're powering the intelligence behind the Hike Gaming Nation. Your work turns cutting-edge research into real-time, scalable systems that make gameplay smarter, faster, and more immersive. You don't just build AI—you use it every day. You're an AI-first thinker, leveraging state-of-the-art tools and intelligent systems to move faster, build smarter, and continuously push boundaries.

Introduction 📖



At Hike, we're revolutionizing gaming and tech by blending innovation and immersive experiences. With our foray into Web3 gaming, we're exploring uncharted territories to create products that redefine fun and ownership. Join us as we make waves in this exciting new frontier.

Hike Code 📝( Our core cultural values )

The Hike Code is our value system. We aim to live and breathe by these every single day. They inspire us to be the best we can be and they are weaved into every part of our decision making, how we review performance and much more. We have 9 core values{​{:}

}
Top Talent in Every Role → Both a quest for greatness & shared values are important to us 🦸‍♂
️
Owner not a Renter → Proactive & radically responsible. Everyone is an owner ?
?
Pro-Sports Team → Strength-based, results driven with a ""team-first"" attitude ⚽
️
Customer Obsession → We exist to delight our customers ?
?
Think Deeply & Exercise Good Judgement → Clear mind, obsession to simplify & data-informed 🙇‍♀
️
Build & Make Magic → Courage to walk into the unknown and pioneer new fronts ?
?
Be Insatiably curious & keep Improving → Curiosity to acquire new perspectives, quickly 👨‍?
?
Move Fast & Be Dynamic → Ruthless prioritization & move fast 🙋‍♂
️
Dream Big, Be Bold & Think Long Term → Courage to climb big mountains ?
?

Skills & experience we're looking for 👨‍?

?
1-3  years of relevant industry experience | Top Talent in Every Rol
e
B.tech/MS from a top Tier institute | Top Talent in Every Rol
e
Strong programming abilities, especially Python Scientific & Deep Learning Stack (Numpy, Pandas, Pytorch/Tensorflow, Transformers, Diffusers etc.) | Top Talent in Every Rol
e
Solid foundations in Data-Structures, Algorithms, Design & Architecture | Top Talent in Every Rol
e
Exposure to Deep Learning, preferably building Generative AI applications | Top Talent in Every Rol
e
Experience working with LLMs such as Open AI GPTs, LLaMA & Claude with use cases taken to production. Preferably, experience working with SLMs and Mobile Language Models. | Top Talent in Every Rol
e
Strong AI-first mindset — you actively use AI tools (e.g., GitHub Copilot, GPT, LangChain) to enhance daily workflows, improve velocity, and automate repetitive dev tasks.  | Be Insatiably curious & keep Improvin
g
Ability to work in a fast-paced environment without compromising on quality I Move Fast & Be Dynami
c
Ability to be self-directed and learn quickly, coupled with a strong desire to stay on top of latest developments in the field of AI | Be Insatiably curious & keep Improvin
g
Teamplayer with excellent organizational, communication and interpersonal skills I Pro Sports Tea
m
Excited about building cutting edge AI products in the fields of Computer Vision, Graphics, Audio, AR/VR etc., preferably with experience, in at least one of the areas | Be Insatiably curious & keep Improvin
g

You will ?

?
Strategy → Build deep learning models in the areas of computer-vision, graphics & audi
o
Strategy → Own end to end Quality & Performance Metrics for AI deployment pipelines{​{:}} from learning to inference to renderi
n
g Operations → Create deployment pipelines for server-side as well as on-device real-time inferen
c
e Operations → Optimize ML inference pipelines to render high quality 3D graphics across multiple clients ranging from Android Native to game-engines like Uni
t
y Collaboration → Collaborate in a cross-functional setup including Artists, Engineers & Scientists to translate cutting-edge research (AI, Art & Graphics/Multimedia) into high quality user-experienc
e
s Operation → Leverage AI not just in product development but in your own workflow — from rapid prototyping with LLMs to automating test generation, documentation, and internal tooli
n

g 💰 Benefits → We have tremendous benefits & perks. Check out work.hike.in to know mo



re
Show more "
Data Scientist 1,Uber,"Bengaluru, Karnataka, India",Bengaluru,2025-08-06,https://in.linkedin.com/jobs/view/data-scientist-1-at-uber-4281428228?position=17&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=8GKkRz88aeQzd4Chemh4eg%3D%3D,"About The Role

Communication Platform enables all the messages (SMS OTP, Whatsapp, Notifications, Voice Call, Chat) among our users. This role will help improve our communications products in improving the Deliverability, reliability and reach of the messages by optimising the cost at the same time. Improving effieciency of communications among our users will helop improve trip conversion and in turn revenue for the organization.

What The Candidate Will Need / Bonus Points

---- What the Candidate Will Do ----


Build scalable analytical frameworks to support product analytics for Uber's Communications Platform
Own new product experimentation including plan creation, roll-out, and monitoring
Be an invaluable partner to cross-functional teams such as engineering, product management, various data teams to deploy data quality across critical pipelines and to set up processes to triage data issues
Develop and track metrics and reporting functions to measure and monitor products performance on our platform
Effectively and proactively communicate insights and drive projects to drive towards team goals
Proactively seek out opportunities to build new solutions to tackle challenges
Create and drive data quality standards and frameworks to ensure inclusion into pipeline engineering efforts


Basic Qualifications


2+ years of experience (Bachelor) OR 1+ years of experience (Masters) in a data-focused role such as product analytics, business analytics, business operations, or data science
Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience
Experience in programming and/or query languages
Past experience with a Product / Tech company serving millions of customers on multiple platforms and countries


Preferred Qualifications


SQL mastery. Write efficient and complex code in SQL
Experience in Python/R and experimentation, A/B testing, and statistical modelling
Experience in Payments or Compliance with a Product / Tech company
Proven ability to handle and visualise large datasets, explore and utilize raw data feeds
Love of data - you just go get the data you need and turn it into an insightful story.
A well-organized, structured approach to problem-solving
Strong sense of ownership, accountability, and entrepreneurial spirit
Great communicator, problem-solver & confident in decision making
Independent & autonomous, while still a strong teammate
Enthusiastic, self-starting and thrives in changing, agile environments
Show more "
Python Backend Engineer – ML,CloudSEK,"Bengaluru, Karnataka, India",Bengaluru,2025-07-11,https://in.linkedin.com/jobs/view/python-backend-engineer-%E2%80%93-ml-at-cloudsek-4265142270?position=18&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=6bdjkt2bhG4eah21%2FHycRg%3D%3D,"WHO ARE WE?

We are a bunch of super enthusiastic, passionate, and highly driven people, working to achieve a common goal! We believe that work and the workplace should be joyful and always buzzing with energy!

CloudSEK, one of India’s most trusted Cyber security product companies, is on a mission to build the world’s fastest and most reliable AI technology that identifies and resolves digital threats in real-time. The central proposition is leveraging Artificial Intelligence and Machine Learning to create a quick and reliable analysis and alert system that provides rapid detection across multiple internet sources, precise threat analysis, and prompt resolution with minimal human intervention.

Founded in 2015, headquartered at Singapore, we are proud to say that we’ve grown at a frenetic pace and have been able to achieve some accolades along the way, including:

CloudSEK’s Product Suite:


CloudSEK XVigil constantly maps a customer’s digital assets, identifies threats and enriches them with cyber intelligence, and then provides workflows to manage and remediate all identified threats including takedown support.
A powerful Attack Surface Monitoring tool that gives visibility and intelligence on customers’ attack surfaces. CloudSEK's BeVigil uses a combination of Mobile, Web, Network and Encryption Scanners to map and protect known and unknown assets.
CloudSEK’s Contextual AI SVigil identifies software supply chain risks by monitoring Software, Cloud Services, and third-party dependencies.


Key Milestones:


2016: Launched our first product.
2018: Secured Pre-series A funding.
2019: Expanded operations to India, Southeast Asia, and the Americas.
2020: Won the NASSCOM-DSCI Excellence Award for Security Product Company of the Year.
2021: Raised $7M in Series A funding led by MassMutual Ventures.
Awards & Recognition: Won NetApp Excellerator's ""Best Growth Strategy Award,"" CloudSEK XVigil joined NVIDIA Inception Program, and won the NASSCOM Emerge 50 Cybersecurity Award.
2025: Secured $19 million in funding led by Tenacity Ventures, Commvault.


Roles and Responsibilities:


Writing clean, efficient, and well-documented Python code
Develop back-end components to improve overall performance and system robustness.
Maintaining and updating existing systems
Collaborating with team members to identify, design, and implement new features
Participating in code reviews to ensure code quality and consistency


Required Skills:


Great programming skills with expertise in Python
Skills to build highly scalable and efficient backend services
Good knowledge of SQL and experience in working with relational databases.
Experience in working with NoSQL database programs such as MongoDB.
Hands-on experience in at least one Python web framework such as FastAPI or Flask.
Working knowledge of a message queuing system like RabbitMQ/ SQS? Kafka
Experience with Docker


Good to Have:


Experience working with kubernetes
Experience with AWS cloud services.
Hands on skills in Applied-ML


Benefits of Joining CloudSEK

We provide an environment where you can develop and enhance your skills while delivering meaningful work that matters. You’ll be rewarded a competitive salary as well as a full spectrum of generous perks and incentives which include:


Flexible working hours.
Food, unlimited snacks and drinks are all available while at office.


And, the finest part is yet to come! Every now and then we ensure to unwind and have a good time together, which involves games, fun, and soulful music. Feel free to show off your artistic side here!
Show more "
ML Software Engineer,eBay,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/ml-software-engineer-at-ebay-4264435923?position=19&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=OzPXgo1y1zAWT9M5ih46lA%3D%3D,"At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

About The Team And Role

The Compliance Engineering team at eBay is focused on prohibited, restricted, and counterfeit compliance detection is dedicated to ensuring that eBay’s marketplace adheres to all relevant regulations and internal policies.

The team develops and maintain advanced, AI-driven tools and scalable backend systems that automatically identify and assess items listed on the platform. By applying sophisticated data models, machine learning algorithms, and rules-based engines, they detect products that may be illegal, harmful, non-compliant with trade regulations, or counterfeit.

Overall, this Compliance Engineering team plays a crucial role in maintaining trust in eBay’s platform, safeguarding customers, and upholding the company’s dedication to a fair, safe, and legally compliant marketplace.

What You Will Accomplish


Build large-scale applications, low-latency APIs, data pipelines, and foundational architectures to support eBay’s business operations and customer experiences.
Design and implement highly configurable, metadata-driven platforms to enable seamless ingestion of attributes, rules, models, policies, and derived aggregates.
Develop machine learning models and Gen AI tools to generate insights and improve customer experiences across eBay.
Partner with architects, business leaders, and industry experts to devise strategies and scalable solutions.
Be responsible for the entire software lifecycle, including design, development, testing, and experimentation.
Mentor and lead junior team members by setting examples and guiding them toward success.



What You Will Bring


Prefer Technical degree with 3-5+ years of relevant software development experience.
Strong hands on Machine Leaning experience, AI/ML/Gen AI, LLM's and proven experience in building and running AI/ML/GenAI models in production environments.
Outstanding programming skills in Java, Scala, and Python, with hands-on experience in frameworks like PyTorch and TensorFlow.
Proven experience with APIs and Distributed Systems, building and consuming horizontally scalable RESTful APIs, GraphQL, and distributed systems.
Hands-on experience with technologies like Spark, Flink, and Kafka with practical experience in their use.
Strong understanding of SQL, NoSQL, and sophisticated data modeling techniques.
Hands-on experience with the Hadoop ecosystem (HDFS, MapReduce, Hive, Spark) for building and optimizing large-scale data solutions.



Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.
Show more "
Data Scientist,HCLTech,"Bengaluru, Karnataka, India",Bengaluru,2025-07-17,https://in.linkedin.com/jobs/view/data-scientist-at-hcltech-4266957142?position=20&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=AvGovH%2BWXbYs2hsLolJwfQ%3D%3D,"Hiring for Data Scientist- AI Developer in HCLTech




Interested candidate share your resume at selvakumari.b@hcltech.com with below format




EXP- 5 to 15Years

Location- Bangalore, Chennai, Noida, Hyderabad, Pune







Name:




Contact Number:




Email ID:




Current Location:




Preferred Location:




Total Experience:




Relevant Experience:




Current Organization:




Current CTC:




Expected CTC:




Notice Period:




Are you available for Interview this Weekend ?




*Required Skills:*




- *Technical Skills*: Proficiency in programming languages like Python, R, , and experience with machine learning algorithms, Deep learning

-Strong foundation in statistics, mathematics,

- *Communication*: Ability to communicate complex concepts clearly and effectively to stakeholders, and tailor messages for business applicability.

- *Leadership*: Strong leadership and management skills, with the ability to build relationships with stakeholders and advocate for data-driven decision-making.

Show more "
Data Scientist,LTIMindtree,Greater Bengaluru Area,Greater Bengaluru Area,2025-07-29,https://in.linkedin.com/jobs/view/data-scientist-at-ltimindtree-4273716987?position=21&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=3rbziJxVAhboM78P9CdcJQ%3D%3D,"Role : Data Scientist

Experience : 5 years to 8 years

Location : Hyderabad, Pune, Bangalore




Job Description:




Mandatory Skills :Machine Learning, Python




Programming Tools Python Pandas NumPy Matplotlib Seaborn Scikit learn SQL complex queries joins CTEs window functions Git
Data Analysis Visualization Exploratory Data Analysis EDA trend and correlation analysis hypothesis testing dashboards Power BI Tableau storytelling with data
Databases Data Handling SQL Server MySQL basic knowledge of Spark BigQuery Hive is a plus
Statistics ML Foundational Descriptive and inferential statistics regression classification clustering KMeans model evaluation metrics accuracy precision recall AUC over fitting under fitting cross validation
LLMAI Exposure
Familiarity with prompt engineering OpenAI APIs basic usage of GPT models for data text automation awareness of LLM limitations and applications in analytics
Soft Skills
Strong problem solving ability attention to detail stakeholder communication ability to translate business problems into data solutions
Experience Highlights
Conducted in depth data analysis to uncover trends patterns and anomalies that informed strategic decisions across product marketing and operations teams
Designed and implemented scalable data pipelines and automated data workflows using Python and SQL
Developed and maintained analytical models and dashboards to track key business metrics and performance indicators
Applied statistical methods and machine learning techniques to solve real world business problems such as forecasting segmentation and performance optimization
Collaborated with stakeholders to gather requirements translate business questions into analytical approaches and communicate findings with clarity
Explored the use of LLMs eg OpenAI GPT for enhancing internal workflows and accelerating data driven tasks such as querying summarization and content generation

Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-09,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4282056300?position=22&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=hBNL4xlpre4ftXItEclzBg%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Title: Data Scientist

Location: Bangalore

Reporting to: Manager- Analytics/ Senior Manager-Analytics




1. Purpose of the role




Contributing to the Data Science efforts of AB InBevʼs global non-commercial analytics capability of Procurement Analytics. Candidate will be required to contribute and may also need to guide the DS team staffed on the area and assess the efforts required to scale and standardize the use of Data Science across multiple ABI markets




2. KEY TASKS AND ACCOUNTABILITIES




Understand the business problem and translate that to an analytical problem; participate in the solution design process.
Manage the full AI/ML lifecycle, including data preprocessing, feature engineering, model training, validation, deployment, and monitoring.
Develop reusable and modular Python code adhering to OOP (Object-Oriented Programming) principles.
Design, develop, and deploy machine learning models into production environments on Azure.
Collaborate with data scientists, software engineers, and other stakeholders to meet business needs.
Ability to communicate findings clearly to both technical and business stakeholders.




3. Qualifications, Experience, Skills




Level of educational attainment required (1 or more of the following)

B. Tech /BE/ Masters in CS/IS/AI/ML




Previous work experience required

Minimum 3 years of relevant experience




Technical skills required




Must Have

Strong expertise in Python, including advanced knowledge of OOP concepts.
Exposure to AI/ML methodologies with a previous hands-on experience in ML concepts like forecasting, clustering, regression, classification, optimization, deep learning , NLP using Python
Solid understanding of GenAI concepts and experience in Prompt Engineering and RAG
Experience with version control tools such as Git.
Consistently display an intent for problem solving
Strong communication skills (vocal and written)
Ability to effectively communicate and present information at various levels of an organization




Good To Have

Preferred industry exposure in CPG and experience of working in the domain of Procurement Analytics
Product building experience would be a plus
Familiarity with Azure Tech Stack, Databricks, ML Flow in any cloud platform
Experience with Airflow for orchestrating and automating workflows
Familiarity with MLOPS and containerization tools like Docker would be plus.




Other Skills required

Passion for solving problems using data
Detail oriented, analytical and inquisitive
Ability to learn on the go
Ability to work independently and with others




We dream big to create future with more cheers

Show more "
Data Scientist,LTIMindtree,"Bengaluru, Karnataka, India",Bengaluru,2025-08-10,https://in.linkedin.com/jobs/view/data-scientist-at-ltimindtree-4282455821?position=23&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=GP%2FEkDeb2XK2MeA8iRO30w%3D%3D,"Job Description

We are seeking a talented AI Engineer with a strong background in signal processing vibration analysis and acousticnoise control The ideal candidate will have experience in deploying AI solutions on edge and IoT devices This role will involve designing developing and implementing AI algorithms to process and analyze various signal types and control noise in realtime applications Experience with Generative AI and Predictive Analytics particularly within the Oil Gas OG and Manufacturing sectors is a plus




Key Responsibilities




Develop and implement AI algorithms for signal processing vibration analysis and acousticnoise control

Design and deploy AI models on edge and IoT devices

Collaborate with crossfunctional teams to integrate AI solutions into existing systems and products

Perform data analysis and interpretation to improve and optimize AI models

Work on realtime data processing and ensure efficient deployment on resourceconstrained devices

Conduct research and stay updated on the latest advancements in AI signal processing noise control Generative AI and Predictive Analytics

Troubleshoot and resolve issues related to AI models and deployment on edge devices




Qualifications

Bachelors or Masters degree in Electrical Engineering Computer Science Mechanical Engineering or a related field

Proven experience in signal processing vibration analysis and acousticnoise control

Strong programming skills in Python MATLAB or similar languages

Experience with AI frameworks and libraries such as TensorFlow PyTorch or similar

Knowledge of deploying AI models on edge and IoT devices

Familiarity with microcontroller programming and embedded systems

Strong analytical and problem solving skills

Excellent communication and teamwork abilities

Experience with Generative AI and Predictive Analytics

Knowledge of the Oil Gas OG and Manufacturing sectors is a plus

Show more "
Data Scientist- Across PAN India,Capgemini Engineering,"Bengaluru, Karnataka, India",Bengaluru,2025-07-11,https://in.linkedin.com/jobs/view/data-scientist-across-pan-india-at-capgemini-engineering-4228162369?position=24&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=DFA7Z%2FBXAfjoLa5AZJMfaw%3D%3D,"Position Title: Data Scientist




Company Overview: Capgemini Engineering is a global leader in engineering services, bringing together a worldwide team of engineers, scientists, and architects to assist the most innovative companies in unleashing their potential.




Position Overview: We are seeking a skilled Data Scientist with expertise in Cognite Data Fusion, data modelling, Unified Namespace (UNS), ontologies, and the identification of data products and datasets. The ideal candidate will have a strong background in developing and implementing data science projects, analyzing large and complex data sets, and driving data-driven decision-making across the organization




Key Responsibilities:




Solution Development: Design, implement, and deploy scalable data solutions utilizing Cognite Data Fusion, focusing on data modeling, UNS, and ontologies to address industry-specific challenges.​
Data Analysis: Analyze large and complex data sets to identify trends, insights, and opportunities, supporting solution development and business strategies.​
Collaboration: Collaborate with cross-functional teams to understand data needs and translate them into data science solutions, ensuring seamless integration and operationalization of digital solutions across various domains.
Client Engagement: Engage with clients to understand their business objectives, lead discovery workshops, and provide expert guidance on data-driven strategies and potential challenges.​
Visualization: Develop dashboards and visualizations using tools such as Power BI, Grafana, or web development frameworks like Plotly Dash and Streamlit to effectively communicate data insights.​
Mentorship: Provide guidance and mentorship to junior team members, promoting best practices in data science and software development.​




Qualifications:

Educational Background: Master’s or PhD degree in a quantitative field.​
Experience: Minimum of 2 years of experience in data science, with a strong background in developing analytical solutions within domains such as pharma, oil and gas, manufacturing, or power & utilities.​
Technical Skills: Proficiency in Python and its data ecosystem (pandas, numpy), machine learning libraries (scikit-learn, keras), and experience with SQL.​
Visualization Tools: Experience with data visualization tools like Power BI, Grafana, Tableau, or web development frameworks such as Plotly Dash and Streamlit.​
Software Practices: Strong understanding of software development practices, including version control (e.g., Git), automated testing, and documentation.​
Cloud Platforms: Experience with cloud services such as GCP, Azure, or AWS is advantageous.​
Domain Knowledge: Familiarity with industrial data management concepts, including Unified Namespace (UNS), ontologies, and data product identification.​
Communication Skills: Excellent communication and collaboration skills, with the ability to work with cross-functional teams and stakeholders.​
Leadership: Demonstrated ability to lead projects and mentor junior team members.​




Preferred Qualifications:

Industry Expertise: Experience serving as a domain expert on internal or customer projects within relevant industries.​
Cloud Deployment: Experience deploying models and solutions in production environments using cloud infrastructure.​
Continuous Learning: Willingness to stay updated with the latest developments in data science and related technologies.​

Show more "
Machine Learning Engineer,Adobe,"Bengaluru East, Karnataka, India",Bengaluru East,2025-07-30,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-adobe-4272843897?position=25&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=AZAVXxKNjRgN36dJRAos9Q%3D%3D,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

The Opportunity

Join our Experience Intelligence team as a Generative AI and LLM Specialist, where you'll contribute to building a brand new ad intelligence platform. In this role, you will develop innovative AI models focused on ad creative intelligence, using your expertise in LLMs and VLMs, including fine-tuning and Retrieval-Augmented Generation (RAG). This position is ideal for professionals passionate about working on the full lifecycle of generative AI-enabled platform capabilities, from conceptualization and experimentation to implementation and execution, ensuring a robust and scalable system.

What you'll Do


Build and Innovate: Design, fine-tune and deploy generative AI models with an eye on generalisation for customer use cases in a multi-tenant environment. Have an Ability to deeply understand product requirements and gaps and design solutions that meet those needs.
Quality Assurance: Conduct detailed testing of AI-generated content to ensure alignment with quality standards and suitability for the intended audience. Identify patterns of errors or biases and work to mitigate these issues.
Standout Colleague: Work effectively with all collaborators to understand product and engineering needs thoroughly.
Eager Learner: Keep abreast of the latest AI/ML trends, tools, and standard methodologies to apply new knowledge for improving project outcomes.
Ethics First: Champion ethical AI development, from bias mitigation to privacy protection.


What you need to succeed

Relevant Degree or equivalent experience: Bachelor’s or advanced degree in Computer Science, AI, ML, or related fields

Practical Experience: 2-4 yrs total experience in ML /Deep Learning with at least 2 years experience in Generative AI (Fine-tuning LLM, RAG, Agentic AI etc.)

Programming Proficiency: Proven Python skills and AI/ML tools (e.g., TensorFlow, PyTorch).

Tech-Savvy Foundations: Exposure to software engineering practices.

Problem Solver: Demonstrated ability to tackle challenges with innovative solutions.

Communicator: Strong skills in articulating ideas and collaborating with various teams.

Research Attitude: A curiosity driven approach to exploring new applications of generative AI is valued.

Emerging Leader: Show potential for technical leadership and project guidance.

Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Show more "
Machine Learning Engineer,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-ab-inbev-gcc-india-4279258468?position=26&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=4gI4VjPLtxp7dTowqSIEpw%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?

We Need You.




Job Description

Job Title: Junior Data Scientist

Location: Bangalore

Reporting to: Senior Manager – Analytics




1. Purpose of the role

The Global GenAI Team at Anheuser-Busch InBev (AB InBev) is tasked with constructing competitive solutions utilizing GenAI techniques. These solutions aim to extract contextual insights and meaningful information from our enterprise data assets. The derived data-driven insights play a pivotal role in empowering our business users to make well-informed decisions regarding their respective products. In the role of a Machine Learning Engineer (MLE), you will operate at the intersection of:




LLM-based frameworks, tools, and technologies
Cloud-native technologies and solutions
Microservices-based software architecture and design patterns As an additional responsibility, you will be involved in the complete development cycle of new product features, encompassing tasks such as the development and deployment of new models integrated into production systems. Furthermore, you will have the opportunity to critically assess and influence the product engineering, design, architecture, and technology stack across multiple products, extending beyond your immediate focus.




2. Key tasks & accountabilities

Large Language Models (LLM):

Experience with LangChain, LangGraph
Proficiency in building agentic patterns like ReAct, ReWoo, LLMCompiler

Multi-modal Retrieval-Augmented Generation (RAG):

Expertise in multi-modal AI systems (text, images, audio, video)
Designing and optimizing chunking strategies and clustering for large data processing

Streaming & Real-time Processing:

Experience in audio/video streaming and real-time data pipelines
Low-latency inference and deployment architectures

NL2SQL:

Natural language-driven SQL generation for databases
Experience with natural language interfaces to databases and query optimization

API Development:

Building scalable APIs with FastAPI for AI model serving

Containerization & Orchestration:

Proficient with Docker for containerized AI services
Experience with orchestration tools for deploying and managing services

Data Processing & Pipelines:

Experience with chunking strategies for efficient document processing
Building data pipelines to handle large-scale data for AI model training and inference

AI Frameworks & Tools:

Experience with AI/ML frameworks like TensorFlow, PyTorch
Proficiency in LangChain, LangGraph, and other LLM-related technologies

Prompt Engineering:

Expertise in advanced prompting techniques like Chain of Thought (CoT) prompting, LLM Judge, and self-reflection prompting
Experience with prompt compression and optimization using tools like LLMLingua, AdaFlow, TextGrad, and DSPy
Strong understanding of context window management and optimizing prompts for performance and efficiency




3. Qualifications, Experience, Skills

Level of educational attainment required (1 or more of the following)

Bachelor's or masterʼs degree in Computer Science, Engineering, or a related field.

Previous work experience required

Proven experience of 3+ years in developing and deploying applications utilizing Azure OpenAI and Redis as a vector database.

Technical skills required

Solid understanding of language model technologies, including LangChain, OpenAI Python SDK, LammaIndex, OLamma, etc.
Proficiency in implementing and optimizing machine learning models for natural language processing.
Experience with observability tools such as mlflow, langsmith, langfuse, weight and bias, etc.
Strong programming skills in languages such as Python and proficiency in relevant frameworks.
Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes).




And above all of this, an undying love for beer!

We dream big to create future with more cheer

Show more "
Data Scientist,LTIMindtree,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-07-21,https://in.linkedin.com/jobs/view/data-scientist-at-ltimindtree-4268301803?position=27&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=2A8hRtY9pAhxRhLYvQMFDA%3D%3D,"Job Details:

Experience - 4 to 12 yrs

Mandatory Skills - Data Science, Classical Machine Learning, Python.

Location - Mumbai, Pune, Bangalore, Chennai, Hyderabad and Kolkata location.

Notice - Immediate to 30 days.




Data Scientist Python and Notebooks

Responsibilities

We are seeking a talented Data Scientist to join our team and drive datadriven decisionmaking across our organization The ideal candidate will have a strong background in statistical analysis machine learning and data visualization with experience working with large datasets in a Teradata environment




Design and implement endtoend data science projects from problem definition to model deployment
Develop and apply advanced machine learning algorithms and statistical models to solve complex business problems
Collaborate with crossfunctional teams to identify opportunities for datadriven improvements
Conduct exploratory data analysis and feature engineering to prepare data for modeling
Create and maintain dashboards and reports to communicate insights to stakeholders
Optimize data collection procedures and ensure data quality
Stay current with the latest advancements in data science and machine learning techniques
Implement and maintain onpremise AIML solutions
Apply Explainable AI techniques to enhance model interpretability and transparency




Requirements

Strong proficiency in Python R and SQL
Experience with Teradata and data lakelakehouse architectures
Expertise in machine learning algorithms statistical modeling and data visualization
Familiarity with big data technologies eg Hadoop Spark
Excellent problemsolving and communication skills
Experience with version control systems eg Git
Experience with onpremise AIML solutions
Knowledge of Explainable AI methods and their practical applications.

Show more "
Data Scientist,PepsiCo,"Hyderabad, Telangana, India",Hyderabad,2025-07-21,https://in.linkedin.com/jobs/view/data-scientist-at-pepsico-4270656480?position=28&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=yJbVHIyBZRl%2B9JA9sttsvQ%3D%3D,"We are PepsiCo

PepsiCo is one of the world's leading food and beverage companies with more than $79 Billion in Net Revenue and a global portfolio of diverse and beloved brands. We have a complementary food and beverage portfolio that includes 22 brands that each generate more than $1 Billion in annual retail sales. PepsiCo's products are sold in more than 200 countries and territories around the world. PepsiCo's strength is its people. We are over 250,000 game changers, mountain movers and history makers, located around the world, and united by a shared set of values and goals.




We believe that acting ethically and responsibly is not only the right thing to do, but also the right thing to do for our business. At PepsiCo, we aim to deliver top-tier financial performance over the long term by integrating sustainability into our business strategy, leaving a positive imprint on society and the environment. We call this Winning with Pep+ Positive. For more information on PepsiCo and the opportunities it holds, visit www.pepsico.com.

PepsiCo Data Analytics & AI Overview:

With data deeply embedded in our DNA, PepsiCo Data, Analytics and AI (DA&AI) transforms data into consumer delight. We build and organize business-ready data that allows PepsiCo’s leaders to solve their problems with the highest degree of confidence. Our platform of data products and services ensures data is activated at scale. This enables new revenue streams, deeper partner relationships, new consumer experiences, and innovation across the enterprise.

The Data Science Pillar in DA&AI will be the organization where Data Scientist and ML Engineers report to in the broader D+A Organization. Also DS will lead, facilitate and collaborate on the larger DS community in PepsiCo. DS will provide the talent for the development and support of DS component and its life cycle within DA&AI Products. And will support “pre-engagement” activities as requested and validated by the prioritization framework of DA&AI.




Data Scientist-Gurugram and Hyderabad




The role will work in developing Machine Learning (ML) and Artificial Intelligence (AI) projects. Specific scope of this role is to develop ML solution in support of ML/AI projects using big analytics toolsets in a CI/CD environment. Analytics toolsets may include DS tools/Spark/Databricks, and other technologies offered by Microsoft Azure or open-source toolsets. This role will also help automate the end-to-end cycle with Machine Learning Services and Pipelines.

Responsibilities

Delivery of key Advanced Analytics/Data Science projects within time and budget, particularly around DevOps/MLOps and Machine Learning models in scope
Collaborate with data engineers and ML engineers to understand data and models and leverage various advanced analytics capabilities
Ensure on time and on budget delivery which satisfies project requirements, while adhering to enterprise architecture standards
Use big data technologies to help process data and build scaled data pipelines (batch to real time)
Automate the end-to-end ML lifecycle with Azure Machine Learning and Azure/AWS/GCP Pipelines.
Setup cloud alerts, monitors, dashboards, and logging and troubleshoot machine learning infrastructure
Automate ML models deployments




Qualifications




Minimum 3years of hands-on work experience in data science / Machine learning
Minimum 3year of SQL experience
Experience in DevOps and Machine Learning (ML) with hands-on experience with one or more cloud service providers
BE/BS in Computer Science, Math, Physics, or other technical fields.
Data Science – Hands on experience and strong knowledge of building machine learning models – supervised and unsupervised models
Programming Skills – Hands-on experience in statistical programming languages like Python and database query languages like SQL
Statistics – Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators
Any Cloud – Experience in Databricks and ADF is desirable
Familiarity with Spark, Hive, Pig is an added advantage
Model deployment experience will be a plus
Experience with version control systems like GitHub and CI/CD tools
Experience in Exploratory data Analysis
Knowledge of ML Ops / DevOps and deploying ML models is required
Experience using MLFlow, Kubeflow etc. will be preferred
Experience executing and contributing to ML OPS automation infrastructure is good to have
Exceptional analytical and problem-solving skills
Show more "
Data Scientist,Circle K,"Gurugram, Haryana, India",Gurugram,2025-08-02,https://in.linkedin.com/jobs/view/data-scientist-at-circle-k-4278120180?position=29&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=NUeYbx5nvANBF%2BoSoQBKvg%3D%3D,"Job Description

Circle K (Part of Alimentation Couche-Tard Inc., (ACT)) is a global Fortune 200 company. A leader in the convenience store and fuel space, it has a footprint across 31 countries and territories. Circle K India Data & Analytics team is an integral part of ACT’s Global Data & Analytics Team, and the Data Scientist will be a key player on this team that will help grow analytics globally at ACT. This is a unique opportunity to be a part of an experienced team of data scientists and analysts within a large organization.

The Data Scientist is responsible for delivering advanced analytics and insights that drive business results and operational excellence to our dynamic and forward-thinking Merchandise team in Europe. The ideal candidate should possess both technical capabilities as well as commercial savviness, should be able to drive independent analysis as well as work effectively in a group.

About The Role

We are looking for an individual who is a proven problem solver with exceptional critical thinking ability. The candidate should have a high sense of curiosity and be comfortable with ambiguity when faced with a difficult challenge. Additionally, the candidate should possess excellent communication skills, the ability to collaborate with others, and simply and effectively communicate complex concepts with a non-technical audience.

Roles & Responsibilities

Analytics (Data & Insights)


Evaluate performance of categories and activities, using proven and advanced analytical methods
Support stakeholders with actionable insights based on transactional, financial or customer data on an ongoing basis
Oversee the design and measurement of experiments and pilots
Initiate and conduct advanced analytics projects such as clustering, forecasting, causal impact
Build highly impactful and intuitive dashboards that bring the underlying data to life through insights


Operational Excellence


Improve data quality by using and improving tools to automatically detect issues
Develop analytical solutions or dashboards using user-centric design techniques in alignment with ACT’s protocol
Study industry/organization benchmarks and design/develop analytical solutions to monitor or improve business performance across retail, marketing, and other business areas


Stakeholder Management


Work with Peers, Functional Consultants, Data Engineers, and cross-functional teams to lead / support the complete lifecycle of analytical applications, from development of mock-ups and storyboards to complete production ready application
Provide regular updates to stakeholders to simplify and clarify complex concepts, and communicate the output of work to business
Create compelling documentation or artefacts that connects business to the solutions
Coordinate internally to share key learning with other teams and lead to accelerated business performance
Be an advocate for a data-driven culture among the stakeholders


Job Requirements

Education


A higher degree in an analytical discipline like Finance, Mathematics, Statistics, Engineering, or similar


Relevant Experience


Experience: 3-4 years for Data Scientist
Relevant working experience in a quantitative/ applied analytics role
Experience with programming, and the ability to quickly pick up handling large data volumes with modern data processing tools, e.g. by using Spark / SQL / Python
Excellent communication skills in English, both verbal and written


Behavioural Skills


Delivery Excellence
Business disposition
Social intelligence
Innovation and agility


Knowledge


Functional Analytics (Retail Analytics, Supply Chain Analytics, Marketing Analytics, Customer Analytics, etc.)
Working understanding of Statistical modelling & Time Series Analysis using Analytical tools (Python, PySpark, R, etc.)
Knowledge of statistics and experimental design (A/B testing, hypothesis testing, causal inference)
Practical experience building scalable ML models, feature engineering, model evaluation metrics, and statistical inference
Enterprise reporting systems, relational (MySQL, Microsoft SQL Server etc.), database management systems
Business intelligence & reporting (Power BI)
Cloud computing services in Azure/ AWS/ GCP for analytics


Show more "
AI/ML Engineer,Impetus,"Bengaluru, Karnataka, India",Bengaluru,2025-08-04,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-impetus-4279596200?position=31&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=b8wVzqnhKZUDaSIXA1eQiw%3D%3D,"Job Description:




Hands-on experience working with SAS to Python conversions.
Strong mathematics and statistics skills.
Skilled in AI-specific utilities like ChatGPT, Hugging Face Transformers, etc.
Ability to understand business requirements.
Use case derivation and solution creation from structured/unstructured data
Storytelling, Business Communication, and Documentation
Programming Skills – SAS, Python, Scikit-Learn, TensorFlow, PyTorch, Keras
Exploratory Data Analysis
Machine Learning and Deep Learning Algorithms
Model building, Hyperparameter tuning, and Model performance metrics
MLOps, Data Pipeline, Data Engineering
Statistics Knowledge (Probability Distributions, Hypothesis Testing)
Time series modeling, Forecasting, Image/Video Analytics, and Natural Language Processing (NLP).
ML services from Clouds such as AWS, GCP, Azure, and Databricks
Optional - Databricks, Big Data -Basic knowledge of Spark, Hive




Roles & Responsibilities:




Responsible for SAS to python code conversion.
Acquire skills required for building Machine learning models and deploy them for production.
Feature Engineering, EDA, Pipeline creation, Model training, and hyperparameter tuning with structured and unstructured data sets. skills
Develop and deploy cloud-based applications, including LLM/GenAI, into production.

Show more "
Data Scientist 1,Uber,"Hyderabad, Telangana, India",Hyderabad,2025-08-06,https://in.linkedin.com/jobs/view/data-scientist-1-at-uber-4281429105?position=32&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=zk9ePhZ0W6sLqU3Mc2iByw%3D%3D,"About The Role

Communication Platform enables all the messages (SMS OTP, Whatsapp, Notifications, Voice Call, Chat) among our users. This role will help improve our communications products in improving the Deliverability, reliability and reach of the messages by optimising the cost at the same time. Improving effieciency of communications among our users will helop improve trip conversion and in turn revenue for the organization.

What The Candidate Will Need / Bonus Points

---- What the Candidate Will Do ----


Build scalable analytical frameworks to support product analytics for Uber's Communications Platform
Own new product experimentation including plan creation, roll-out, and monitoring
Be an invaluable partner to cross-functional teams such as engineering, product management, various data teams to deploy data quality across critical pipelines and to set up processes to triage data issues
Develop and track metrics and reporting functions to measure and monitor products performance on our platform
Effectively and proactively communicate insights and drive projects to drive towards team goals
Proactively seek out opportunities to build new solutions to tackle challenges
Create and drive data quality standards and frameworks to ensure inclusion into pipeline engineering efforts


Basic Qualifications


2+ years of experience (Bachelor) OR 1+ years of experience (Masters) in a data-focused role such as product analytics, business analytics, business operations, or data science
Education in Engineering, Computer Science, Math, Economics, Statistics or equivalent experience
Experience in programming and/or query languages
Past experience with a Product / Tech company serving millions of customers on multiple platforms and countries


Preferred Qualifications


SQL mastery. Write efficient and complex code in SQL
Experience in Python/R and experimentation, A/B testing, and statistical modelling
Experience in Payments or Compliance with a Product / Tech company
Proven ability to handle and visualise large datasets, explore and utilize raw data feeds
Love of data - you just go get the data you need and turn it into an insightful story.
A well-organized, structured approach to problem-solving
Strong sense of ownership, accountability, and entrepreneurial spirit
Great communicator, problem-solver & confident in decision making
Independent & autonomous, while still a strong teammate
Enthusiastic, self-starting and thrives in changing, agile environments
Show more "
Machine Learning Engineer,Adobe,"Noida, Uttar Pradesh, India",Noida,2025-07-30,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-adobe-4272845837?position=33&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=5yZKsNhioFEVKOJqgUTAZQ%3D%3D,"Our Company

Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.

We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!

Excited by AI/ML? Interested in crafting new innovative solutions using Machine Learning?

The Document Cloud team, in Noida, is crafting PDF solutions spanning all surfaces - Web, Mobile, Desktop and Platform APIs, that processes billions of PDFs every month using ML, Deep-Learning and Generative AI at its core.

As a part of this, we need expert individuals focusing on research and development of methods for processing huge amount of content, and can build mashups of Vision, Image Processing, NLP, generative models to solve sophisticated problems.

What you get to do in this role:


Develop algorithms that apply deep learning and innovative methods in NLP & computer vision, combined with traditional large sophisticated solutions/codebases!
Developing innovative solutions using Generative AI, Python, Machine Learning and Data Science!
Build experiments, algorithms and ship solution that not only yield high accuracy but are also crafted and engineered to scale.
Collaborate across multiple research and engineering teams, making the tradeoffs required to rapidly deliver AI/ML software solutions.


In order to be successful, we need someone who has:


B.Tech in Computer Science. MS/PhD preferred.
3+ years hands-on experience in either deep-learning models, Image processing, Vision and/or NLP.
Ability to write efficient, clean, and reusable code in Python. Knowledge of C++.
Broad Machine Learning experience – Data, Modelling, Metric, Analysis of Results.
Experience in prompt-engineering and working with advanced-RAG systems.
Exposure to Deep Learning - CNNs, LSTMs, Transformers, network architecture, network tuning, transfer learning, multi-task learning. Hands-on coding in pyTorch or Tensorflow.
Exposure in building solutions from scratch and writing maintainable code inside large existing codebases.
Strong software development skills that encourage code reuse among engineers and researchers.


Adobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.

Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.
Show more "
Junior Data Scientist (immediate joiner only),VectorStack,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-08,https://in.linkedin.com/jobs/view/junior-data-scientist-immediate-joiner-only-at-vectorstack-4281803092?position=34&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=0TtWGrK7BGfHmuDs978%2F0Q%3D%3D,"Skills:
Python, aws, ETL, Time Series Forecasting, Predictive Modeling, SQL,

Company Overview

VectorStack, headquartered in Bangalore, is a leader in the IT industry known for its dynamic and creative approach in delivering high-quality, high-value goods and consulting services. Our commitment to innovation and quality sets us apart, ensuring clients receive outstanding solutions with 24/7 dedicated support. We pride ourselves on resolving issues promptly and fostering an environment that supports both creativity and customer satisfaction.

Job Overview

We are seeking a Junior Data Scientist to join our team immediately. This full-time role is based in Bangalore Urban, Bengaluru, and is an exciting opportunity for those with 2 to 4 years of experience in the field. As a Junior Data Scientist, you will be an integral part of our team, helping to analyze and transform data into actionable insights to drive our business forward.

Qualifications And Skills


Proficiency in Python (Mandatory skill) to develop algorithms and perform data analysis tasks effectively.
Hands-on experience with Time Series Forecasting (Mandatory skill) for predictive modeling and trend analysis.
Solid understanding of SQL (Mandatory skill) for querying databases and managing data efficiently.
Experience with AWS for deploying models and running cloud-based analytics solutions.
Knowledge of ETL processes to efficiently extract, transform, and load data from various sources.
Ability to develop Predictive Modeling techniques to drive strategic decisions and business growth.
Strong analytical skills with an attention to detail, ensuring accurate and meaningful data interpretations.
Effective communication skills to present data-driven insights to non-technical stakeholders.


Roles And Responsibilities


Analyze complex data sets to identify trends and patterns that can inform business strategies.
Collaborate with cross-functional teams to integrate data solutions into business processes.
Develop predictive models to support decision-making and enhance business performance.
Implement and maintain data pipelines, ensuring efficient data flow across the organization.
Utilize SQL for data manipulation and extraction to support ongoing analysis.
Contribute to the development of analytical tools and capabilities that improve data accessibility.
Prepare clear and concise reports to communicate analytical findings to management.
Stay current with industry trends and emerging technologies to bring innovative solutions to the team.
Show more "
AI/ML Software Engineer,eBay,"Bengaluru, Karnataka, India",Bengaluru,2025-08-06,https://in.linkedin.com/jobs/view/ai-ml-software-engineer-at-ebay-4265461193?position=35&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=QbT7aSkl46YFFap5LxiLUA%3D%3D,"At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

About The Team And Role

The Compliance Engineering team at eBay is focused on prohibited, restricted, and counterfeit compliance detection is dedicated to ensuring that eBay’s marketplace adheres to all relevant regulations and internal policies.

The team develops and maintain advanced, AI-driven tools and scalable backend systems that automatically identify and assess items listed on the platform. By applying sophisticated data models, machine learning algorithms, and rules-based engines, they detect products that may be illegal, harmful, non-compliant with trade regulations, or counterfeit.

Overall, this Compliance Engineering team plays a crucial role in maintaining trust in eBay’s platform, safeguarding customers, and upholding the company’s dedication to a fair, safe, and legally compliant marketplace.

What You Will Accomplish


Build large-scale applications, low-latency APIs, data pipelines, and foundational architectures to support eBay’s business operations and customer experiences.
Design and implement highly configurable, metadata-driven platforms to enable seamless ingestion of attributes, rules, models, policies, and derived aggregates.
Develop machine learning models and Gen AI tools to generate insights and improve customer experiences across eBay.
Partner with architects, business leaders, and industry experts to devise strategies and scalable solutions.
Be responsible for the entire software lifecycle, including design, development, testing, and experimentation.
Mentor and lead junior team members by setting examples and guiding them toward success.



What You Will Bring


Prefer Technical degree with 3-5+ years of relevant software development experience.
Strong hands on Machine Leaning experience, AI/ML/Gen AI, LLM's and proven experience in building and running AI/ML/GenAI models in production environments.
Outstanding programming skills in Java, Scala, and Python, with hands-on experience in frameworks like PyTorch and TensorFlow.
Proven experience with APIs and Distributed Systems, building and consuming horizontally scalable RESTful APIs, GraphQL, and distributed systems.
Hands-on experience with technologies like Spark, Flink, and Kafka with practical experience in their use.
Strong understanding of SQL, NoSQL, and sophisticated data modeling techniques.
Hands-on experience with the Hadoop ecosystem (HDFS, MapReduce, Hive, Spark) for building and optimizing large-scale data solutions.



Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.
Show more "
Machine Learning Engineer,Impetus,"Pune, Maharashtra, India",Pune,2025-07-20,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-impetus-4241752294?position=37&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=ARZRbTyKXhr9QQZ9TTA5xA%3D%3D,"Job Summary:

We are looking for highly motivated and analytical Machine Learning Engineers with 1–3 years of experience in building scalable, production-ready AI/ML models. This role involves working on complex business problems using advanced ML/DL techniques across domains such as Natural Language Processing (NLP), Computer Vision, Time Series Forecasting, and Generative AI.

You will be responsible for end-to-end model development, deployment, and performance tracking while collaborating with cross-functional teams including data engineering, DevOps, and product.




Location: Noida / Gurugram / Indore / Bengaluru / Pune / Hyderabad

Experience: 1–3 Years

Education: BE / B.Tech / M.Tech / MCA / M.Com




Key Responsibilities:

Model Development & Experimentation

Design and build machine learning models for NLP, computer vision, and time series prediction using supervised, unsupervised, and deep learning techniques.
Conduct experiments to improve model performance via architectural modifications, hyperparameter tuning, and feature selection.
Apply statistical analysis to validate and interpret model results.
Evaluate models using appropriate metrics (e.g., accuracy, precision, recall, F1-score, AUC-ROC).

Data Handling & Feature Engineering

Process large structured and unstructured datasets using Python, Pandas, and DataFrame APIs.
Perform feature extraction, transformation, and selection tailored to specific ML problems.
Implement data augmentation and enrichment techniques to enhance training quality.

Model Deployment & Productionization

Deploy trained models to production environments using cloud platforms such as AWS (especially SageMaker).
Containerize models using Docker and orchestrate deployments with Kubernetes.
Implement monitoring, logging, and automated retraining pipelines for model health tracking.

Collaboration & Innovation

Collaborate with data engineers and architects to ensure smooth data flow and infrastructure alignment.
Explore and adopt cutting-edge AI/ML methodologies and GenAI frameworks (e.g., LangChain, GPT-3).
Contribute to documentation, versioning, and knowledge-sharing across teams.
Drive innovation and continuous improvement in AI/ML delivery and engineering practices.

Mandatory Technical Skills:

Languages & Tools: Python (Pandas, NumPy, Scikit-learn, TensorFlow/PyTorch)
Model Development: Deep Learning, NLP, Time Series, Computer Vision
Cloud Platforms: AWS (especially SageMaker)
Model Deployment: Docker, Kubernetes, REST APIs
ML Ops: Model monitoring, performance logging, CI/CD
Frameworks: LangChain (for GenAI), Transformers, Hugging Face

Preferred / Good to Have:

Experience with Foundation Model tuning and prompt engineering
Hands-on with Generative AI (GPT-3/4, OpenAI APIs, LangChain integrations)
Certifications: AWS Certified Machine Learning – Specialty
Experience with version control (Git), and experiment tracking tools (MLflow, Weights & Biases)

Soft Skills:

Excellent communication and presentation abilities
Strong analytical and problem-solving mindset
Ability to work in collaborative, fast-paced environments
Curiosity to learn emerging technologies and apply them to real-world problems

Show more "
Junior Data Scientist (immediate joiner only),VectorStack,"Bengaluru, Karnataka, India",Bengaluru,2025-08-08,https://in.linkedin.com/jobs/view/junior-data-scientist-immediate-joiner-only-at-vectorstack-4281803091?position=38&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=trfohBPn45RyFrCDea30Dg%3D%3D,"Skills:
Python, aws, ETL, Time Series Forecasting, Predictive Modeling, SQL,

Company Overview

VectorStack, headquartered in Bangalore, is a leader in the IT industry known for its dynamic and creative approach in delivering high-quality, high-value goods and consulting services. Our commitment to innovation and quality sets us apart, ensuring clients receive outstanding solutions with 24/7 dedicated support. We pride ourselves on resolving issues promptly and fostering an environment that supports both creativity and customer satisfaction.

Job Overview

We are seeking a Junior Data Scientist to join our team immediately. This full-time role is based in Bangalore Urban, Bengaluru, and is an exciting opportunity for those with 2 to 4 years of experience in the field. As a Junior Data Scientist, you will be an integral part of our team, helping to analyze and transform data into actionable insights to drive our business forward.

Qualifications And Skills


Proficiency in Python (Mandatory skill) to develop algorithms and perform data analysis tasks effectively.
Hands-on experience with Time Series Forecasting (Mandatory skill) for predictive modeling and trend analysis.
Solid understanding of SQL (Mandatory skill) for querying databases and managing data efficiently.
Experience with AWS for deploying models and running cloud-based analytics solutions.
Knowledge of ETL processes to efficiently extract, transform, and load data from various sources.
Ability to develop Predictive Modeling techniques to drive strategic decisions and business growth.
Strong analytical skills with an attention to detail, ensuring accurate and meaningful data interpretations.
Effective communication skills to present data-driven insights to non-technical stakeholders.


Roles And Responsibilities


Analyze complex data sets to identify trends and patterns that can inform business strategies.
Collaborate with cross-functional teams to integrate data solutions into business processes.
Develop predictive models to support decision-making and enhance business performance.
Implement and maintain data pipelines, ensuring efficient data flow across the organization.
Utilize SQL for data manipulation and extraction to support ongoing analysis.
Contribute to the development of analytical tools and capabilities that improve data accessibility.
Prepare clear and concise reports to communicate analytical findings to management.
Stay current with industry trends and emerging technologies to bring innovative solutions to the team.
Show more "
Data Scientist,AB InBev GCC India,"Bengaluru, Karnataka, India",Bengaluru,2025-07-15,https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4267194473?position=39&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=5rmE%2F0%2Bc6OLwjhXi38hhsQ%3D%3D,"AB InBev GCC was incorporated in 2014 as a strategic partner for Anheuser-Busch InBev. The center leverages the power of data and analytics to drive growth for critical business functions such as operations, finance, people, and technology. The teams are transforming Operations through Tech and Analytics.




Do You Dream Big?




We Need You.




Job Title: Data Scientist

Location: Bangalore




PURPOSE OF ROLE

The Data Scientist will play a key role in designing and delivering data-driven solutions that enable better decision-making across the organization. This role requires strong hands-on coding skills in Python, experience with core data science libraries, and the ability to statistically validate features and models. The analyst will collaborate across teams, work efficiently with existing codebases, and apply version control and development best practices to build scalable, production-ready analytics solutions. With intermediate SQL expertise and a solid grasp of model development workflows, the role ensures robust, interpretable, and actionable outcomes from complex data.







KEY TASKS AND ACCOUNTABILITIES

Develop and maintain data science models using Python, applying intermediate to advanced knowledge of syntax, data structures, and key libraries such as pandas and numpy.
Perform feature engineering and statistical validation of features and models to ensure robustness, accuracy, and business relevance.
Write clean, modular, and well-documented code following best development practices; optionally adopt Test-Driven Development (TDD) to enable faster iteration and feedback cycles.
Collaborate with cross-functional teams to understand data requirements, align on analytical solutions, and translate business problems into data science problems.
Read, understand, and extend existing codebases, adapting quickly to different coding styles and project structures.
Leverage version control tools like Git for collaborative development, code management, and maintaining reproducibility of models.
Write and optimize intermediate-level SQL queries to extract, transform, and analyze data from structured databases.
Contribute to the deployment readiness of models, ensuring outputs are interpretable, reusable, and aligned with production or decision-support use cases.
Document processes, assumptions, and outputs clearly for stakeholder transparency, reproducibility, and future reference.
Stay up to date with industry trends, new tools, and emerging best practices in data science, analytics, and development methodologies.







Qualifications

Bachelor’s or Master’s degree in Computer Science, Information Systems, Artificial Intelligence, Machine Learning, or a related field (B.Tech / BE / Masters in CS/IS/AI/ML).




Work Experience:

3-7 years of hands-on experience in a data science or analytics role, with a proven track record of building and deploying data-driven solutions in real-world scenarios.




Technical Skills Required:

Python Programming (Intermediate to Advanced): Strong grasp of syntax, data structures, and experience with libraries like pandas and numpy.
Data Science Fundamentals: Ability to statistically validate features and models, ensuring sound analytical rigor.
SQL (Intermediate): Proficiency in writing queries to extract, manipulate, and analyze data from relational databases.
Version Control (GIT): Familiarity with collaborative development using Git for code versioning and management.
Code Adaptability: Comfortable working with and modifying existing codebases written by others.




Good to have skills:

Object-Oriented Programming (OOPs) in Python: Understanding and applying OOP concepts where appropriate.
Test-Driven Development (TDD): Awareness of TDD practices for faster iteration and improved code quality.
Model Deployment Lifecycle Knowledge: Familiarity with reproducibility, tracking, and maintaining deployed models (though not explicitly required, it’s a plus if known).







We dream big to create a future with more cheers!

Show more "
Data Scientist,Media.net,"Bengaluru, Karnataka, India",Bengaluru,2025-08-11,https://in.linkedin.com/jobs/view/data-scientist-at-media-net-4275687771?position=40&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=cf3RJACzLiWdVnB4GjBapg%3D%3D,"Role : Data Scientist II




About Media.net :

Media.net is a leading, global ad tech company that focuses on creating the most transparent and efficient path for advertiser budgets to become publisher revenue. Our proprietary contextual technology is at the forefront of enhancing Programmatic buying, the latest industry-standard in ad buying for digital platforms.




The Media.net platform powers major global publishers and ad-tech businesses at scale across ad formats like display, video, mobile, native, as well as search. Media.net’s U.S. HQ is based in New York, and the Global HQ is in Dubai. With office locations and consultant partners across the world, Media.net takes pride in the value-add it offers to its 50+ demand and 21K+ publisher partners, in terms of both products and services.




Data Science is at the heart of Media.net. The team uses advanced statistical and machine learning and deep learning models, large scale distributed computing along with tools from mathematics, economics, auction theory to build solutions that enable us to match users with relevant ads in the most optimal way thereby maximizing revenue for our customers and for Media.net.




Some of the challenges the team deals with:

How do you use information retrieval, machine learning models to estimate click through rate and revenue given the information regarding the position of the slot, user device, location and content of the page. How do you scale the same for thousands of domains, millions of urls?
How do you match ads to page views considering contextual information? How do you design learning mechanisms to continuously learn from user feedback in the form of clicks and conversions? How do you deal with the extremely sparse data? What do you do for new ads and new pages? How do we design better explore-exploit frameworks? How do you design learning algorithms that are fast and scalable?
How do you combine contextual targeting with behavioral user-based targeting?
How do you establish a unique user identity based on multiple noisy signals so that behavioral targeting is accurate?
Can you use NLP to find more genetic trends based on the content of the page and as?




What is in it for you?




Understand business requirements, analyze and extract relevant information from large amounts of historical data.
Use your knowledge of Information retrieval, NLP, Machine Learning (including Deep Learning) to build prototype solutions keeping scale, speed and accuracy in mind.
Work with engineering teams to implement the prototype. Work with engineers to design appropriate model performance metrics and create reports to track the same.
Work with the engineering teams to identify areas of improvement, jointly develop research agenda and execute on the same using cutting edge algorithms and tools.
You will need to understand a broad range of ML algorithms and appreciation on how to apply them to complex practical problems. You will also need to have enough theoretical background and a good grasp of algorithms to be able to critically evaluate existing ML algorithms and be creative when there is a need to go beyond textbook solutions.




Who should apply for this role ?




PhD/Research Degree or BS/MS in Computer Science, Statistics, Artificial Intelligence, Machine learning, Operations Research or related field.
3- 5 years of experience in building Machine Learning/AI/Information Retrieval models
Extensive knowledge and practical experience in machine learning, data mining, artificial intelligence, statistics.
Understanding of supervised and unsupervised algorithms including but not limited to linear models, decision trees, random forests, gradient boosting machines etc.
Excellent analytical and problem-solving abilities.
Good knowledge of scientific programming in Python.
Experience with Apache Spark is desired.
Excellent verbal & written communication skills

Bonus Points:

Publications or presentation in recognized Machine Learning and Data Mining journals/conferences such as ICML
Knowledge in several of the following: Math/math modeling, decision theory, fuzzy logic, Bayesian techniques, optimization techniques, statistical analysis of data, information retrieval, natural language processing, large scale data processing and data mining
Ability deal with ambiguity & break them down into research problems
Strong theoretical and research acumen
Show more "
Data Scientist - I,Navi,"Bengaluru, Karnataka, India",Bengaluru,2025-07-16,https://in.linkedin.com/jobs/view/data-scientist-i-at-navi-4267674285?position=41&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=3KGfD4Ty2XdL3esxYPtrYA%3D%3D,"About the Team

The Data Science team at Navi plays a central role in building intelligent solutions that power our products and drive business impact. We work across key domains such as Lending, Collections, KYC, UPI Growth and Ads recommendation, applying advanced machine learning/deep learning/GenAI techniques to solve high-impact challenges. Our work involves a diverse range of data types—including text, image, and tabular data—and we closely collaborate with cross-functional teams like Product, Business, Engineering, etc. to deliver end-to-end solutions.




About the Role

As a Data Scientist 1 at Navi, you’ll be an integral part of a team that’s building scalable and efficient solutions across lending, insurance, investments, and UPI. You won’t just be solving predefined problems - you’ll help define them, working hands-on across a variety of domains including computer vision, tabular data, natural language processing, speech recognition, and Generative AI. You’ll have the opportunity to apply cutting-edge techniques to real-world challenges, while collaborating closely with cross-functional teams to deliver measurable business impact. This isn’t just a role - it’s a chance to contribute to the future of fintech through innovative, high-ownership work that makes a visible difference.




What We Expect From You

End-to-End Project Ownership: Take complete responsibility for data science projects—from building models to deploying them—ensuring delivery of measurable business outcomes.
Cross-Functional Collaboration: Work closely with Product, Engineering, and Business teams to translate problem statements into scalable, real-world data science solutions.
Technical Expertise: Apply advanced techniques across machine learning, deep learning, NLP, computer vision, and generative AI to address complex business challenges.
Diverse Data Handling: Work confidently with tabular, text, image, and speech data, choosing the right models and tools to extract actionable insights.
Innovation & Experimentation: Proactively explore and implement new algorithms and approaches, consistently pushing the boundaries of what’s possible in fintech.
Model Validation & Monitoring: Ensure robust model validation, ongoing monitoring, and performance tracking in production to guarantee continuous business value.
Culture Contribution: Contribute to a culture of learning, peer review, and technical excellence within the data science team.




Must Haves

Bachelor's or Master's in Engineering or equivalent.
Strong Python programming skills and SQL skills; experience with pyspark / scala is a plus
Proficiency in pandas, scikit-learn and familiarity with TensorFlow/PyTorch
Strong data analysis and visualisation skills
Understanding of machine learning / deep learning concepts, probability theory, optimisation techniques and statistical concepts
Strong interpersonal and collaborative skills
Excellent verbal and written communication skills




Inside Navi

We are shaping the future of financial services for a billion Indians through products that are simple, accessible, and affordable. From Personal & Home Loans to UPI, Insurance, Mutual Funds, and Gold — we’re building tech-first solutions that work at scale, with a strong customer-first approach.




Founded by Sachin Bansal & Ankit Agarwal in 2018, we are one of India’s fastest-growing financial services organisations. But we’re just getting started!




Our Culture

The Navi DNA

Ambition. Perseverance. Self-awareness. Ownership. Integrity.

We’re looking for people who dream big when it comes to innovation. At Navi, you’ll be empowered with the right mechanisms to work in a dynamic team that builds and improves innovative solutions. If you’re driven to deliver real value to customers, no matter the challenge, this is the place for you.

We chase excellence by uplifting each other—and that starts with every one of us.




Why You'll Thrive at Navi

At Navi, it’s about how you think, build, and grow. You’ll thrive here if:

You’re impact-driven : You take ownership, build boldly, and care about making a real difference.
You strive for excellence : Good isn’t good enough. You bring focus, precision, and a passion for quality.
You embrace change : You adapt quickly, move fast, and always put the customer first.

Show more "
Data Scientist + Gen AI,LTIMindtree,"Bangalore Urban, Karnataka, India",Bangalore Urban,2025-08-02,https://in.linkedin.com/jobs/view/data-scientist-%2B-gen-ai-at-ltimindtree-4276226981?position=43&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=krYqP3x8hq1qTo%2FJuQy65w%3D%3D,"Job Details:

Experience - 6 to 12 yrs

Mandatory Skills -Data Science, Gen AI, Python, RAG and Azure/AWS/GCP, AI/ML, NLP

Location - Mumbai, Pune, Bangalore, Chennai, Hyderabad and Kolkata location.

Notice - Immediate to 60 days




Generic JD-

Mandatory Skills - Data Science, Gen AI, Python, RAG and Azure/AWS/GCP, AI/ML, NLP

Secondary - (Any) Machine Learning, Deep Learning, ChatGPT, Langchain, Prompt, vector stores, RAG, llama, Computer vision, Deep learning, Machine learning, OCR, Transformer, regression, forecasting, classification, hyper parameter tunning, MLOps, Inference, Model training, Model Deployment

JD_

More than 6 years of experience in Data Engineering, Data Science and AI / ML domain

Excellent understanding of machine learning techniques and algorithms, such as GPTs, CNN, RNN, k-NN, Naive Bayes, SVM, Decision Forests, etc.

Experience using business intelligence tools (e.g. Tableau, PowerBI) and data frameworks (e.g. Hadoop)

Experience in Cloud native skills.

Knowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset

Analytical mind and business acumen and Strong math skills (e.g. statistics, algebra)

Experience with common data science toolkits, such as TensorFlow, KERAs, PyTorch, PANDAs, Microsoft CNTK, NumPy etc. Deep expertise in at least one of these is highly desirable.

Experience with NLP, NLG and Large Language Models like BERT, LLaMa, LaMDA, GPT, BLOOM, PaLM, DALL-E, etc.

Great communication and presentation skills. Should have experience in working in a fast-paced team culture.

Experience with AIML and Big Data technologies like AWS SageMaker, Azure Cognitive Services, Google Colab, Jupyter Notebook, Hadoop, PySpark, HIVE, AWS EMR etc.

Experience with NoSQL databases, such as MongoDB, Cassandra, HBase, Vector databases

Good understanding of applied statistics skills, such as distributions, statistical testing, regression, etc.

Should be a data-oriented person with analytical mind and business acumen.

Show more "
Data Scientist,Infosys,"Bengaluru East, Karnataka, India",Bengaluru East,2025-08-01,https://in.linkedin.com/jobs/view/data-scientist-at-infosys-4270904356?position=44&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=N70TdC74asw5uf9bFVGuAw%3D%3D,"Should have the hands on experience to train computer vision and deep learning models to solve computer vision use cases.
Should be able to create and optimize algorithms for image and video analysis, for tasks such as object detection, image recognition, segmentation and video analytics.
Should have expertise on different object tracking algorithms and track multi objects in multi cameras.
Should be able to articulate camera calibration and region of interest extraction.
Should have experience working on a large-scale implementation with 100+ stream in real time
Fine-tune deep learning models like CNNs, vision transformers using frameworks such as Tensorflow, PyTorch, onnx etc.
Should have used NVIDIA frameworks preferably like NGC models, TAO toolkit, metropolis Deep stream, triton server, and triton server to create inferencing pipeline and its deployment.
Should have knowledge of optimizing inferencing pipelines to work on edge
Should be able to perform necessary pre and post processing to optimize the computer vision models and evaluate it.
Should have experience working on action recognition with temporal analysis
Should have knowledge on pruning the model for deploying on edge/ARM devices
Collaborate with Business and IT teams
Show more "
Data Scientist,Protium,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-scientist-at-protium-4284055487?position=45&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=acpnIf3BaeilpwEFCgNbnQ%3D%3D,"Company Description

Protium is a leading engineering-led, risk-focused lender operating in India. With a full stack approach, Protium offers lending services to MSMEs, consumers, and educational institutions through various channels including digital interfaces and dedicated sales teams. Protium uses proprietary models to assess revenues and growth, providing secured and unsecured lending solutions to small businesses and consumers in tier 1, 2, and 3 cities.




Role Description

This is a full-time on-site role for a Data Scientist - Credit Risk at Protium in Bengaluru. The Data Scientist will be responsible for tasks such as data analysis and visualization to assess credit risk, develop risk models, and provide insights for lending decisions.




Qualifications

2-3 years of experience in credit risk based roles in financial or lending industry.
Data Science and Data Analysis skills
Statistics knowledge
SQL / Python knowledge
Strong analytical and problem-solving skills
Excellent communication and presentation abilities
Bachelor's/Master’s degree in Data Science, Statistics, or related field

Show more "
AI/ML Engineer,Impetus,"Gurugram, Haryana, India",Gurugram,2025-08-10,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-impetus-4262914875?position=46&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=xB6tzJxwZ4HC25e4CyePrA%3D%3D,"Job Description-

ML Engineer:

Strong experience of at-least 2-3 years in Python.
2 + years’ experience of working on feature/data pipelines and feature stores using Py-Spark.
Exposure to AWS cloud services such as Sagemaker, Bedrock, Kendra etc.
Experience with machine learning model lifecycle management tools, and an understanding of MLOps principles and best practice.
Knowledge on Docker and Kubernetes.
Experience with orchestration/scheduling tools like Argo.
Experience building and consuming data from REST APIs.
Demonstrable ability to think outside of the box and not be dependent on readily available tools.
Excellent communication, presentation and interpersonal skills are a must.

Py-Spark AWS Engineer:

Good hands-on experience of python and Bash Scripts.
4+ years of good hands-on exposure with Big Data technologies – Pyspark (Data frame and Spark SQL), Hadoop, and Hive
Hands-on experience with using Cloud Platform provided Big Data technologies (i.e. Glue, EMR, RedShift, S3, Kinesis)
Ability to write Glue jobs and utilise the different core functionalities of Glue.
Good understanding of SQL and data warehouse tools like (Redshift).
Experience with orchestration/scheduling tools like Airflow.
Strong analytical, problem-solving, data analysis and research skills.
Demonstrable ability to think outside of the box and not be dependent on readily available tools.
Excellent communication, presentation and interpersonal skills are a must.




Roles & Responsibilities-

Collaborate with data engineers & architects to implement and deploy scalable solutions.
Provide technical guidance and code review of the deliverables.
Play active role in estimation and planning.
Communicate results to diverse technical and non-technical audiences.
Generate actionable insights for business improvements.
Ability to understand business requirements.
Use case derivation and solution creation from structured/unstructured data.
Actively drive a culture of knowledge-building and sharing within the team
Encourage continuous innovation and out-of-the-box thinking.

Good To Have:

ML Engineer:

Experience researching and applying large language and Generative AI models.
Experience with Langchain, LLAMA Index, and Performance Evaluation frameworks.
Experience working with model registry, model deployment & monitoring tools.
ML-Flow / App. Monitoring tools.

Py-Spark AWS Engineer:

Experience in migrating workload from on-premises to cloud and cloud to cloud migrations.
Experience with Data quality frameworks.

Show more "
Machine Learning Engineer,eBay,"Bengaluru, Karnataka, India",Bengaluru,2025-08-05,https://in.linkedin.com/jobs/view/machine-learning-engineer-at-ebay-4264478744?position=47&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=uLS86DnQfs5HBhtYoQbawA%3D%3D,"At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.

Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.

Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.

Machine Learning Engineer

Level: T24

People Manager: No

Location: India

Team: BX Recs

Hiring Manager: rishaagarwal@ebay.com

Recruiter: TBD

Date: Jul 3, 2025

Job Description

Looking for a company that inspires passion, courage and creativity, where you can be on the team shaping the future of global commerce? Want to shape how millions of people buy, sell, connect, and share around the world? If you’re interested in joining a purpose driven community that is dedicated to crafting an ambitious and inclusive work environment, join eBay – a company you can be proud to be with.

Our Recommendations team works on delivering recommendations at scale and in near real time to our buyers on our website and native app platforms. Recommendations are a core part of how our buyers navigate eBay’s vast and varied inventory. Our team develops state-of-the-art recommendations systems, including deep learning based retrieval systems for personalized recommendations, machine learned ranking models, GenAI/LLM powered recommendations, as well as advanced MLOps in a high volume traffic industrial e-commerce setting.

We are building cutting edge recommender systems powered by the latest ML, NLP, LLM/GenAI/RAG and AI technologies. Additionally, we are building production integrations with Google GCP Vertex AI platforms to supercharge our item recommendation algorithms. Come join our innovative engineering and applied research team!

This Is An Opportunity To


Influence how people will interact with eBay’s recommender systems in the future, and how recommender systems technology will evolve
Work with unique and large data sets of unstructured multimodal data representing eBay's vast and varied inventory, including billions of items and millions of users
Develop and deploy state-of-the-art AI models to production which have direct measurable impact on eBay buyers
Deploy big data technology and large scale data pipelines
Drive marketplace GMB as well as advertising revenue via organic and sponsored recommendations



Qualifications


MS in Computer Science or related area with 1+ years of relevant work experience (or BS/BA with 3+ years) in Engineering / Machine Learning / AI
Experience building large scale distributed applications and expertise in an OO/functional language (Scala, Java, etc.)
Experience building with no sql databases and key value stores (MongoDB, Redis, etc)
Generalist with a can do attitude and willingness to learn/pick up new skill sets as needed
Experience with using cloud services is a plus (GCP is a double plus)
Experience with big data pipelines (Hadoop, Spark, Flink) is a plus
Experience in AI applied research and industrial recommendation systems is a plus
Experience with Large Language Models (LLMs) and prompt engineering is a plus



Links To Some Of Our Previous Work


Tech Blog 2025 (Multimodal GenAI)
Tech Blog 2025 (GenAI Agentic Platform)
RecSys 2024 Workshop paper
Google Cloud Blog 2024
eBay Tech Blog 2023
eBay Tech Blog 2022
RecSys 2021 paper



Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.

eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.

The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.
Show more "
Data Scientist,McKinsey & Company,"Gurugram, Haryana, India",Gurugram,2025-08-12,https://in.linkedin.com/jobs/view/data-scientist-at-mckinsey-company-4283536266?position=48&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=kjiST6sFNqDi4yIygyGDCg%3D%3D,"Who You'll Work With

Driving lasting impact and building long-term capabilities with our clients is not easy work. You are the kind of person who thrives in a high performance/high reward culture - doing hard things, picking yourself up when you stumble, and having the resilience to try another way forward.

In return for your drive, determination, and curiosity, we'll provide the resources, mentorship, and opportunities you need to become a stronger leader faster than you ever thought possible. Your colleagues—at all levels—will invest deeply in your development, just as much as they invest in delivering exceptional results for clients. Every day, you'll receive apprenticeship, coaching, and exposure that will accelerate your growth in ways you won’t find anywhere else.

When you join us, you will have:


Continuous learning: Our learning and apprenticeship culture, backed by structured programs, is all about helping you grow while creating an environment where feedback is clear, actionable, and focused on your development. The real magic happens when you take the input from others to heart and embrace the fast-paced learning experience, owning your journey.
A voice that matters: From day one, we value your ideas and contributions. You’ll make a tangible impact by offering innovative ideas and practical solutions. We not only encourage diverse perspectives, but they are critical in driving us toward the best possible outcomes.
Global community: With colleagues across 65+ countries and over 100 different nationalities, our firm’s diversity fuels creativity and helps us come up with the best solutions for our clients. Plus, you’ll have the opportunity to learn from exceptional colleagues with diverse backgrounds and experiences.
World-class benefits: On top of a competitive salary (based on your location, experience, and skills), we provide a comprehensive benefits package to enable holistic well-being for you and your family.


Your Impact

At McKinsey you will work on real-world, high-impact projects across a variety of industries.

You will have the opportunity to collaborate with QB/Labs teams and build complex and innovative ML systems to accelerate our work in AI and help solve business problems at speed and scale.

You will experience the best environment to grow as a technologist and a leader.

You will develop a sought-after perspective connecting technology and business value by working on real-life problems across a variety of industries and technical challenges to serve our clients on their changing needs.

You will be surrounded by inspiring individuals as part of diverse and multidisciplinary teams.

You will develop a holistic perspective of AI by partnering with the best design, technical, and business talent in the world as your team members.

While we advocate for using the right tech for the right task, we often leverage the following technologies: Python, PySpark, the PyData stack, Airflow, Databricks, our own open-source data pipelining framework called Kedro, Dask/RAPIDS, container technologies such as Docker and Kubernetes, cloud solutions such as AWS, GCP, Azure, and more.

You will work with other data scientists, data/ML engineers, designers, project managers and business subject matter experts on interdisciplinary projects across various industry sectors to enable business ambitions with data & analytics.

You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritizing impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.

As a Data Scientist, you will:


Solve the hardest business problems with our clients in multiple industries worldwide while leading research and development of state-of-the-art Machine Learning and statistical methods
Play a leading role in bringing the latest advances in AI and deep learning to our clients, collaborating with industry executives and QuantumBlack experts to find and execute opportunities to improve business performance using data and advanced machine learning models
Identify machine learning R&D initiatives that have high potential of applicability in industry
Work with QuantumBlack leadership and client executives to understand business problems and map them to state-of-the-art analytics and AI solutions
Work closely with other data scientists, data engineers, machine learning engineers and designers to build end-to-end analytics solutions for our clients that drive real impact in the real world
Perhaps most importantly, you will work in one of the most talented and diverse data science teams in the world


Your Qualifications and Skills


Bachelor's or master's level in a discipline such as: computer science, machine learning, applied statistics, mathematics, engineering or artificial intelligence
2+ years of deep technical experience in machine learning, advanced analytics and statistics
Advanced programming expertise in Python
Proven application of advanced analytical, data science and statistical methods in realworld engagements
Knowledge in Engineering standards, QA/Risk Management
Experience and expertise In GenAI application development (RAG, Agentic flows, etc.) using API integration and orchestration tools such as Langchains, Crew.AI, AutoGen will be an added advantage
Willingness to travel both domestic and international
Good presentation and communication skills, with a knack for explaining complex analytical concepts and insights to technical as well as non-technical audiences
Show more "
Associate Data Scientist,Circle K,"Gurugram, Haryana, India",Gurugram,2025-08-02,https://in.linkedin.com/jobs/view/associate-data-scientist-at-circle-k-4278114996?position=49&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=7usN62kzZyl9u5sBdMhLIA%3D%3D,"Job Description

Alimentation Couche-Tard Inc., (ACT) is a global Fortune 200 company. A leader in the convenience store and fuel space, it has footprint across 31 countries and territories. The India Data & Analytics Global Capability Centre is an integral part of ACT’s Global Data & Analytics Team and the Associate Data Scientist will be a key player on this team that will help grow analytics globally at ACT.

About The Role

The hired candidate will partner with multiple departments, including Global Marketing, Merchandising, Global Technology, and Business Units. The incumbent will be responsible for delivering advanced analytics projects that drive business results including interpreting business, selecting the appropriate methodology, data cleaning, exploratory data analysis, model building, and creation of polished deliverables.

Responsibilities


Analyze large-scale structured and unstructured data; develop deep-dive analyses and machine learning models in retail, marketing, merchandising, and other areas of the business
Utilize data mining, statistical and machine learning techniques to derive business value from store, product, operations, financial, and customer transactional data
Apply multiple algorithms or architectures and recommend the best model with in-depth description to evangelize data-driven business decisions
Utilize cloud setup to extract processed data for statistical modelling and big data analysis, and visualization tools to represent large sets of time series/cross-sectional data
Structure hypothesis, build thoughtful analyses, develop underlying data models, and bring clarity to previously undefined problems
Partner with Data Engineering to build, design and maintain core data infrastructure, pipelines, and data workflows to automate dashboards and analyses
Articulate complex data science models to business teams and present the insights in easily understandable and innovative formats


Qualifications And Experience


Bachelor’s degree required, preferably with a quantitative focus (Statistics, Business Analytics, Data Science, Math, Economics, etc.)
Master’s degree preferred (MBA/MS Computer Science/M.Tech Computer Science, etc.)
1–2 years of relevant working experience in a data science/advanced analytics role
Knowledge of Functional Analytics (Supply chain analytics, Marketing Analytics, Customer Analytics)
Knowledge and ability to conduct statistical modelling using Analytical tools (R, Python, KNIME, etc.) and use big data technologies
Knowledge of business intelligence & reporting (Power BI, Tableau, Alteryx, etc.)
Knowledge of Enterprise reporting systems, relational (MySQL, Microsoft SQL Server etc.), non-relational database management systems and Data Engineering tools
Knowledge and ability to use Big data technologies (Hadoop, Spark, Kafka, Presto etc) and Cloud computing services in Azure/AWS/GCP for data engineering, ML Ops
Ability to delivery, strong disposition towards business and strong interpersonal communication
Individual must be organized, dependable, able to multi-task and manage priorities, display initiative, and must have the ability to work independently in a demanding, fast-paced environment.


Show more "
Data Scientist ( Gen AI ),Citi,"Bengaluru, Karnataka, India",Bengaluru,2025-07-30,https://in.linkedin.com/jobs/view/data-scientist-gen-ai-at-citi-4274380349?position=50&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=yx%2Bhf8RqiNDz2v4fCMePlQ%3D%3D,"Data Science (GenAI & Prompt engineering) – Bangalore

Business Analytics Analyst 2

About CITI

Citi's mission is to serve as a trusted partner to our clients by responsibly providing financial services that enable growth and economic progress. We have 200 years of experience helping our clients meet the world's toughest challenges and embrace its greatest opportunities.

Analytics and Information Management (AIM)

Citi AIM was established in 2003, and is located across multiple cities in India – Bengaluru, Chennai, Pune and Mumbai. It is a global community that objectively connects and analyzes information, to create actionable intelligence for our business leaders. It identifies fact-based opportunities for revenue growth in partnership with the businesses. The function balances customer needs, business strategy, and profit objectives using best in class and relevant analytic methodologies.

What do we do?

The North America Consumer Bank – Data Science and Modeling team analyzes millions of prospects and billions of customer level transactions using big data tools and machine learning, AI techniques to unlock opportunities for our clients in meeting their financial needs and create economic value for the bank.

The team extracts relevant insights, identifies business opportunities, converts business problems into modeling framework, uses big data tools, latest deep learning and machine learning algorithms to build predictive models, implements solutions and designs go-to-market strategies for a huge variety of business problems.

Role Description


The role will be Business Analytics Analyst 2 in the Data Science and Modeling of North America Consumer Bank team
The role will report to the AVP / VP leading the team


What do we offer: The Next Gen Analytics (NGA) team is a part of the Analytics & Information Management (AIM) unit. The NGA modeling team will focus on the following areas of work:

Role Expectations:


Client Obsession – Create client centric analytic solution to business problems. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly.
Analytic Project Execution – Own and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create economic value.
Domain expert – Individuals are expected to be domain expert in their sub field, as well as have a holistic view of other business lines to create better solutions. Key fields of focus are new customer acquisition, existing customer management, customer retention, product development, pricing and payment optimization and digital journey.
Modeling and Tech Savvy – Always up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team.
Statistical mind set – Proficiency in basic statistics, hypothesis testing, segmentation and predictive modeling.
Communication skills – Ability to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management.
Strong project management skills.
Ability to coach and mentor juniors.
Contribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.


Role Responsibilities:


Work with large and complex datasets using a variety of tools (Python, PySpark, SQL, Hive, etc.) and frameworks to build Deep learning/generative AI solutions for various business requirements.
Primary focus areas include model training/fine-tuning, model validation, model deployment, and model governance related to multiple portfolios.
Design, fine-tune and implement LLMs/GenAI applications using techniques like prompt engineering, Retrieval Augmented Generation (RAG) and model fine-tuning
Responsible for documenting data requirements, data collection/processing/cleaning, and exploratory data analysis, including utilizing deep learning /generative AI algorithms and, data visualization techniques.
Incumbents in this role may often be referred to as Data Scientists.
Specialization in marketing, risk, digital, and AML fields possible, applying Deep learning & generative AI models to innovate in these domains.
Collaborate with team members and business partners to build model-driven solutions using cutting-edge Generative AI models (e.g., Large Language Models) and also at times, ML/traditional methods (XGBoost, Linear, Logistic, Segmentation, etc.)
Work with model governance & fair lending teams to ensure compliance of models in accordance with Citi standards.
Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.


What do we look for:

If you are a bright and talented individual looking for a career in AI and Machine Learning with a focus on Generative AI, Citi has amazing opportunities for you.


Bachelor’s Degree with atleast 3 years of experience in data analytics, or Master’s Degree with 2 years of experience in data analytics, or PhD.
Technical Skills
Hands-on experience in PySpark/Python/R programing along with strong experience in SQL.
2-4 years of experience working on deep learning, and generative AI applications
Experience working on Transformers/ LLMs (OpenAI, Claude, Gemini etc.,), Prompt engineering, RAG based architectures and relevant tools/frameworks such as TensorFlow, PyTorch, Hugging Face Transformers, LangChain, LlamaIndex etc.,
Solid understanding of deep learning, transformers/language models.
Familiarity with vector databases and fine-tuning techniques
Experience working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding.
Strong background in Statistical Analysis.
Capability to validate/maintain deployed models in production
Self-motivated and able to implement innovative solutions at fast pace
Experience in Credit Cards and Retail Banking is preferred
Competencies
Strong communication skills
Multiple stake holder management
Strong analytical and problem solving skills
Excellent written and oral communication skills
Strong team player
Control orientated and Risk awareness
Working experience in a quantitative field
Willing to learn and can-do attitude
Ability to build partnerships with cross-function leaders

Education:


Bachelor's / master’s degree in economics / Statistics / Mathematics / Information Technology / Computer Applications / Engineering etc. from a premier institute


Other Details


Employment: Full Time
Industry: Credit Cards, Retail Banking, Financial Services, Banking


------------------------------------------------------

Job Family Group:

Decision Management

------------------------------------------------------

Job Family:

Specialized Analytics (Data Science/Computational Statistics)

------------------------------------------------------

Time Type:

------------------------------------------------------

Most Relevant Skills

Please see the requirements listed above.

------------------------------------------------------

Other Relevant Skills

For complementary skills, please see above and/or contact the recruiter.

------------------------------------------------------

Citi is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.

If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View Citi’s EEO Policy Statement and the Know Your Rights poster.
Show more "
AI/ML Engineer,TaskUs,"Chennai, Tamil Nadu, India",Chennai,2025-08-14,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-taskus-4256963112?position=51&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=DnVtU9ZSDvbdtYpGK8OHMQ%3D%3D,"Job Description

About TaskUs: TaskUs is a provider of outsourced digital services and next-generation customer experience to fast-growing technology companies, helping its clients represent, protect and grow their brands. Leveraging a cloud-based infrastructure, TaskUs serves clients in the fastest-growing sectors, including social media, e-commerce, gaming, streaming media, food delivery, ride-sharing, HiTech, FinTech, and HealthTech.

The People First culture at TaskUs has enabled the company to expand its workforce to approximately 45,000 employees globally. Presently, we have a presence in twenty-three locations across twelve countries, which include the Philippines, India, and the United States.

It started with one ridiculously good idea to create a different breed of Business Processing Outsourcing (BPO)! We at TaskUs understand that achieving growth for our partners requires a culture of constant motion, exploring new technologies, being ready to handle any challenge at a moment's notice, and mastering consistency in an ever-changing world.

What We Offer: At TaskUs, we prioritize our employees' well-being by offering competitive industry salaries and comprehensive benefits packages. Our commitment to a People First culture is reflected in the various departments we have established, including Total Rewards, Wellness, HR, and Diversity. We take pride in our inclusive environment and positive impact on the community. Moreover, we actively encourage internal mobility and professional growth at all stages of an employee's career within TaskUs. Join our team today and experience firsthand our dedication to supporting People First.

Developer, AI/ML Engineer

About TaskUs: TaskUs is a provider of outsourced digital services and next-generation customer experience to fast-growing technology companies, helping its clients represent, protect and grow their brands. Leveraging a cloud-based infrastructure, TaskUs serves clients in the fastest-growing sectors, including social media, e-commerce, gaming, streaming media, food delivery, ride-sharing, HiTech, FinTech, and HealthTech.

TaskUs People First culture has grown the company to have approximately 45K employees worldwide. We are currently in twenty-three locations across twelve countries, including the Philippines, India, and the United States.

It started with one ridiculously good idea to create a different breed of Business Processing Outsourcing (BPO)! We at TaskUs understand that achieving growth for our partners requires a culture of constant motion, exploring new technologies, being ready to handle any challenge at a moment's notice, and mastering consistency in an ever-changing world.

What We Offer: TaskUs provides world-class benefit packages with competitive industry salaries to all its employees. With well-developed departments, such as Total Rewards, Wellness, HR, and Diversity, we continuously thrive in supporting a People First culture. We are known for our inclusiveness and community impact. We also promote internal mobility and professional development at every step of an employee's career within TaskUs. Come be part of TaskUs that supports People First by applying today!

What can you expect in a Developer, AI/ML Engineer role with TaskUs:

We are looking for an Artificial Intelligence and Machine Learning Engineer with 2 to 3 years of experience with python technology, who will be responsible for leveraging AI, NLP, NLU, LLM, and Generative AI technologies to create innovative products. The ideal candidate should have a strong background in machine learning and artificial intelligence with hands-on experience in building scalable and reliable AI-based products .

Key Responsibilities


Design and develop machine learning models to solve complex business problems using AI,NLP, NLU, LLM, and Generative AI technologies
Develop and implement algorithms for data processing, feature extraction, and model training
Collaborate with cross-functional teams to identify business requirements and create solutions that meet those requirements
Identify and evaluate new AI technologies and tools that can improve the performance and efficiency of our products
Manage and mentor a team of AI and Machine Learning Engineers
Ensure that the products are delivered on time, meet quality standards, and are scalable
Communicate technical solutions and results to non-technical stakeholders


Required Qualifications


Bachelor's or Master's degree in Computer Science, Information Technology or related fields 2 to 4 years of experience in machine learning and artificial intelligence
Hands-on experience in building and deploying AI-based products using NLP, NLU, LLM, and Generative AI technologies
Strong hands on experience in Object Oriented Programming System, Python, FastAPI, Generative AI Prompting.
Experience in containerisation(docker), Jenkins.
Experience in leading and managing a team of AI and Machine Learning Engineers
Experience in AWS AI Services would be added advantage
Excellent problem-solving skills with the ability to think creatively and critically
Strong communication and presentation skills with the ability to communicate technical solutions to non-technical stakeholders
Experience in Agile development methodologies and project management
If you are passionate about leveraging AI technologies to create innovative products and have a strong background in machine learning and artificial intelligence, we encourage you to apply for this exciting opportunity.


How We Partner To Protect You: TaskUs will neither solicit money from you during your application process nor require any form of payment in order to proceed with your application. Kindly ensure that you are always in communication with only authorized recruiters of TaskUs.

DEI: In TaskUs we believe that innovation and higher performance are brought by people from all walks of life. We welcome applicants of different backgrounds, demographics, and circumstances. Inclusive and equitable practices are our responsibility as a business. TaskUs is committed to providing equal access to opportunities. If you need reasonable accommodations in any part of the hiring process, please let us know.

We invite you to explore all TaskUs career opportunities and apply through the provided URL https://www.taskus.com/careers/ .

TaskUs is proud to be an equal opportunity workplace and is an affirmative action employer. We celebrate and support diversity; we are committed to creating an inclusive environment for all employees. TaskUs people first culture thrives on it for the benefit of our employees, our clients, our services, and our community.

Req Id: R_2506_8227

Posted At: Wed Jun 25 2025 00:00:00 GMT+0000 (Coordinated Universal Time)
Show more "
AI/ML Engineer,CodeCraft Technologies Pvt Ltd,"Bengaluru, Karnataka, India",Bengaluru,2025-08-01,https://in.linkedin.com/jobs/view/ai-ml-engineer-at-codecraft-technologies-pvt-ltd-4278976918?position=53&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=6aexNB3Z0NqWIcu40%2FNvZg%3D%3D,"Job Category: AIML

Job Type: Full Time

Job Location: Bengaluru Mangalore

Experience: 4-8 Years

Skills: AI AWS/AZURE/GCP Azure ML C computer vision data analytics Data Modeling Data Visualization deep learning Descriptive Analytics GenAI Image processing Java LLM models ML ONNX Predictive Analytics Python R Regression/Classification Models SageMaker SQL TensorFlow

Position Overview

We are looking for an experienced AI/ML Engineer to join our team. The ideal candidate will bring a deep understanding of machine learning, artificial intelligence, and big data technologies, with proven expertise in developing scalable AI/ML solutions. This role shall lead technical efforts, mentor team members, and collaborate with cross-functional teams to design, develop, and deploy cutting edge AI/ML applications.

Job Details


Job Category: AI/ML Engineer.
Job Type: Full-Time
Job Location: Bangalore/Mangalore
Experience Required: 4-8 Years


Key Responsibilities


Design, develop, and deploy deep learning models for object classification, detection, and segmentation using CNNs and Transfer Learning.
Implement image preprocessing and advanced computer vision pipelines.
Optimize deep learning models using pruning, quantization, and ONNX for deployment on edge devices.
Work with PyTorch, TensorFlow, and ONNX frameworks to develop and convert models.
Accelerate model inference using GPU programming with CUDA and cuDNN.
Port and test models on embedded and edge hardware platforms. (Orin, Jetson, Hailo)
Conduct research and experiments to evaluate and integrate GenAI technologies in computer vision tasks.
Explore and implement cloud-based AI workflows, particularly using AWS/Azure AI/ML services.
Collaborate with cross-functional teams for data analytics, data processing, and large-scale model training.


Desired Profile


Strong programming experience in Python.
Solid background in deep learning, CNNs, and transfer learning and Machine learning basics.
Expertise in object detection, classification, segmentation.
Proficiency with PyTorch, TensorFlow, and ONNX.
Experience with GPU acceleration (CUDA, cuDNN).
Hands-on knowledge of model optimization (pruning, quantization).
Experience deploying models to edge devices (e.g., Jetson, mobile, Orin, Hailo )
Understanding of image processing techniques.
Familiarity with data pipelines, data preprocessing, and data analytics.
Willingness to explore and contribute to Generative AI and cloud-based AI solutions.
Good problem-solving and communication skills.


Good to have


Experience with C/C++.
Familiarity with AWS Cloud AI/ML tools (e.g., SageMaker, Rekognition).
Exposure to GenAI frameworks like OpenAI, Stable Diffusion, etc.
Knowledge of real-time deployment systems and streaming analytics.


Qualifications

Graduation/Post-graduation in Computers, Engineering, or Statistics from a reputed institute

If you are passionate to work in a collaborative and challenging environment, apply now!
Show more "
Data Scientist,HCLTech,"Bengaluru, Karnataka, India",Bengaluru,2025-08-13,https://in.linkedin.com/jobs/view/data-scientist-at-hcltech-4279889600?position=54&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=6YGJpRmjQaMgVkKCqwnEOA%3D%3D,"Dear Candidate,

Greetings from HCL Tech!!

We are hiring Data scientist – Machine Learning requirement

Below is the JD for your perusal:

JD:

• Develop and implement AI models capable of accurate predictions.

• Analyze input data to identify key factors influencing rapid movements, utilizing data-driven insights.

• Establish and maintain a continuous learning framework to update models based on planner feedback.

Skills:

• Expert in AI and machine learning model development

• Strong programming knowledge in Python




If interested, kindly revert this mail with the details in the below format along with updated resume

Name

Contact Number

Email ID

Current Location

Preferred Location

Total Experience

Relevant Experience

Current Organisation

Current CTC

Expected CTC

Notice Period




Regards

Durga Karunakaran

HCL Technologies Ltd.

Show more "
Data Scientist,Maxis AI,"Hyderabad, Telangana, India",Hyderabad,2025-07-31,https://in.linkedin.com/jobs/view/data-scientist-at-maxis-ai-4275950724?position=55&pageNum=0&refId=BHMg5x5WKcuA1SqdGWbs2Q%3D%3D&trackingId=%2BqHgZVBLewzd2xR7Okq1lg%3D%3D,"Dear all,

We are looking for highly motivated PhD freshers in Data Science, AI/ML, or related disciplines to join our team as AI/ML Research. This role is designed for individuals with a strong academic foundation and hands-on project experience, eager to apply their knowledge in real-world AI and Large Language Model (LLM) applications.




Key Responsibilities:

Research, design, and implement models in AI/ML/NLP, with a focus on Large Language Models (LLMs).
Collaborate with cross-functional teams to integrate models into production or research pipelines.
Contribute to codebases and perform experiments using Python and relevant ML libraries.
Develop proof-of-concept (PoC) applications or tools based on self-designed research or side projects.

Required Qualifications:

PhD (completed) in Data Science, Computer Science, Artificial Intelligence, Machine Learning, or related fields.
Strong proficiency in Python and libraries such as NumPy, pandas, scikit-learn, PyTorch, or TensorFlow.
Practical understanding of foundational ML and deep learning techniques (e.g., regression, classification, transformers, etc.).
Experience with LLMs (e.g., GPT, BERT, LLaMA) – either academic research or side projects.
Demonstrated ability to build end-to-end AI/ML/NLP projects (e.g., GitHub projects, open-source contributions, thesis work).




If you are interested, kindly share your updated CV by emailing it to recruitment.india@maxisit.com.

Show more "
